{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For AROUSAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/the-4-convolutional-neural-network-models-that-can-classify-your-fashion-images-9fe7f3e5399d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"/Users/apple/Desktop/eeglab14_1_2b/Granger Casuality/img/\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "(32, 32, 4)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for i in range(len(onlyfiles)):\n",
    "    data = Image.open(mypath + onlyfiles[i])\n",
    "    arr = np.array(data)\n",
    "    #arr = arr[:,:,0:3]\n",
    "    #result = np.zeros((32,32))\n",
    "    #toadd = np.zeros((32,32,4))\n",
    "    #for k in range(arr.shape[2]-1):\n",
    "    #    result[:arr[:,:,k].shape[0],:arr[:,:,k].shape[1]] = arr[:,:,k] \n",
    "    #    toadd[:,:,k] = result\n",
    "    X.append(arr)\n",
    "print(len(X))\n",
    "print(X[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/apple/Desktop/eeglab14_1_2b/participant_ratings.csv',\n",
    "                sep=r'\\s*,\\s*',engine = 'python', na_values = '?')\n",
    "df.dropna()\n",
    "Y_chart = pd.get_dummies(df, drop_first=True)\n",
    "Y = Y_chart['Arousal'].tolist()\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Y)):\n",
    "    if Y[i] < 5:\n",
    "        Y[i] = 0\n",
    "    else:\n",
    "        Y[i] = 1\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=(40/len(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1240, 32, 32, 4)\n",
      "(1240,)\n",
      "(40, 32, 32, 4)\n",
      "(40,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 4)\n",
      "Image dataset has min/mean/std/max = 1.00/139.61/79.38/255.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.59/0.49/1.00\n"
     ]
    }
   ],
   "source": [
    "print('Image dataset have shape =', X_train.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train.min(),\n",
    "                        X_train.mean(), X_train.std(), X_train.max()))\n",
    "print('')\n",
    "print('Train label has shape =', y_train.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(y_train.min(),\n",
    "                        y_train.mean(), y_train.std(), y_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 4)\n",
      "Image dataset has min/mean/std/max = 0.00/0.55/0.31/1.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.59/0.49/1.00\n"
     ]
    }
   ],
   "source": [
    "def normalize_data(data): \n",
    "    data = data / data.max()\n",
    "    return data\n",
    "\n",
    "X_train = normalize_data(X_train)\n",
    "X_test = normalize_data(X_test)\n",
    "print('Image dataset have shape =', X_train.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train.min(),\n",
    "                        X_train.mean(), X_train.std(), X_train.max()))\n",
    "print('')\n",
    "print('Train label has shape =', y_train.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(y_train.min(),\n",
    "                        y_train.mean(), y_train.std(), y_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    " [transforms.ToTensor(),\n",
    " transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "tensor_x = torch.stack([torch.Tensor(i) for i in X_train])\n",
    "tensor_y = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = utils.TensorDataset(tensor_x,tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = utils.DataLoader(trainset,  batch_size= 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x_test = torch.stack([torch.Tensor(i) for i in X_test])\n",
    "tensor_y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = utils.TensorDataset(tensor_x_test,tensor_y_test)\n",
    "testloader = utils.DataLoader(testset,  batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "classes = ('Positive', 'Negative')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 32, 32, 4])\n",
      "torch.Size([40, 4, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "images = images.permute(0, 3, 1, 2)\n",
    "print(images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "rows = 1\n",
    "columns = 1\n",
    "fig=plt.figure()\n",
    "for i in range(1):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    img = images[i]\n",
    "    img = torchvision.transforms.ToPILImage()(img)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkernal size 3*3\\nstep size = 1\\nmaximum pooled layer of 2*2\\nstep size = 2\\nlearning rate = 0.0001\\nbatch size = 63\\ndropout rate = 0.5\\nk-fold: 5-fold cross validation\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "kernal size 3*3\n",
    "step size = 1\n",
    "maximum pooled layer of 2*2\n",
    "step size = 2\n",
    "learning rate = 0.0001\n",
    "batch size = 63\n",
    "dropout rate = 0.5\n",
    "k-fold: 5-fold cross validation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(4, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1280, out_features=100, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 10, 3, padding=1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(20)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(10)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(20*8*8, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(100, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 20 * 8 * 8)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_classes = 2\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 6, 3)\n",
    "        self.conv1_bn = nn.BatchNorm2d(20)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.conv2_bn = nn.BatchNorm2d(10)\n",
    "        \n",
    "        '''\n",
    "        #spatial transformer localization\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(4, 10, 3, padding = 1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(10, 20, 3, padding=1),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.ReLU(True)\n",
    "            \n",
    "        ) '''\n",
    "        #add an regressor\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(16*6*6, 96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(96, 6),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(6, num_classes),\n",
    "        )\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        #x = self.stn(x)\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        #x = F.dropout2d(x, p=0.5)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.flat(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    #spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        #xs = self.flat(xs)\n",
    "        theta = self.classifier(xs)\n",
    "        theta = theta.view(-1,2,3)\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x,grid)\n",
    "        return x\n",
    "        '''\n",
    "        \n",
    "    def flat(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num = 1\n",
    "        for s in size:\n",
    "            num *= s\n",
    "        return num\n",
    "    \n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.hub.load('pytorch/vision:v0.4.2', 'squeezenet1_0', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:    19] avg mini-batch loss: 0.682\n",
      "[epoch: 1, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 2, i:    19] avg mini-batch loss: 0.674\n",
      "[epoch: 3, i:    19] avg mini-batch loss: 0.678\n",
      "[epoch: 4, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 5, i:    19] avg mini-batch loss: 0.678\n",
      "[epoch: 6, i:    19] avg mini-batch loss: 0.677\n",
      "[epoch: 7, i:    19] avg mini-batch loss: 0.675\n",
      "[epoch: 8, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 9, i:    19] avg mini-batch loss: 0.678\n",
      "[epoch: 10, i:    19] avg mini-batch loss: 0.677\n",
      "[epoch: 11, i:    19] avg mini-batch loss: 0.677\n",
      "[epoch: 12, i:    19] avg mini-batch loss: 0.677\n",
      "[epoch: 13, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 14, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 15, i:    19] avg mini-batch loss: 0.677\n",
      "[epoch: 16, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 17, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 18, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 19, i:    19] avg mini-batch loss: 0.677\n",
      "[epoch: 20, i:    19] avg mini-batch loss: 0.677\n",
      "[epoch: 21, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 22, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 23, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 24, i:    19] avg mini-batch loss: 0.675\n",
      "[epoch: 25, i:    19] avg mini-batch loss: 0.675\n",
      "[epoch: 26, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 27, i:    19] avg mini-batch loss: 0.675\n",
      "[epoch: 28, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 29, i:    19] avg mini-batch loss: 0.674\n",
      "[epoch: 30, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 31, i:    19] avg mini-batch loss: 0.675\n",
      "[epoch: 32, i:    19] avg mini-batch loss: 0.675\n",
      "[epoch: 33, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 34, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 35, i:    19] avg mini-batch loss: 0.674\n",
      "[epoch: 36, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 37, i:    19] avg mini-batch loss: 0.674\n",
      "[epoch: 38, i:    19] avg mini-batch loss: 0.675\n",
      "[epoch: 39, i:    19] avg mini-batch loss: 0.674\n",
      "[epoch: 40, i:    19] avg mini-batch loss: 0.674\n",
      "[epoch: 41, i:    19] avg mini-batch loss: 0.674\n",
      "[epoch: 42, i:    19] avg mini-batch loss: 0.672\n",
      "[epoch: 43, i:    19] avg mini-batch loss: 0.673\n",
      "[epoch: 44, i:    19] avg mini-batch loss: 0.672\n",
      "[epoch: 45, i:    19] avg mini-batch loss: 0.674\n",
      "[epoch: 46, i:    19] avg mini-batch loss: 0.670\n",
      "[epoch: 47, i:    19] avg mini-batch loss: 0.672\n",
      "[epoch: 48, i:    19] avg mini-batch loss: 0.672\n",
      "[epoch: 49, i:    19] avg mini-batch loss: 0.671\n",
      "[epoch: 50, i:    19] avg mini-batch loss: 0.669\n",
      "[epoch: 51, i:    19] avg mini-batch loss: 0.668\n",
      "[epoch: 52, i:    19] avg mini-batch loss: 0.665\n",
      "[epoch: 53, i:    19] avg mini-batch loss: 0.667\n",
      "[epoch: 54, i:    19] avg mini-batch loss: 0.671\n",
      "[epoch: 55, i:    19] avg mini-batch loss: 0.672\n",
      "[epoch: 56, i:    19] avg mini-batch loss: 0.669\n",
      "[epoch: 57, i:    19] avg mini-batch loss: 0.662\n",
      "[epoch: 58, i:    19] avg mini-batch loss: 0.669\n",
      "[epoch: 59, i:    19] avg mini-batch loss: 0.665\n",
      "[epoch: 60, i:    19] avg mini-batch loss: 0.663\n",
      "[epoch: 61, i:    19] avg mini-batch loss: 0.659\n",
      "[epoch: 62, i:    19] avg mini-batch loss: 0.663\n",
      "[epoch: 63, i:    19] avg mini-batch loss: 0.661\n",
      "[epoch: 64, i:    19] avg mini-batch loss: 0.659\n",
      "[epoch: 65, i:    19] avg mini-batch loss: 0.667\n",
      "[epoch: 66, i:    19] avg mini-batch loss: 0.659\n",
      "[epoch: 67, i:    19] avg mini-batch loss: 0.656\n",
      "[epoch: 68, i:    19] avg mini-batch loss: 0.660\n",
      "[epoch: 69, i:    19] avg mini-batch loss: 0.663\n",
      "[epoch: 70, i:    19] avg mini-batch loss: 0.663\n",
      "[epoch: 71, i:    19] avg mini-batch loss: 0.664\n",
      "[epoch: 72, i:    19] avg mini-batch loss: 0.662\n",
      "[epoch: 73, i:    19] avg mini-batch loss: 0.657\n",
      "[epoch: 74, i:    19] avg mini-batch loss: 0.660\n",
      "[epoch: 75, i:    19] avg mini-batch loss: 0.651\n",
      "[epoch: 76, i:    19] avg mini-batch loss: 0.649\n",
      "[epoch: 77, i:    19] avg mini-batch loss: 0.648\n",
      "[epoch: 78, i:    19] avg mini-batch loss: 0.655\n",
      "[epoch: 79, i:    19] avg mini-batch loss: 0.666\n",
      "[epoch: 80, i:    19] avg mini-batch loss: 0.639\n",
      "[epoch: 81, i:    19] avg mini-batch loss: 0.643\n",
      "[epoch: 82, i:    19] avg mini-batch loss: 0.655\n",
      "[epoch: 83, i:    19] avg mini-batch loss: 0.655\n",
      "[epoch: 84, i:    19] avg mini-batch loss: 0.644\n",
      "[epoch: 85, i:    19] avg mini-batch loss: 0.638\n",
      "[epoch: 86, i:    19] avg mini-batch loss: 0.637\n",
      "[epoch: 87, i:    19] avg mini-batch loss: 0.636\n",
      "[epoch: 88, i:    19] avg mini-batch loss: 0.652\n",
      "[epoch: 89, i:    19] avg mini-batch loss: 0.646\n",
      "[epoch: 90, i:    19] avg mini-batch loss: 0.639\n",
      "[epoch: 91, i:    19] avg mini-batch loss: 0.646\n",
      "[epoch: 92, i:    19] avg mini-batch loss: 0.647\n",
      "[epoch: 93, i:    19] avg mini-batch loss: 0.638\n",
      "[epoch: 94, i:    19] avg mini-batch loss: 0.641\n",
      "[epoch: 95, i:    19] avg mini-batch loss: 0.635\n",
      "[epoch: 96, i:    19] avg mini-batch loss: 0.643\n",
      "[epoch: 97, i:    19] avg mini-batch loss: 0.637\n",
      "[epoch: 98, i:    19] avg mini-batch loss: 0.627\n",
      "[epoch: 99, i:    19] avg mini-batch loss: 0.630\n",
      "[epoch: 100, i:    19] avg mini-batch loss: 0.630\n",
      "[epoch: 101, i:    19] avg mini-batch loss: 0.611\n",
      "[epoch: 102, i:    19] avg mini-batch loss: 0.626\n",
      "[epoch: 103, i:    19] avg mini-batch loss: 0.639\n",
      "[epoch: 104, i:    19] avg mini-batch loss: 0.621\n",
      "[epoch: 105, i:    19] avg mini-batch loss: 0.622\n",
      "[epoch: 106, i:    19] avg mini-batch loss: 0.613\n",
      "[epoch: 107, i:    19] avg mini-batch loss: 0.620\n",
      "[epoch: 108, i:    19] avg mini-batch loss: 0.640\n",
      "[epoch: 109, i:    19] avg mini-batch loss: 0.618\n",
      "[epoch: 110, i:    19] avg mini-batch loss: 0.604\n",
      "[epoch: 111, i:    19] avg mini-batch loss: 0.617\n",
      "[epoch: 112, i:    19] avg mini-batch loss: 0.603\n",
      "[epoch: 113, i:    19] avg mini-batch loss: 0.610\n",
      "[epoch: 114, i:    19] avg mini-batch loss: 0.617\n",
      "[epoch: 115, i:    19] avg mini-batch loss: 0.604\n",
      "[epoch: 116, i:    19] avg mini-batch loss: 0.627\n",
      "[epoch: 117, i:    19] avg mini-batch loss: 0.624\n",
      "[epoch: 118, i:    19] avg mini-batch loss: 0.609\n",
      "[epoch: 119, i:    19] avg mini-batch loss: 0.606\n",
      "[epoch: 120, i:    19] avg mini-batch loss: 0.619\n",
      "[epoch: 121, i:    19] avg mini-batch loss: 0.601\n",
      "[epoch: 122, i:    19] avg mini-batch loss: 0.610\n",
      "[epoch: 123, i:    19] avg mini-batch loss: 0.603\n",
      "[epoch: 124, i:    19] avg mini-batch loss: 0.627\n",
      "[epoch: 125, i:    19] avg mini-batch loss: 0.595\n",
      "[epoch: 126, i:    19] avg mini-batch loss: 0.595\n",
      "[epoch: 127, i:    19] avg mini-batch loss: 0.596\n",
      "[epoch: 128, i:    19] avg mini-batch loss: 0.599\n",
      "[epoch: 129, i:    19] avg mini-batch loss: 0.586\n",
      "[epoch: 130, i:    19] avg mini-batch loss: 0.591\n",
      "[epoch: 131, i:    19] avg mini-batch loss: 0.588\n",
      "[epoch: 132, i:    19] avg mini-batch loss: 0.584\n",
      "[epoch: 133, i:    19] avg mini-batch loss: 0.569\n",
      "[epoch: 134, i:    19] avg mini-batch loss: 0.558\n",
      "[epoch: 135, i:    19] avg mini-batch loss: 0.573\n",
      "[epoch: 136, i:    19] avg mini-batch loss: 0.557\n",
      "[epoch: 137, i:    19] avg mini-batch loss: 0.564\n",
      "[epoch: 138, i:    19] avg mini-batch loss: 0.551\n",
      "[epoch: 139, i:    19] avg mini-batch loss: 0.572\n",
      "[epoch: 140, i:    19] avg mini-batch loss: 0.561\n",
      "[epoch: 141, i:    19] avg mini-batch loss: 0.565\n",
      "[epoch: 142, i:    19] avg mini-batch loss: 0.554\n",
      "[epoch: 143, i:    19] avg mini-batch loss: 0.544\n",
      "[epoch: 144, i:    19] avg mini-batch loss: 0.542\n",
      "[epoch: 145, i:    19] avg mini-batch loss: 0.537\n",
      "[epoch: 146, i:    19] avg mini-batch loss: 0.526\n",
      "[epoch: 147, i:    19] avg mini-batch loss: 0.562\n",
      "[epoch: 148, i:    19] avg mini-batch loss: 0.551\n",
      "[epoch: 149, i:    19] avg mini-batch loss: 0.534\n",
      "[epoch: 150, i:    19] avg mini-batch loss: 0.516\n",
      "[epoch: 151, i:    19] avg mini-batch loss: 0.537\n",
      "[epoch: 152, i:    19] avg mini-batch loss: 0.506\n",
      "[epoch: 153, i:    19] avg mini-batch loss: 0.522\n",
      "[epoch: 154, i:    19] avg mini-batch loss: 0.505\n",
      "[epoch: 155, i:    19] avg mini-batch loss: 0.511\n",
      "[epoch: 156, i:    19] avg mini-batch loss: 0.508\n",
      "[epoch: 157, i:    19] avg mini-batch loss: 0.496\n",
      "[epoch: 158, i:    19] avg mini-batch loss: 0.521\n",
      "[epoch: 159, i:    19] avg mini-batch loss: 0.484\n",
      "[epoch: 160, i:    19] avg mini-batch loss: 0.499\n",
      "[epoch: 161, i:    19] avg mini-batch loss: 0.486\n",
      "[epoch: 162, i:    19] avg mini-batch loss: 0.472\n",
      "[epoch: 163, i:    19] avg mini-batch loss: 0.456\n",
      "[epoch: 164, i:    19] avg mini-batch loss: 0.469\n",
      "[epoch: 165, i:    19] avg mini-batch loss: 0.489\n",
      "[epoch: 166, i:    19] avg mini-batch loss: 0.434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 167, i:    19] avg mini-batch loss: 0.464\n",
      "[epoch: 168, i:    19] avg mini-batch loss: 0.460\n",
      "[epoch: 169, i:    19] avg mini-batch loss: 0.450\n",
      "[epoch: 170, i:    19] avg mini-batch loss: 0.430\n",
      "[epoch: 171, i:    19] avg mini-batch loss: 0.448\n",
      "[epoch: 172, i:    19] avg mini-batch loss: 0.418\n",
      "[epoch: 173, i:    19] avg mini-batch loss: 0.430\n",
      "[epoch: 174, i:    19] avg mini-batch loss: 0.424\n",
      "[epoch: 175, i:    19] avg mini-batch loss: 0.437\n",
      "[epoch: 176, i:    19] avg mini-batch loss: 0.418\n",
      "[epoch: 177, i:    19] avg mini-batch loss: 0.422\n",
      "[epoch: 178, i:    19] avg mini-batch loss: 0.430\n",
      "[epoch: 179, i:    19] avg mini-batch loss: 0.413\n",
      "[epoch: 180, i:    19] avg mini-batch loss: 0.394\n",
      "[epoch: 181, i:    19] avg mini-batch loss: 0.413\n",
      "[epoch: 182, i:    19] avg mini-batch loss: 0.390\n",
      "[epoch: 183, i:    19] avg mini-batch loss: 0.369\n",
      "[epoch: 184, i:    19] avg mini-batch loss: 0.385\n",
      "[epoch: 185, i:    19] avg mini-batch loss: 0.387\n",
      "[epoch: 186, i:    19] avg mini-batch loss: 0.404\n",
      "[epoch: 187, i:    19] avg mini-batch loss: 0.380\n",
      "[epoch: 188, i:    19] avg mini-batch loss: 0.365\n",
      "[epoch: 189, i:    19] avg mini-batch loss: 0.367\n",
      "[epoch: 190, i:    19] avg mini-batch loss: 0.376\n",
      "[epoch: 191, i:    19] avg mini-batch loss: 0.401\n",
      "[epoch: 192, i:    19] avg mini-batch loss: 0.358\n",
      "[epoch: 193, i:    19] avg mini-batch loss: 0.361\n",
      "[epoch: 194, i:    19] avg mini-batch loss: 0.371\n",
      "[epoch: 195, i:    19] avg mini-batch loss: 0.349\n",
      "[epoch: 196, i:    19] avg mini-batch loss: 0.348\n",
      "[epoch: 197, i:    19] avg mini-batch loss: 0.336\n",
      "[epoch: 198, i:    19] avg mini-batch loss: 0.359\n",
      "[epoch: 199, i:    19] avg mini-batch loss: 0.346\n",
      "[epoch: 200, i:    19] avg mini-batch loss: 0.300\n",
      "[epoch: 201, i:    19] avg mini-batch loss: 0.320\n",
      "[epoch: 202, i:    19] avg mini-batch loss: 0.282\n",
      "[epoch: 203, i:    19] avg mini-batch loss: 0.320\n",
      "[epoch: 204, i:    19] avg mini-batch loss: 0.309\n",
      "[epoch: 205, i:    19] avg mini-batch loss: 0.340\n",
      "[epoch: 206, i:    19] avg mini-batch loss: 0.325\n",
      "[epoch: 207, i:    19] avg mini-batch loss: 0.328\n",
      "[epoch: 208, i:    19] avg mini-batch loss: 0.319\n",
      "[epoch: 209, i:    19] avg mini-batch loss: 0.337\n",
      "[epoch: 210, i:    19] avg mini-batch loss: 0.425\n",
      "[epoch: 211, i:    19] avg mini-batch loss: 0.439\n",
      "[epoch: 212, i:    19] avg mini-batch loss: 0.482\n",
      "[epoch: 213, i:    19] avg mini-batch loss: 0.377\n",
      "[epoch: 214, i:    19] avg mini-batch loss: 0.447\n",
      "[epoch: 215, i:    19] avg mini-batch loss: 0.389\n",
      "[epoch: 216, i:    19] avg mini-batch loss: 0.422\n",
      "[epoch: 217, i:    19] avg mini-batch loss: 0.368\n",
      "[epoch: 218, i:    19] avg mini-batch loss: 0.360\n",
      "[epoch: 219, i:    19] avg mini-batch loss: 0.358\n",
      "[epoch: 220, i:    19] avg mini-batch loss: 0.292\n",
      "[epoch: 221, i:    19] avg mini-batch loss: 0.340\n",
      "[epoch: 222, i:    19] avg mini-batch loss: 0.320\n",
      "[epoch: 223, i:    19] avg mini-batch loss: 0.300\n",
      "[epoch: 224, i:    19] avg mini-batch loss: 0.312\n",
      "[epoch: 225, i:    19] avg mini-batch loss: 0.333\n",
      "[epoch: 226, i:    19] avg mini-batch loss: 0.330\n",
      "[epoch: 227, i:    19] avg mini-batch loss: 0.330\n",
      "[epoch: 228, i:    19] avg mini-batch loss: 0.263\n",
      "[epoch: 229, i:    19] avg mini-batch loss: 0.305\n",
      "[epoch: 230, i:    19] avg mini-batch loss: 0.308\n",
      "[epoch: 231, i:    19] avg mini-batch loss: 0.267\n",
      "[epoch: 232, i:    19] avg mini-batch loss: 0.305\n",
      "[epoch: 233, i:    19] avg mini-batch loss: 0.322\n",
      "[epoch: 234, i:    19] avg mini-batch loss: 0.304\n",
      "[epoch: 235, i:    19] avg mini-batch loss: 0.274\n",
      "[epoch: 236, i:    19] avg mini-batch loss: 0.295\n",
      "[epoch: 237, i:    19] avg mini-batch loss: 0.253\n",
      "[epoch: 238, i:    19] avg mini-batch loss: 0.281\n",
      "[epoch: 239, i:    19] avg mini-batch loss: 0.274\n",
      "[epoch: 240, i:    19] avg mini-batch loss: 0.241\n",
      "[epoch: 241, i:    19] avg mini-batch loss: 0.260\n",
      "[epoch: 242, i:    19] avg mini-batch loss: 0.258\n",
      "[epoch: 243, i:    19] avg mini-batch loss: 0.249\n",
      "[epoch: 244, i:    19] avg mini-batch loss: 0.244\n",
      "[epoch: 245, i:    19] avg mini-batch loss: 0.227\n",
      "[epoch: 246, i:    19] avg mini-batch loss: 0.258\n",
      "[epoch: 247, i:    19] avg mini-batch loss: 0.280\n",
      "[epoch: 248, i:    19] avg mini-batch loss: 0.231\n",
      "[epoch: 249, i:    19] avg mini-batch loss: 0.243\n",
      "[epoch: 250, i:    19] avg mini-batch loss: 0.226\n",
      "[epoch: 251, i:    19] avg mini-batch loss: 0.194\n",
      "[epoch: 252, i:    19] avg mini-batch loss: 0.210\n",
      "[epoch: 253, i:    19] avg mini-batch loss: 0.224\n",
      "[epoch: 254, i:    19] avg mini-batch loss: 0.227\n",
      "[epoch: 255, i:    19] avg mini-batch loss: 0.217\n",
      "[epoch: 256, i:    19] avg mini-batch loss: 0.245\n",
      "[epoch: 257, i:    19] avg mini-batch loss: 0.245\n",
      "[epoch: 258, i:    19] avg mini-batch loss: 0.207\n",
      "[epoch: 259, i:    19] avg mini-batch loss: 0.189\n",
      "[epoch: 260, i:    19] avg mini-batch loss: 0.225\n",
      "[epoch: 261, i:    19] avg mini-batch loss: 0.217\n",
      "[epoch: 262, i:    19] avg mini-batch loss: 0.200\n",
      "[epoch: 263, i:    19] avg mini-batch loss: 0.204\n",
      "[epoch: 264, i:    19] avg mini-batch loss: 0.186\n",
      "[epoch: 265, i:    19] avg mini-batch loss: 0.194\n",
      "[epoch: 266, i:    19] avg mini-batch loss: 0.202\n",
      "[epoch: 267, i:    19] avg mini-batch loss: 0.196\n",
      "[epoch: 268, i:    19] avg mini-batch loss: 0.199\n",
      "[epoch: 269, i:    19] avg mini-batch loss: 0.199\n",
      "[epoch: 270, i:    19] avg mini-batch loss: 0.180\n",
      "[epoch: 271, i:    19] avg mini-batch loss: 0.193\n",
      "[epoch: 272, i:    19] avg mini-batch loss: 0.184\n",
      "[epoch: 273, i:    19] avg mini-batch loss: 0.186\n",
      "[epoch: 274, i:    19] avg mini-batch loss: 0.178\n",
      "[epoch: 275, i:    19] avg mini-batch loss: 0.172\n",
      "[epoch: 276, i:    19] avg mini-batch loss: 0.167\n",
      "[epoch: 277, i:    19] avg mini-batch loss: 0.217\n",
      "[epoch: 278, i:    19] avg mini-batch loss: 0.199\n",
      "[epoch: 279, i:    19] avg mini-batch loss: 0.182\n",
      "[epoch: 280, i:    19] avg mini-batch loss: 0.178\n",
      "[epoch: 281, i:    19] avg mini-batch loss: 0.176\n",
      "[epoch: 282, i:    19] avg mini-batch loss: 0.189\n",
      "[epoch: 283, i:    19] avg mini-batch loss: 0.187\n",
      "[epoch: 284, i:    19] avg mini-batch loss: 0.166\n",
      "[epoch: 285, i:    19] avg mini-batch loss: 0.175\n",
      "[epoch: 286, i:    19] avg mini-batch loss: 0.170\n",
      "[epoch: 287, i:    19] avg mini-batch loss: 0.172\n",
      "[epoch: 288, i:    19] avg mini-batch loss: 0.169\n",
      "[epoch: 289, i:    19] avg mini-batch loss: 0.182\n",
      "[epoch: 290, i:    19] avg mini-batch loss: 0.144\n",
      "[epoch: 291, i:    19] avg mini-batch loss: 0.177\n",
      "[epoch: 292, i:    19] avg mini-batch loss: 0.143\n",
      "[epoch: 293, i:    19] avg mini-batch loss: 0.186\n",
      "[epoch: 294, i:    19] avg mini-batch loss: 0.148\n",
      "[epoch: 295, i:    19] avg mini-batch loss: 0.154\n",
      "[epoch: 296, i:    19] avg mini-batch loss: 0.186\n",
      "[epoch: 297, i:    19] avg mini-batch loss: 0.179\n",
      "[epoch: 298, i:    19] avg mini-batch loss: 0.179\n",
      "[epoch: 299, i:    19] avg mini-batch loss: 0.191\n",
      "[epoch: 300, i:    19] avg mini-batch loss: 0.137\n",
      "[epoch: 301, i:    19] avg mini-batch loss: 0.170\n",
      "[epoch: 302, i:    19] avg mini-batch loss: 0.151\n",
      "[epoch: 303, i:    19] avg mini-batch loss: 0.174\n",
      "[epoch: 304, i:    19] avg mini-batch loss: 0.162\n",
      "[epoch: 305, i:    19] avg mini-batch loss: 0.156\n",
      "[epoch: 306, i:    19] avg mini-batch loss: 0.159\n",
      "[epoch: 307, i:    19] avg mini-batch loss: 0.155\n",
      "[epoch: 308, i:    19] avg mini-batch loss: 0.149\n",
      "[epoch: 309, i:    19] avg mini-batch loss: 0.159\n",
      "[epoch: 310, i:    19] avg mini-batch loss: 0.155\n",
      "[epoch: 311, i:    19] avg mini-batch loss: 0.160\n",
      "[epoch: 312, i:    19] avg mini-batch loss: 0.165\n",
      "[epoch: 313, i:    19] avg mini-batch loss: 0.148\n",
      "[epoch: 314, i:    19] avg mini-batch loss: 0.151\n",
      "[epoch: 315, i:    19] avg mini-batch loss: 0.163\n",
      "[epoch: 316, i:    19] avg mini-batch loss: 0.165\n",
      "[epoch: 317, i:    19] avg mini-batch loss: 0.118\n",
      "[epoch: 318, i:    19] avg mini-batch loss: 0.136\n",
      "[epoch: 319, i:    19] avg mini-batch loss: 0.140\n",
      "[epoch: 320, i:    19] avg mini-batch loss: 0.140\n",
      "[epoch: 321, i:    19] avg mini-batch loss: 0.120\n",
      "[epoch: 322, i:    19] avg mini-batch loss: 0.130\n",
      "[epoch: 323, i:    19] avg mini-batch loss: 0.157\n",
      "[epoch: 324, i:    19] avg mini-batch loss: 0.148\n",
      "[epoch: 325, i:    19] avg mini-batch loss: 0.152\n",
      "[epoch: 326, i:    19] avg mini-batch loss: 0.171\n",
      "[epoch: 327, i:    19] avg mini-batch loss: 0.153\n",
      "[epoch: 328, i:    19] avg mini-batch loss: 0.149\n",
      "[epoch: 329, i:    19] avg mini-batch loss: 0.126\n",
      "[epoch: 330, i:    19] avg mini-batch loss: 0.151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 331, i:    19] avg mini-batch loss: 0.129\n",
      "[epoch: 332, i:    19] avg mini-batch loss: 0.131\n",
      "[epoch: 333, i:    19] avg mini-batch loss: 0.172\n",
      "[epoch: 334, i:    19] avg mini-batch loss: 0.135\n",
      "[epoch: 335, i:    19] avg mini-batch loss: 0.163\n",
      "[epoch: 336, i:    19] avg mini-batch loss: 0.137\n",
      "[epoch: 337, i:    19] avg mini-batch loss: 0.138\n",
      "[epoch: 338, i:    19] avg mini-batch loss: 0.178\n",
      "[epoch: 339, i:    19] avg mini-batch loss: 0.155\n",
      "[epoch: 340, i:    19] avg mini-batch loss: 0.147\n",
      "[epoch: 341, i:    19] avg mini-batch loss: 0.124\n",
      "[epoch: 342, i:    19] avg mini-batch loss: 0.139\n",
      "[epoch: 343, i:    19] avg mini-batch loss: 0.131\n",
      "[epoch: 344, i:    19] avg mini-batch loss: 0.130\n",
      "[epoch: 345, i:    19] avg mini-batch loss: 0.135\n",
      "[epoch: 346, i:    19] avg mini-batch loss: 0.132\n",
      "[epoch: 347, i:    19] avg mini-batch loss: 0.132\n",
      "[epoch: 348, i:    19] avg mini-batch loss: 0.136\n",
      "[epoch: 349, i:    19] avg mini-batch loss: 0.132\n",
      "[epoch: 350, i:    19] avg mini-batch loss: 0.184\n",
      "[epoch: 351, i:    19] avg mini-batch loss: 0.120\n",
      "[epoch: 352, i:    19] avg mini-batch loss: 0.133\n",
      "[epoch: 353, i:    19] avg mini-batch loss: 0.128\n",
      "[epoch: 354, i:    19] avg mini-batch loss: 0.165\n",
      "[epoch: 355, i:    19] avg mini-batch loss: 0.114\n",
      "[epoch: 356, i:    19] avg mini-batch loss: 0.144\n",
      "[epoch: 357, i:    19] avg mini-batch loss: 0.127\n",
      "[epoch: 358, i:    19] avg mini-batch loss: 0.125\n",
      "[epoch: 359, i:    19] avg mini-batch loss: 0.152\n",
      "[epoch: 360, i:    19] avg mini-batch loss: 0.109\n",
      "[epoch: 361, i:    19] avg mini-batch loss: 0.098\n",
      "[epoch: 362, i:    19] avg mini-batch loss: 0.113\n",
      "[epoch: 363, i:    19] avg mini-batch loss: 0.095\n",
      "[epoch: 364, i:    19] avg mini-batch loss: 0.125\n",
      "[epoch: 365, i:    19] avg mini-batch loss: 0.119\n",
      "[epoch: 366, i:    19] avg mini-batch loss: 0.139\n",
      "[epoch: 367, i:    19] avg mini-batch loss: 0.128\n",
      "[epoch: 368, i:    19] avg mini-batch loss: 0.132\n",
      "[epoch: 369, i:    19] avg mini-batch loss: 0.107\n",
      "[epoch: 370, i:    19] avg mini-batch loss: 0.128\n",
      "[epoch: 371, i:    19] avg mini-batch loss: 0.166\n",
      "[epoch: 372, i:    19] avg mini-batch loss: 0.132\n",
      "[epoch: 373, i:    19] avg mini-batch loss: 0.126\n",
      "[epoch: 374, i:    19] avg mini-batch loss: 0.144\n",
      "[epoch: 375, i:    19] avg mini-batch loss: 0.136\n",
      "[epoch: 376, i:    19] avg mini-batch loss: 0.104\n",
      "[epoch: 377, i:    19] avg mini-batch loss: 0.122\n",
      "[epoch: 378, i:    19] avg mini-batch loss: 0.142\n",
      "[epoch: 379, i:    19] avg mini-batch loss: 0.130\n",
      "[epoch: 380, i:    19] avg mini-batch loss: 0.138\n",
      "[epoch: 381, i:    19] avg mini-batch loss: 0.125\n",
      "[epoch: 382, i:    19] avg mini-batch loss: 0.107\n",
      "[epoch: 383, i:    19] avg mini-batch loss: 0.126\n",
      "[epoch: 384, i:    19] avg mini-batch loss: 0.143\n",
      "[epoch: 385, i:    19] avg mini-batch loss: 0.117\n",
      "[epoch: 386, i:    19] avg mini-batch loss: 0.122\n",
      "[epoch: 387, i:    19] avg mini-batch loss: 0.132\n",
      "[epoch: 388, i:    19] avg mini-batch loss: 0.137\n",
      "[epoch: 389, i:    19] avg mini-batch loss: 0.113\n",
      "[epoch: 390, i:    19] avg mini-batch loss: 0.132\n",
      "[epoch: 391, i:    19] avg mini-batch loss: 0.127\n",
      "[epoch: 392, i:    19] avg mini-batch loss: 0.123\n",
      "[epoch: 393, i:    19] avg mini-batch loss: 0.121\n",
      "[epoch: 394, i:    19] avg mini-batch loss: 0.124\n",
      "[epoch: 395, i:    19] avg mini-batch loss: 0.122\n",
      "[epoch: 396, i:    19] avg mini-batch loss: 0.105\n",
      "[epoch: 397, i:    19] avg mini-batch loss: 0.120\n",
      "[epoch: 398, i:    19] avg mini-batch loss: 0.121\n",
      "[epoch: 399, i:    19] avg mini-batch loss: 0.078\n",
      "[epoch: 400, i:    19] avg mini-batch loss: 0.125\n",
      "[epoch: 401, i:    19] avg mini-batch loss: 0.096\n",
      "[epoch: 402, i:    19] avg mini-batch loss: 0.108\n",
      "[epoch: 403, i:    19] avg mini-batch loss: 0.081\n",
      "[epoch: 404, i:    19] avg mini-batch loss: 0.122\n",
      "[epoch: 405, i:    19] avg mini-batch loss: 0.126\n",
      "[epoch: 406, i:    19] avg mini-batch loss: 0.122\n",
      "[epoch: 407, i:    19] avg mini-batch loss: 0.121\n",
      "[epoch: 408, i:    19] avg mini-batch loss: 0.119\n",
      "[epoch: 409, i:    19] avg mini-batch loss: 0.105\n",
      "[epoch: 410, i:    19] avg mini-batch loss: 0.099\n",
      "[epoch: 411, i:    19] avg mini-batch loss: 0.123\n",
      "[epoch: 412, i:    19] avg mini-batch loss: 0.095\n",
      "[epoch: 413, i:    19] avg mini-batch loss: 0.112\n",
      "[epoch: 414, i:    19] avg mini-batch loss: 0.126\n",
      "[epoch: 415, i:    19] avg mini-batch loss: 0.104\n",
      "[epoch: 416, i:    19] avg mini-batch loss: 0.142\n",
      "[epoch: 417, i:    19] avg mini-batch loss: 0.129\n",
      "[epoch: 418, i:    19] avg mini-batch loss: 0.123\n",
      "[epoch: 419, i:    19] avg mini-batch loss: 0.109\n",
      "[epoch: 420, i:    19] avg mini-batch loss: 0.083\n",
      "[epoch: 421, i:    19] avg mini-batch loss: 0.087\n",
      "[epoch: 422, i:    19] avg mini-batch loss: 0.090\n",
      "[epoch: 423, i:    19] avg mini-batch loss: 0.107\n",
      "[epoch: 424, i:    19] avg mini-batch loss: 0.095\n",
      "[epoch: 425, i:    19] avg mini-batch loss: 0.107\n",
      "[epoch: 426, i:    19] avg mini-batch loss: 0.088\n",
      "[epoch: 427, i:    19] avg mini-batch loss: 0.097\n",
      "[epoch: 428, i:    19] avg mini-batch loss: 0.088\n",
      "[epoch: 429, i:    19] avg mini-batch loss: 0.100\n",
      "[epoch: 430, i:    19] avg mini-batch loss: 0.090\n",
      "[epoch: 431, i:    19] avg mini-batch loss: 0.103\n",
      "[epoch: 432, i:    19] avg mini-batch loss: 0.147\n",
      "[epoch: 433, i:    19] avg mini-batch loss: 0.093\n",
      "[epoch: 434, i:    19] avg mini-batch loss: 0.096\n",
      "[epoch: 435, i:    19] avg mini-batch loss: 0.099\n",
      "[epoch: 436, i:    19] avg mini-batch loss: 0.129\n",
      "[epoch: 437, i:    19] avg mini-batch loss: 0.087\n",
      "[epoch: 438, i:    19] avg mini-batch loss: 0.103\n",
      "[epoch: 439, i:    19] avg mini-batch loss: 0.104\n",
      "[epoch: 440, i:    19] avg mini-batch loss: 0.118\n",
      "[epoch: 441, i:    19] avg mini-batch loss: 0.118\n",
      "[epoch: 442, i:    19] avg mini-batch loss: 0.090\n",
      "[epoch: 443, i:    19] avg mini-batch loss: 0.074\n",
      "[epoch: 444, i:    19] avg mini-batch loss: 0.090\n",
      "[epoch: 445, i:    19] avg mini-batch loss: 0.098\n",
      "[epoch: 446, i:    19] avg mini-batch loss: 0.098\n",
      "[epoch: 447, i:    19] avg mini-batch loss: 0.104\n",
      "[epoch: 448, i:    19] avg mini-batch loss: 0.087\n",
      "[epoch: 449, i:    19] avg mini-batch loss: 0.133\n",
      "[epoch: 450, i:    19] avg mini-batch loss: 0.096\n",
      "[epoch: 451, i:    19] avg mini-batch loss: 0.107\n",
      "[epoch: 452, i:    19] avg mini-batch loss: 0.112\n",
      "[epoch: 453, i:    19] avg mini-batch loss: 0.100\n",
      "[epoch: 454, i:    19] avg mini-batch loss: 0.093\n",
      "[epoch: 455, i:    19] avg mini-batch loss: 0.114\n",
      "[epoch: 456, i:    19] avg mini-batch loss: 0.067\n",
      "[epoch: 457, i:    19] avg mini-batch loss: 0.093\n",
      "[epoch: 458, i:    19] avg mini-batch loss: 0.085\n",
      "[epoch: 459, i:    19] avg mini-batch loss: 0.115\n",
      "[epoch: 460, i:    19] avg mini-batch loss: 0.102\n",
      "[epoch: 461, i:    19] avg mini-batch loss: 0.090\n",
      "[epoch: 462, i:    19] avg mini-batch loss: 0.075\n",
      "[epoch: 463, i:    19] avg mini-batch loss: 0.107\n",
      "[epoch: 464, i:    19] avg mini-batch loss: 0.110\n",
      "[epoch: 465, i:    19] avg mini-batch loss: 0.080\n",
      "[epoch: 466, i:    19] avg mini-batch loss: 0.115\n",
      "[epoch: 467, i:    19] avg mini-batch loss: 0.081\n",
      "[epoch: 468, i:    19] avg mini-batch loss: 0.090\n",
      "[epoch: 469, i:    19] avg mini-batch loss: 0.093\n",
      "[epoch: 470, i:    19] avg mini-batch loss: 0.121\n",
      "[epoch: 471, i:    19] avg mini-batch loss: 0.106\n",
      "[epoch: 472, i:    19] avg mini-batch loss: 0.091\n",
      "[epoch: 473, i:    19] avg mini-batch loss: 0.095\n",
      "[epoch: 474, i:    19] avg mini-batch loss: 0.126\n",
      "[epoch: 475, i:    19] avg mini-batch loss: 0.090\n",
      "[epoch: 476, i:    19] avg mini-batch loss: 0.065\n",
      "[epoch: 477, i:    19] avg mini-batch loss: 0.087\n",
      "[epoch: 478, i:    19] avg mini-batch loss: 0.088\n",
      "[epoch: 479, i:    19] avg mini-batch loss: 0.084\n",
      "[epoch: 480, i:    19] avg mini-batch loss: 0.123\n",
      "[epoch: 481, i:    19] avg mini-batch loss: 0.108\n",
      "[epoch: 482, i:    19] avg mini-batch loss: 0.111\n",
      "[epoch: 483, i:    19] avg mini-batch loss: 0.084\n",
      "[epoch: 484, i:    19] avg mini-batch loss: 0.113\n",
      "[epoch: 485, i:    19] avg mini-batch loss: 0.080\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-50e0bfe56686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "#opt = torch.optim.Adam(net.parameters(), lr= 0.001)\n",
    "#opt = torch.optim.Adamax(net.parameters(), lr=0.01)\n",
    "opt = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "#opt = torch.optim.Adagrad(net.parameters(), lr=0.0)\n",
    "avg_losses = [] \n",
    "epochs = 450\n",
    "print_freq = 20\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.permute(0, 3, 1, 2)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        opt.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1:\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Accuracy of the network on the 40 test images: 80 %\n",
      "Accuracy of Positive : 68 %\n",
      "Accuracy of Negative : 90 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(total)\n",
    "print('Accuracy of the network on the 40 test images: %d %%' % (100 * correct / total))\n",
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        one = torch.tensor(1, dtype=torch.float, device=device)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(40):\n",
    "            label = labels[i]\n",
    "            labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240\n",
      "Accuracy of the network on the 1240 training images: 100 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Positive : 100 %\n",
      "Accuracy of Negative : 100 %\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(total)\n",
    "print('Accuracy of the network on the 1240 training images: %d %%' % (100 * correct / total))\n",
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        one = torch.tensor(1, dtype=torch.float, device=device)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(40):\n",
    "            label = labels[i]\n",
    "            labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "kernal size 3*3\n",
    "step size = 1\n",
    "maximum pooled layer of 2*2\n",
    "step size = 2\n",
    "learning rate = 0.0001\n",
    "batch size = 63\n",
    "dropout rate = 0.5\n",
    "k-fold: 5-fold cross validation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
