{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For AROUSAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/the-4-convolutional-neural-network-models-that-can-classify-your-fashion-images-9fe7f3e5399d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"/Users/apple/Desktop/eeglab14_1_2b/Granger Casuality/img/\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for i in range(len(onlyfiles)):\n",
    "    data = Image.open(mypath + onlyfiles[i])\n",
    "    arr = np.array(data)\n",
    "    arr = arr[:,:,0:3]\n",
    "    #result = np.zeros((32,32))\n",
    "    #toadd = np.zeros((32,32,4))\n",
    "    #for k in range(arr.shape[2]-1):\n",
    "    #    result[:arr[:,:,k].shape[0],:arr[:,:,k].shape[1]] = arr[:,:,k] \n",
    "    #    toadd[:,:,k] = result\n",
    "    X.append(arr)\n",
    "print(len(X))\n",
    "print(X[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/apple/Desktop/eeglab14_1_2b/participant_ratings.csv',\n",
    "                sep=r'\\s*,\\s*',engine = 'python', na_values = '?')\n",
    "df.dropna()\n",
    "Y_chart = pd.get_dummies(df, drop_first=True)\n",
    "Y = Y_chart['Arousal'].tolist()\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Y)):\n",
    "    if Y[i] < 5:\n",
    "        Y[i] = 0\n",
    "    else:\n",
    "        Y[i] = 1\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=(40/len(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1240, 32, 32, 3)\n",
      "(1240,)\n",
      "(40, 32, 32, 3)\n",
      "(40,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 3)\n",
      "Image dataset has min/mean/std/max = 1.00/101.14/49.84/253.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.59/0.49/1.00\n"
     ]
    }
   ],
   "source": [
    "print('Image dataset have shape =', X_train.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train.min(),\n",
    "                        X_train.mean(), X_train.std(), X_train.max()))\n",
    "print('')\n",
    "print('Train label has shape =', y_train.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(y_train.min(),\n",
    "                        y_train.mean(), y_train.std(), y_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 3)\n",
      "Image dataset has min/mean/std/max = 0.00/0.40/0.20/1.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.59/0.49/1.00\n"
     ]
    }
   ],
   "source": [
    "def normalize_data(data): \n",
    "    data = data / data.max()\n",
    "    return data\n",
    "\n",
    "X_train = normalize_data(X_train)\n",
    "X_test = normalize_data(X_test)\n",
    "print('Image dataset have shape =', X_train.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train.min(),\n",
    "                        X_train.mean(), X_train.std(), X_train.max()))\n",
    "print('')\n",
    "print('Train label has shape =', y_train.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(y_train.min(),\n",
    "                        y_train.mean(), y_train.std(), y_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data): \n",
    "    for x in data:\n",
    "        x = x/255\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 3)\n",
      "Image dataset has min/mean/std/max = 0.00/0.40/0.20/1.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.59/0.49/1.00\n"
     ]
    }
   ],
   "source": [
    "X_train = normalize_data(X_train)\n",
    "X_test = normalize_data(X_test)\n",
    "X_train_temp = np.asarray(X_train)\n",
    "Y_train_temp = np.asarray(y_train)\n",
    "print('Image dataset have shape =', X_train_temp.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train_temp.min(),\n",
    "                        X_train_temp.mean(), X_train_temp.std(), X_train_temp.max()))\n",
    "print('')\n",
    "print('Train label has shape =', Y_train_temp.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(Y_train_temp.min(),\n",
    "                        Y_train_temp.mean(), Y_train_temp.std(), Y_train_temp.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    " [transforms.ToTensor(),\n",
    " transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "tensor_x = torch.stack([torch.Tensor(i) for i in X_train])\n",
    "tensor_y = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = utils.TensorDataset(tensor_x,tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = utils.DataLoader(trainset,  batch_size= 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x_test = torch.stack([torch.Tensor(i) for i in X_test])\n",
    "tensor_y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = utils.TensorDataset(tensor_x_test,tensor_y_test)\n",
    "testloader = utils.DataLoader(testset,  batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "classes = ('Positive', 'Negative')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 32, 32, 3])\n",
      "torch.Size([40, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "images = images.permute(0, 3, 1, 2)\n",
    "print(images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "rows = 1\n",
    "columns = 1\n",
    "fig=plt.figure()\n",
    "for i in range(1):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    img = images[i]\n",
    "    img = torchvision.transforms.ToPILImage()(img)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkernal size 3*3\\nstep size = 1\\nmaximum pooled layer of 2*2\\nstep size = 2\\nlearning rate = 0.0001\\nbatch size = 63\\ndropout rate = 0.5\\nk-fold: 5-fold cross validation\\n'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "kernal size 3*3\n",
    "step size = 1\n",
    "maximum pooled layer of 2*2\n",
    "step size = 2\n",
    "learning rate = 0.0001\n",
    "batch size = 63\n",
    "dropout rate = 0.5\n",
    "k-fold: 5-fold cross validation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1280, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(20 * 8 * 8, 100)\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 20 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:     9] avg mini-batch loss: 0.695\n",
      "[epoch: 0, i:    19] avg mini-batch loss: 0.664\n",
      "[epoch: 0, i:    29] avg mini-batch loss: 0.695\n",
      "[epoch: 1, i:     9] avg mini-batch loss: 0.688\n",
      "[epoch: 1, i:    19] avg mini-batch loss: 0.672\n",
      "[epoch: 1, i:    29] avg mini-batch loss: 0.687\n",
      "[epoch: 2, i:     9] avg mini-batch loss: 0.690\n",
      "[epoch: 2, i:    19] avg mini-batch loss: 0.666\n",
      "[epoch: 2, i:    29] avg mini-batch loss: 0.687\n",
      "[epoch: 3, i:     9] avg mini-batch loss: 0.689\n",
      "[epoch: 3, i:    19] avg mini-batch loss: 0.667\n",
      "[epoch: 3, i:    29] avg mini-batch loss: 0.686\n",
      "[epoch: 4, i:     9] avg mini-batch loss: 0.689\n",
      "[epoch: 4, i:    19] avg mini-batch loss: 0.666\n",
      "[epoch: 4, i:    29] avg mini-batch loss: 0.686\n",
      "[epoch: 5, i:     9] avg mini-batch loss: 0.689\n",
      "[epoch: 5, i:    19] avg mini-batch loss: 0.666\n",
      "[epoch: 5, i:    29] avg mini-batch loss: 0.686\n",
      "[epoch: 6, i:     9] avg mini-batch loss: 0.689\n",
      "[epoch: 6, i:    19] avg mini-batch loss: 0.665\n",
      "[epoch: 6, i:    29] avg mini-batch loss: 0.687\n",
      "[epoch: 7, i:     9] avg mini-batch loss: 0.688\n",
      "[epoch: 7, i:    19] avg mini-batch loss: 0.666\n",
      "[epoch: 7, i:    29] avg mini-batch loss: 0.685\n",
      "[epoch: 8, i:     9] avg mini-batch loss: 0.688\n",
      "[epoch: 8, i:    19] avg mini-batch loss: 0.664\n",
      "[epoch: 8, i:    29] avg mini-batch loss: 0.686\n",
      "[epoch: 9, i:     9] avg mini-batch loss: 0.687\n",
      "[epoch: 9, i:    19] avg mini-batch loss: 0.665\n",
      "[epoch: 9, i:    29] avg mini-batch loss: 0.684\n",
      "[epoch: 10, i:     9] avg mini-batch loss: 0.687\n",
      "[epoch: 10, i:    19] avg mini-batch loss: 0.663\n",
      "[epoch: 10, i:    29] avg mini-batch loss: 0.684\n",
      "[epoch: 11, i:     9] avg mini-batch loss: 0.686\n",
      "[epoch: 11, i:    19] avg mini-batch loss: 0.663\n",
      "[epoch: 11, i:    29] avg mini-batch loss: 0.682\n",
      "[epoch: 12, i:     9] avg mini-batch loss: 0.685\n",
      "[epoch: 12, i:    19] avg mini-batch loss: 0.662\n",
      "[epoch: 12, i:    29] avg mini-batch loss: 0.683\n",
      "[epoch: 13, i:     9] avg mini-batch loss: 0.683\n",
      "[epoch: 13, i:    19] avg mini-batch loss: 0.661\n",
      "[epoch: 13, i:    29] avg mini-batch loss: 0.681\n",
      "[epoch: 14, i:     9] avg mini-batch loss: 0.682\n",
      "[epoch: 14, i:    19] avg mini-batch loss: 0.660\n",
      "[epoch: 14, i:    29] avg mini-batch loss: 0.682\n",
      "[epoch: 15, i:     9] avg mini-batch loss: 0.680\n",
      "[epoch: 15, i:    19] avg mini-batch loss: 0.659\n",
      "[epoch: 15, i:    29] avg mini-batch loss: 0.680\n",
      "[epoch: 16, i:     9] avg mini-batch loss: 0.678\n",
      "[epoch: 16, i:    19] avg mini-batch loss: 0.657\n",
      "[epoch: 16, i:    29] avg mini-batch loss: 0.681\n",
      "[epoch: 17, i:     9] avg mini-batch loss: 0.674\n",
      "[epoch: 17, i:    19] avg mini-batch loss: 0.654\n",
      "[epoch: 17, i:    29] avg mini-batch loss: 0.677\n",
      "[epoch: 18, i:     9] avg mini-batch loss: 0.671\n",
      "[epoch: 18, i:    19] avg mini-batch loss: 0.648\n",
      "[epoch: 18, i:    29] avg mini-batch loss: 0.677\n",
      "[epoch: 19, i:     9] avg mini-batch loss: 0.670\n",
      "[epoch: 19, i:    19] avg mini-batch loss: 0.647\n",
      "[epoch: 19, i:    29] avg mini-batch loss: 0.674\n",
      "[epoch: 20, i:     9] avg mini-batch loss: 0.667\n",
      "[epoch: 20, i:    19] avg mini-batch loss: 0.642\n",
      "[epoch: 20, i:    29] avg mini-batch loss: 0.669\n",
      "[epoch: 21, i:     9] avg mini-batch loss: 0.665\n",
      "[epoch: 21, i:    19] avg mini-batch loss: 0.637\n",
      "[epoch: 21, i:    29] avg mini-batch loss: 0.666\n",
      "[epoch: 22, i:     9] avg mini-batch loss: 0.662\n",
      "[epoch: 22, i:    19] avg mini-batch loss: 0.634\n",
      "[epoch: 22, i:    29] avg mini-batch loss: 0.662\n",
      "[epoch: 23, i:     9] avg mini-batch loss: 0.663\n",
      "[epoch: 23, i:    19] avg mini-batch loss: 0.628\n",
      "[epoch: 23, i:    29] avg mini-batch loss: 0.654\n",
      "[epoch: 24, i:     9] avg mini-batch loss: 0.656\n",
      "[epoch: 24, i:    19] avg mini-batch loss: 0.623\n",
      "[epoch: 24, i:    29] avg mini-batch loss: 0.654\n",
      "[epoch: 25, i:     9] avg mini-batch loss: 0.655\n",
      "[epoch: 25, i:    19] avg mini-batch loss: 0.623\n",
      "[epoch: 25, i:    29] avg mini-batch loss: 0.644\n",
      "[epoch: 26, i:     9] avg mini-batch loss: 0.650\n",
      "[epoch: 26, i:    19] avg mini-batch loss: 0.612\n",
      "[epoch: 26, i:    29] avg mini-batch loss: 0.635\n",
      "[epoch: 27, i:     9] avg mini-batch loss: 0.642\n",
      "[epoch: 27, i:    19] avg mini-batch loss: 0.606\n",
      "[epoch: 27, i:    29] avg mini-batch loss: 0.628\n",
      "[epoch: 28, i:     9] avg mini-batch loss: 0.639\n",
      "[epoch: 28, i:    19] avg mini-batch loss: 0.600\n",
      "[epoch: 28, i:    29] avg mini-batch loss: 0.621\n",
      "[epoch: 29, i:     9] avg mini-batch loss: 0.630\n",
      "[epoch: 29, i:    19] avg mini-batch loss: 0.591\n",
      "[epoch: 29, i:    29] avg mini-batch loss: 0.611\n",
      "[epoch: 30, i:     9] avg mini-batch loss: 0.625\n",
      "[epoch: 30, i:    19] avg mini-batch loss: 0.584\n",
      "[epoch: 30, i:    29] avg mini-batch loss: 0.602\n",
      "[epoch: 31, i:     9] avg mini-batch loss: 0.618\n",
      "[epoch: 31, i:    19] avg mini-batch loss: 0.577\n",
      "[epoch: 31, i:    29] avg mini-batch loss: 0.595\n",
      "[epoch: 32, i:     9] avg mini-batch loss: 0.608\n",
      "[epoch: 32, i:    19] avg mini-batch loss: 0.568\n",
      "[epoch: 32, i:    29] avg mini-batch loss: 0.584\n",
      "[epoch: 33, i:     9] avg mini-batch loss: 0.605\n",
      "[epoch: 33, i:    19] avg mini-batch loss: 0.561\n",
      "[epoch: 33, i:    29] avg mini-batch loss: 0.577\n",
      "[epoch: 34, i:     9] avg mini-batch loss: 0.596\n",
      "[epoch: 34, i:    19] avg mini-batch loss: 0.553\n",
      "[epoch: 34, i:    29] avg mini-batch loss: 0.569\n",
      "[epoch: 35, i:     9] avg mini-batch loss: 0.588\n",
      "[epoch: 35, i:    19] avg mini-batch loss: 0.545\n",
      "[epoch: 35, i:    29] avg mini-batch loss: 0.559\n",
      "[epoch: 36, i:     9] avg mini-batch loss: 0.579\n",
      "[epoch: 36, i:    19] avg mini-batch loss: 0.536\n",
      "[epoch: 36, i:    29] avg mini-batch loss: 0.551\n",
      "[epoch: 37, i:     9] avg mini-batch loss: 0.573\n",
      "[epoch: 37, i:    19] avg mini-batch loss: 0.530\n",
      "[epoch: 37, i:    29] avg mini-batch loss: 0.545\n",
      "[epoch: 38, i:     9] avg mini-batch loss: 0.566\n",
      "[epoch: 38, i:    19] avg mini-batch loss: 0.522\n",
      "[epoch: 38, i:    29] avg mini-batch loss: 0.535\n",
      "[epoch: 39, i:     9] avg mini-batch loss: 0.556\n",
      "[epoch: 39, i:    19] avg mini-batch loss: 0.515\n",
      "[epoch: 39, i:    29] avg mini-batch loss: 0.525\n",
      "[epoch: 40, i:     9] avg mini-batch loss: 0.547\n",
      "[epoch: 40, i:    19] avg mini-batch loss: 0.506\n",
      "[epoch: 40, i:    29] avg mini-batch loss: 0.516\n",
      "[epoch: 41, i:     9] avg mini-batch loss: 0.536\n",
      "[epoch: 41, i:    19] avg mini-batch loss: 0.499\n",
      "[epoch: 41, i:    29] avg mini-batch loss: 0.505\n",
      "[epoch: 42, i:     9] avg mini-batch loss: 0.526\n",
      "[epoch: 42, i:    19] avg mini-batch loss: 0.489\n",
      "[epoch: 42, i:    29] avg mini-batch loss: 0.492\n",
      "[epoch: 43, i:     9] avg mini-batch loss: 0.516\n",
      "[epoch: 43, i:    19] avg mini-batch loss: 0.480\n",
      "[epoch: 43, i:    29] avg mini-batch loss: 0.481\n",
      "[epoch: 44, i:     9] avg mini-batch loss: 0.507\n",
      "[epoch: 44, i:    19] avg mini-batch loss: 0.470\n",
      "[epoch: 44, i:    29] avg mini-batch loss: 0.471\n",
      "[epoch: 45, i:     9] avg mini-batch loss: 0.498\n",
      "[epoch: 45, i:    19] avg mini-batch loss: 0.458\n",
      "[epoch: 45, i:    29] avg mini-batch loss: 0.461\n",
      "[epoch: 46, i:     9] avg mini-batch loss: 0.487\n",
      "[epoch: 46, i:    19] avg mini-batch loss: 0.448\n",
      "[epoch: 46, i:    29] avg mini-batch loss: 0.448\n",
      "[epoch: 47, i:     9] avg mini-batch loss: 0.476\n",
      "[epoch: 47, i:    19] avg mini-batch loss: 0.439\n",
      "[epoch: 47, i:    29] avg mini-batch loss: 0.439\n",
      "[epoch: 48, i:     9] avg mini-batch loss: 0.467\n",
      "[epoch: 48, i:    19] avg mini-batch loss: 0.429\n",
      "[epoch: 48, i:    29] avg mini-batch loss: 0.427\n",
      "[epoch: 49, i:     9] avg mini-batch loss: 0.459\n",
      "[epoch: 49, i:    19] avg mini-batch loss: 0.419\n",
      "[epoch: 49, i:    29] avg mini-batch loss: 0.414\n",
      "[epoch: 50, i:     9] avg mini-batch loss: 0.447\n",
      "[epoch: 50, i:    19] avg mini-batch loss: 0.408\n",
      "[epoch: 50, i:    29] avg mini-batch loss: 0.402\n",
      "[epoch: 51, i:     9] avg mini-batch loss: 0.437\n",
      "[epoch: 51, i:    19] avg mini-batch loss: 0.400\n",
      "[epoch: 51, i:    29] avg mini-batch loss: 0.390\n",
      "[epoch: 52, i:     9] avg mini-batch loss: 0.429\n",
      "[epoch: 52, i:    19] avg mini-batch loss: 0.387\n",
      "[epoch: 52, i:    29] avg mini-batch loss: 0.381\n",
      "[epoch: 53, i:     9] avg mini-batch loss: 0.420\n",
      "[epoch: 53, i:    19] avg mini-batch loss: 0.377\n",
      "[epoch: 53, i:    29] avg mini-batch loss: 0.374\n",
      "[epoch: 54, i:     9] avg mini-batch loss: 0.414\n",
      "[epoch: 54, i:    19] avg mini-batch loss: 0.368\n",
      "[epoch: 54, i:    29] avg mini-batch loss: 0.370\n",
      "[epoch: 55, i:     9] avg mini-batch loss: 0.409\n",
      "[epoch: 55, i:    19] avg mini-batch loss: 0.361\n",
      "[epoch: 55, i:    29] avg mini-batch loss: 0.360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 56, i:     9] avg mini-batch loss: 0.393\n",
      "[epoch: 56, i:    19] avg mini-batch loss: 0.351\n",
      "[epoch: 56, i:    29] avg mini-batch loss: 0.352\n",
      "[epoch: 57, i:     9] avg mini-batch loss: 0.383\n",
      "[epoch: 57, i:    19] avg mini-batch loss: 0.343\n",
      "[epoch: 57, i:    29] avg mini-batch loss: 0.342\n",
      "[epoch: 58, i:     9] avg mini-batch loss: 0.372\n",
      "[epoch: 58, i:    19] avg mini-batch loss: 0.334\n",
      "[epoch: 58, i:    29] avg mini-batch loss: 0.333\n",
      "[epoch: 59, i:     9] avg mini-batch loss: 0.362\n",
      "[epoch: 59, i:    19] avg mini-batch loss: 0.324\n",
      "[epoch: 59, i:    29] avg mini-batch loss: 0.325\n",
      "[epoch: 60, i:     9] avg mini-batch loss: 0.359\n",
      "[epoch: 60, i:    19] avg mini-batch loss: 0.316\n",
      "[epoch: 60, i:    29] avg mini-batch loss: 0.317\n",
      "[epoch: 61, i:     9] avg mini-batch loss: 0.352\n",
      "[epoch: 61, i:    19] avg mini-batch loss: 0.308\n",
      "[epoch: 61, i:    29] avg mini-batch loss: 0.311\n",
      "[epoch: 62, i:     9] avg mini-batch loss: 0.348\n",
      "[epoch: 62, i:    19] avg mini-batch loss: 0.303\n",
      "[epoch: 62, i:    29] avg mini-batch loss: 0.309\n",
      "[epoch: 63, i:     9] avg mini-batch loss: 0.341\n",
      "[epoch: 63, i:    19] avg mini-batch loss: 0.298\n",
      "[epoch: 63, i:    29] avg mini-batch loss: 0.307\n",
      "[epoch: 64, i:     9] avg mini-batch loss: 0.337\n",
      "[epoch: 64, i:    19] avg mini-batch loss: 0.294\n",
      "[epoch: 64, i:    29] avg mini-batch loss: 0.301\n",
      "[epoch: 65, i:     9] avg mini-batch loss: 0.326\n",
      "[epoch: 65, i:    19] avg mini-batch loss: 0.286\n",
      "[epoch: 65, i:    29] avg mini-batch loss: 0.292\n",
      "[epoch: 66, i:     9] avg mini-batch loss: 0.316\n",
      "[epoch: 66, i:    19] avg mini-batch loss: 0.278\n",
      "[epoch: 66, i:    29] avg mini-batch loss: 0.281\n",
      "[epoch: 67, i:     9] avg mini-batch loss: 0.307\n",
      "[epoch: 67, i:    19] avg mini-batch loss: 0.268\n",
      "[epoch: 67, i:    29] avg mini-batch loss: 0.264\n",
      "[epoch: 68, i:     9] avg mini-batch loss: 0.297\n",
      "[epoch: 68, i:    19] avg mini-batch loss: 0.260\n",
      "[epoch: 68, i:    29] avg mini-batch loss: 0.252\n",
      "[epoch: 69, i:     9] avg mini-batch loss: 0.289\n",
      "[epoch: 69, i:    19] avg mini-batch loss: 0.251\n",
      "[epoch: 69, i:    29] avg mini-batch loss: 0.242\n",
      "[epoch: 70, i:     9] avg mini-batch loss: 0.281\n",
      "[epoch: 70, i:    19] avg mini-batch loss: 0.244\n",
      "[epoch: 70, i:    29] avg mini-batch loss: 0.234\n",
      "[epoch: 71, i:     9] avg mini-batch loss: 0.272\n",
      "[epoch: 71, i:    19] avg mini-batch loss: 0.239\n",
      "[epoch: 71, i:    29] avg mini-batch loss: 0.225\n",
      "[epoch: 72, i:     9] avg mini-batch loss: 0.263\n",
      "[epoch: 72, i:    19] avg mini-batch loss: 0.231\n",
      "[epoch: 72, i:    29] avg mini-batch loss: 0.213\n",
      "[epoch: 73, i:     9] avg mini-batch loss: 0.255\n",
      "[epoch: 73, i:    19] avg mini-batch loss: 0.224\n",
      "[epoch: 73, i:    29] avg mini-batch loss: 0.206\n",
      "[epoch: 74, i:     9] avg mini-batch loss: 0.248\n",
      "[epoch: 74, i:    19] avg mini-batch loss: 0.219\n",
      "[epoch: 74, i:    29] avg mini-batch loss: 0.201\n",
      "[epoch: 75, i:     9] avg mini-batch loss: 0.241\n",
      "[epoch: 75, i:    19] avg mini-batch loss: 0.211\n",
      "[epoch: 75, i:    29] avg mini-batch loss: 0.191\n",
      "[epoch: 76, i:     9] avg mini-batch loss: 0.236\n",
      "[epoch: 76, i:    19] avg mini-batch loss: 0.205\n",
      "[epoch: 76, i:    29] avg mini-batch loss: 0.184\n",
      "[epoch: 77, i:     9] avg mini-batch loss: 0.232\n",
      "[epoch: 77, i:    19] avg mini-batch loss: 0.201\n",
      "[epoch: 77, i:    29] avg mini-batch loss: 0.178\n",
      "[epoch: 78, i:     9] avg mini-batch loss: 0.227\n",
      "[epoch: 78, i:    19] avg mini-batch loss: 0.195\n",
      "[epoch: 78, i:    29] avg mini-batch loss: 0.174\n",
      "[epoch: 79, i:     9] avg mini-batch loss: 0.220\n",
      "[epoch: 79, i:    19] avg mini-batch loss: 0.192\n",
      "[epoch: 79, i:    29] avg mini-batch loss: 0.167\n",
      "[epoch: 80, i:     9] avg mini-batch loss: 0.210\n",
      "[epoch: 80, i:    19] avg mini-batch loss: 0.186\n",
      "[epoch: 80, i:    29] avg mini-batch loss: 0.159\n",
      "[epoch: 81, i:     9] avg mini-batch loss: 0.204\n",
      "[epoch: 81, i:    19] avg mini-batch loss: 0.184\n",
      "[epoch: 81, i:    29] avg mini-batch loss: 0.150\n",
      "[epoch: 82, i:     9] avg mini-batch loss: 0.196\n",
      "[epoch: 82, i:    19] avg mini-batch loss: 0.177\n",
      "[epoch: 82, i:    29] avg mini-batch loss: 0.142\n",
      "[epoch: 83, i:     9] avg mini-batch loss: 0.189\n",
      "[epoch: 83, i:    19] avg mini-batch loss: 0.172\n",
      "[epoch: 83, i:    29] avg mini-batch loss: 0.135\n",
      "[epoch: 84, i:     9] avg mini-batch loss: 0.183\n",
      "[epoch: 84, i:    19] avg mini-batch loss: 0.167\n",
      "[epoch: 84, i:    29] avg mini-batch loss: 0.128\n",
      "[epoch: 85, i:     9] avg mini-batch loss: 0.175\n",
      "[epoch: 85, i:    19] avg mini-batch loss: 0.162\n",
      "[epoch: 85, i:    29] avg mini-batch loss: 0.122\n",
      "[epoch: 86, i:     9] avg mini-batch loss: 0.168\n",
      "[epoch: 86, i:    19] avg mini-batch loss: 0.158\n",
      "[epoch: 86, i:    29] avg mini-batch loss: 0.119\n",
      "[epoch: 87, i:     9] avg mini-batch loss: 0.160\n",
      "[epoch: 87, i:    19] avg mini-batch loss: 0.154\n",
      "[epoch: 87, i:    29] avg mini-batch loss: 0.115\n",
      "[epoch: 88, i:     9] avg mini-batch loss: 0.155\n",
      "[epoch: 88, i:    19] avg mini-batch loss: 0.151\n",
      "[epoch: 88, i:    29] avg mini-batch loss: 0.112\n",
      "[epoch: 89, i:     9] avg mini-batch loss: 0.149\n",
      "[epoch: 89, i:    19] avg mini-batch loss: 0.147\n",
      "[epoch: 89, i:    29] avg mini-batch loss: 0.110\n",
      "[epoch: 90, i:     9] avg mini-batch loss: 0.144\n",
      "[epoch: 90, i:    19] avg mini-batch loss: 0.142\n",
      "[epoch: 90, i:    29] avg mini-batch loss: 0.109\n",
      "[epoch: 91, i:     9] avg mini-batch loss: 0.138\n",
      "[epoch: 91, i:    19] avg mini-batch loss: 0.135\n",
      "[epoch: 91, i:    29] avg mini-batch loss: 0.107\n",
      "[epoch: 92, i:     9] avg mini-batch loss: 0.133\n",
      "[epoch: 92, i:    19] avg mini-batch loss: 0.128\n",
      "[epoch: 92, i:    29] avg mini-batch loss: 0.108\n",
      "[epoch: 93, i:     9] avg mini-batch loss: 0.131\n",
      "[epoch: 93, i:    19] avg mini-batch loss: 0.121\n",
      "[epoch: 93, i:    29] avg mini-batch loss: 0.107\n",
      "[epoch: 94, i:     9] avg mini-batch loss: 0.129\n",
      "[epoch: 94, i:    19] avg mini-batch loss: 0.113\n",
      "[epoch: 94, i:    29] avg mini-batch loss: 0.106\n",
      "[epoch: 95, i:     9] avg mini-batch loss: 0.128\n",
      "[epoch: 95, i:    19] avg mini-batch loss: 0.106\n",
      "[epoch: 95, i:    29] avg mini-batch loss: 0.105\n",
      "[epoch: 96, i:     9] avg mini-batch loss: 0.130\n",
      "[epoch: 96, i:    19] avg mini-batch loss: 0.103\n",
      "[epoch: 96, i:    29] avg mini-batch loss: 0.103\n",
      "[epoch: 97, i:     9] avg mini-batch loss: 0.130\n",
      "[epoch: 97, i:    19] avg mini-batch loss: 0.100\n",
      "[epoch: 97, i:    29] avg mini-batch loss: 0.102\n",
      "[epoch: 98, i:     9] avg mini-batch loss: 0.132\n",
      "[epoch: 98, i:    19] avg mini-batch loss: 0.099\n",
      "[epoch: 98, i:    29] avg mini-batch loss: 0.102\n",
      "[epoch: 99, i:     9] avg mini-batch loss: 0.130\n",
      "[epoch: 99, i:    19] avg mini-batch loss: 0.097\n",
      "[epoch: 99, i:    29] avg mini-batch loss: 0.100\n",
      "[epoch: 100, i:     9] avg mini-batch loss: 0.123\n",
      "[epoch: 100, i:    19] avg mini-batch loss: 0.092\n",
      "[epoch: 100, i:    29] avg mini-batch loss: 0.092\n",
      "[epoch: 101, i:     9] avg mini-batch loss: 0.114\n",
      "[epoch: 101, i:    19] avg mini-batch loss: 0.088\n",
      "[epoch: 101, i:    29] avg mini-batch loss: 0.083\n",
      "[epoch: 102, i:     9] avg mini-batch loss: 0.106\n",
      "[epoch: 102, i:    19] avg mini-batch loss: 0.085\n",
      "[epoch: 102, i:    29] avg mini-batch loss: 0.074\n",
      "[epoch: 103, i:     9] avg mini-batch loss: 0.103\n",
      "[epoch: 103, i:    19] avg mini-batch loss: 0.084\n",
      "[epoch: 103, i:    29] avg mini-batch loss: 0.067\n",
      "[epoch: 104, i:     9] avg mini-batch loss: 0.100\n",
      "[epoch: 104, i:    19] avg mini-batch loss: 0.080\n",
      "[epoch: 104, i:    29] avg mini-batch loss: 0.061\n",
      "[epoch: 105, i:     9] avg mini-batch loss: 0.098\n",
      "[epoch: 105, i:    19] avg mini-batch loss: 0.077\n",
      "[epoch: 105, i:    29] avg mini-batch loss: 0.057\n",
      "[epoch: 106, i:     9] avg mini-batch loss: 0.094\n",
      "[epoch: 106, i:    19] avg mini-batch loss: 0.076\n",
      "[epoch: 106, i:    29] avg mini-batch loss: 0.055\n",
      "[epoch: 107, i:     9] avg mini-batch loss: 0.090\n",
      "[epoch: 107, i:    19] avg mini-batch loss: 0.076\n",
      "[epoch: 107, i:    29] avg mini-batch loss: 0.051\n",
      "[epoch: 108, i:     9] avg mini-batch loss: 0.083\n",
      "[epoch: 108, i:    19] avg mini-batch loss: 0.073\n",
      "[epoch: 108, i:    29] avg mini-batch loss: 0.049\n",
      "[epoch: 109, i:     9] avg mini-batch loss: 0.078\n",
      "[epoch: 109, i:    19] avg mini-batch loss: 0.067\n",
      "[epoch: 109, i:    29] avg mini-batch loss: 0.048\n",
      "[epoch: 110, i:     9] avg mini-batch loss: 0.074\n",
      "[epoch: 110, i:    19] avg mini-batch loss: 0.062\n",
      "[epoch: 110, i:    29] avg mini-batch loss: 0.048\n",
      "[epoch: 111, i:     9] avg mini-batch loss: 0.070\n",
      "[epoch: 111, i:    19] avg mini-batch loss: 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 111, i:    29] avg mini-batch loss: 0.047\n",
      "[epoch: 112, i:     9] avg mini-batch loss: 0.069\n",
      "[epoch: 112, i:    19] avg mini-batch loss: 0.054\n",
      "[epoch: 112, i:    29] avg mini-batch loss: 0.045\n",
      "[epoch: 113, i:     9] avg mini-batch loss: 0.067\n",
      "[epoch: 113, i:    19] avg mini-batch loss: 0.051\n",
      "[epoch: 113, i:    29] avg mini-batch loss: 0.043\n",
      "[epoch: 114, i:     9] avg mini-batch loss: 0.066\n",
      "[epoch: 114, i:    19] avg mini-batch loss: 0.049\n",
      "[epoch: 114, i:    29] avg mini-batch loss: 0.041\n",
      "[epoch: 115, i:     9] avg mini-batch loss: 0.064\n",
      "[epoch: 115, i:    19] avg mini-batch loss: 0.047\n",
      "[epoch: 115, i:    29] avg mini-batch loss: 0.040\n",
      "[epoch: 116, i:     9] avg mini-batch loss: 0.061\n",
      "[epoch: 116, i:    19] avg mini-batch loss: 0.045\n",
      "[epoch: 116, i:    29] avg mini-batch loss: 0.038\n",
      "[epoch: 117, i:     9] avg mini-batch loss: 0.060\n",
      "[epoch: 117, i:    19] avg mini-batch loss: 0.044\n",
      "[epoch: 117, i:    29] avg mini-batch loss: 0.036\n",
      "[epoch: 118, i:     9] avg mini-batch loss: 0.058\n",
      "[epoch: 118, i:    19] avg mini-batch loss: 0.042\n",
      "[epoch: 118, i:    29] avg mini-batch loss: 0.035\n",
      "[epoch: 119, i:     9] avg mini-batch loss: 0.056\n",
      "[epoch: 119, i:    19] avg mini-batch loss: 0.041\n",
      "[epoch: 119, i:    29] avg mini-batch loss: 0.033\n",
      "[epoch: 120, i:     9] avg mini-batch loss: 0.054\n",
      "[epoch: 120, i:    19] avg mini-batch loss: 0.040\n",
      "[epoch: 120, i:    29] avg mini-batch loss: 0.032\n",
      "[epoch: 121, i:     9] avg mini-batch loss: 0.053\n",
      "[epoch: 121, i:    19] avg mini-batch loss: 0.039\n",
      "[epoch: 121, i:    29] avg mini-batch loss: 0.030\n",
      "[epoch: 122, i:     9] avg mini-batch loss: 0.051\n",
      "[epoch: 122, i:    19] avg mini-batch loss: 0.038\n",
      "[epoch: 122, i:    29] avg mini-batch loss: 0.030\n",
      "[epoch: 123, i:     9] avg mini-batch loss: 0.050\n",
      "[epoch: 123, i:    19] avg mini-batch loss: 0.037\n",
      "[epoch: 123, i:    29] avg mini-batch loss: 0.029\n",
      "[epoch: 124, i:     9] avg mini-batch loss: 0.048\n",
      "[epoch: 124, i:    19] avg mini-batch loss: 0.037\n",
      "[epoch: 124, i:    29] avg mini-batch loss: 0.027\n",
      "[epoch: 125, i:     9] avg mini-batch loss: 0.047\n",
      "[epoch: 125, i:    19] avg mini-batch loss: 0.036\n",
      "[epoch: 125, i:    29] avg mini-batch loss: 0.027\n",
      "[epoch: 126, i:     9] avg mini-batch loss: 0.046\n",
      "[epoch: 126, i:    19] avg mini-batch loss: 0.034\n",
      "[epoch: 126, i:    29] avg mini-batch loss: 0.026\n",
      "[epoch: 127, i:     9] avg mini-batch loss: 0.044\n",
      "[epoch: 127, i:    19] avg mini-batch loss: 0.033\n",
      "[epoch: 127, i:    29] avg mini-batch loss: 0.025\n",
      "[epoch: 128, i:     9] avg mini-batch loss: 0.043\n",
      "[epoch: 128, i:    19] avg mini-batch loss: 0.032\n",
      "[epoch: 128, i:    29] avg mini-batch loss: 0.024\n",
      "[epoch: 129, i:     9] avg mini-batch loss: 0.042\n",
      "[epoch: 129, i:    19] avg mini-batch loss: 0.031\n",
      "[epoch: 129, i:    29] avg mini-batch loss: 0.024\n",
      "[epoch: 130, i:     9] avg mini-batch loss: 0.041\n",
      "[epoch: 130, i:    19] avg mini-batch loss: 0.030\n",
      "[epoch: 130, i:    29] avg mini-batch loss: 0.023\n",
      "[epoch: 131, i:     9] avg mini-batch loss: 0.040\n",
      "[epoch: 131, i:    19] avg mini-batch loss: 0.029\n",
      "[epoch: 131, i:    29] avg mini-batch loss: 0.023\n",
      "[epoch: 132, i:     9] avg mini-batch loss: 0.039\n",
      "[epoch: 132, i:    19] avg mini-batch loss: 0.028\n",
      "[epoch: 132, i:    29] avg mini-batch loss: 0.022\n",
      "[epoch: 133, i:     9] avg mini-batch loss: 0.038\n",
      "[epoch: 133, i:    19] avg mini-batch loss: 0.027\n",
      "[epoch: 133, i:    29] avg mini-batch loss: 0.021\n",
      "[epoch: 134, i:     9] avg mini-batch loss: 0.037\n",
      "[epoch: 134, i:    19] avg mini-batch loss: 0.027\n",
      "[epoch: 134, i:    29] avg mini-batch loss: 0.021\n",
      "[epoch: 135, i:     9] avg mini-batch loss: 0.036\n",
      "[epoch: 135, i:    19] avg mini-batch loss: 0.026\n",
      "[epoch: 135, i:    29] avg mini-batch loss: 0.020\n",
      "[epoch: 136, i:     9] avg mini-batch loss: 0.035\n",
      "[epoch: 136, i:    19] avg mini-batch loss: 0.025\n",
      "[epoch: 136, i:    29] avg mini-batch loss: 0.020\n",
      "[epoch: 137, i:     9] avg mini-batch loss: 0.034\n",
      "[epoch: 137, i:    19] avg mini-batch loss: 0.025\n",
      "[epoch: 137, i:    29] avg mini-batch loss: 0.019\n",
      "[epoch: 138, i:     9] avg mini-batch loss: 0.033\n",
      "[epoch: 138, i:    19] avg mini-batch loss: 0.025\n",
      "[epoch: 138, i:    29] avg mini-batch loss: 0.019\n",
      "[epoch: 139, i:     9] avg mini-batch loss: 0.033\n",
      "[epoch: 139, i:    19] avg mini-batch loss: 0.025\n",
      "[epoch: 139, i:    29] avg mini-batch loss: 0.019\n",
      "[epoch: 140, i:     9] avg mini-batch loss: 0.032\n",
      "[epoch: 140, i:    19] avg mini-batch loss: 0.025\n",
      "[epoch: 140, i:    29] avg mini-batch loss: 0.018\n",
      "[epoch: 141, i:     9] avg mini-batch loss: 0.032\n",
      "[epoch: 141, i:    19] avg mini-batch loss: 0.024\n",
      "[epoch: 141, i:    29] avg mini-batch loss: 0.017\n",
      "[epoch: 142, i:     9] avg mini-batch loss: 0.031\n",
      "[epoch: 142, i:    19] avg mini-batch loss: 0.024\n",
      "[epoch: 142, i:    29] avg mini-batch loss: 0.016\n",
      "[epoch: 143, i:     9] avg mini-batch loss: 0.030\n",
      "[epoch: 143, i:    19] avg mini-batch loss: 0.024\n",
      "[epoch: 143, i:    29] avg mini-batch loss: 0.016\n",
      "[epoch: 144, i:     9] avg mini-batch loss: 0.029\n",
      "[epoch: 144, i:    19] avg mini-batch loss: 0.024\n",
      "[epoch: 144, i:    29] avg mini-batch loss: 0.017\n",
      "[epoch: 145, i:     9] avg mini-batch loss: 0.027\n",
      "[epoch: 145, i:    19] avg mini-batch loss: 0.023\n",
      "[epoch: 145, i:    29] avg mini-batch loss: 0.017\n",
      "[epoch: 146, i:     9] avg mini-batch loss: 0.026\n",
      "[epoch: 146, i:    19] avg mini-batch loss: 0.022\n",
      "[epoch: 146, i:    29] avg mini-batch loss: 0.018\n",
      "[epoch: 147, i:     9] avg mini-batch loss: 0.026\n",
      "[epoch: 147, i:    19] avg mini-batch loss: 0.021\n",
      "[epoch: 147, i:    29] avg mini-batch loss: 0.018\n",
      "[epoch: 148, i:     9] avg mini-batch loss: 0.025\n",
      "[epoch: 148, i:    19] avg mini-batch loss: 0.020\n",
      "[epoch: 148, i:    29] avg mini-batch loss: 0.017\n",
      "[epoch: 149, i:     9] avg mini-batch loss: 0.025\n",
      "[epoch: 149, i:    19] avg mini-batch loss: 0.020\n",
      "[epoch: 149, i:    29] avg mini-batch loss: 0.017\n",
      "[epoch: 150, i:     9] avg mini-batch loss: 0.025\n",
      "[epoch: 150, i:    19] avg mini-batch loss: 0.019\n",
      "[epoch: 150, i:    29] avg mini-batch loss: 0.016\n",
      "[epoch: 151, i:     9] avg mini-batch loss: 0.025\n",
      "[epoch: 151, i:    19] avg mini-batch loss: 0.019\n",
      "[epoch: 151, i:    29] avg mini-batch loss: 0.015\n",
      "[epoch: 152, i:     9] avg mini-batch loss: 0.025\n",
      "[epoch: 152, i:    19] avg mini-batch loss: 0.019\n",
      "[epoch: 152, i:    29] avg mini-batch loss: 0.015\n",
      "[epoch: 153, i:     9] avg mini-batch loss: 0.024\n",
      "[epoch: 153, i:    19] avg mini-batch loss: 0.018\n",
      "[epoch: 153, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 154, i:     9] avg mini-batch loss: 0.024\n",
      "[epoch: 154, i:    19] avg mini-batch loss: 0.018\n",
      "[epoch: 154, i:    29] avg mini-batch loss: 0.013\n",
      "[epoch: 155, i:     9] avg mini-batch loss: 0.023\n",
      "[epoch: 155, i:    19] avg mini-batch loss: 0.017\n",
      "[epoch: 155, i:    29] avg mini-batch loss: 0.013\n",
      "[epoch: 156, i:     9] avg mini-batch loss: 0.023\n",
      "[epoch: 156, i:    19] avg mini-batch loss: 0.017\n",
      "[epoch: 156, i:    29] avg mini-batch loss: 0.013\n",
      "[epoch: 157, i:     9] avg mini-batch loss: 0.021\n",
      "[epoch: 157, i:    19] avg mini-batch loss: 0.017\n",
      "[epoch: 157, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 158, i:     9] avg mini-batch loss: 0.020\n",
      "[epoch: 158, i:    19] avg mini-batch loss: 0.017\n",
      "[epoch: 158, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 159, i:     9] avg mini-batch loss: 0.020\n",
      "[epoch: 159, i:    19] avg mini-batch loss: 0.016\n",
      "[epoch: 159, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 160, i:     9] avg mini-batch loss: 0.019\n",
      "[epoch: 160, i:    19] avg mini-batch loss: 0.015\n",
      "[epoch: 160, i:    29] avg mini-batch loss: 0.013\n",
      "[epoch: 161, i:     9] avg mini-batch loss: 0.019\n",
      "[epoch: 161, i:    19] avg mini-batch loss: 0.015\n",
      "[epoch: 161, i:    29] avg mini-batch loss: 0.013\n",
      "[epoch: 162, i:     9] avg mini-batch loss: 0.019\n",
      "[epoch: 162, i:    19] avg mini-batch loss: 0.016\n",
      "[epoch: 162, i:    29] avg mini-batch loss: 0.013\n",
      "[epoch: 163, i:     9] avg mini-batch loss: 0.019\n",
      "[epoch: 163, i:    19] avg mini-batch loss: 0.016\n",
      "[epoch: 163, i:    29] avg mini-batch loss: 0.013\n",
      "[epoch: 164, i:     9] avg mini-batch loss: 0.017\n",
      "[epoch: 164, i:    19] avg mini-batch loss: 0.017\n",
      "[epoch: 164, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 165, i:     9] avg mini-batch loss: 0.017\n",
      "[epoch: 165, i:    19] avg mini-batch loss: 0.017\n",
      "[epoch: 165, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 166, i:     9] avg mini-batch loss: 0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 166, i:    19] avg mini-batch loss: 0.016\n",
      "[epoch: 166, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 167, i:     9] avg mini-batch loss: 0.016\n",
      "[epoch: 167, i:    19] avg mini-batch loss: 0.015\n",
      "[epoch: 167, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 168, i:     9] avg mini-batch loss: 0.017\n",
      "[epoch: 168, i:    19] avg mini-batch loss: 0.013\n",
      "[epoch: 168, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 169, i:     9] avg mini-batch loss: 0.017\n",
      "[epoch: 169, i:    19] avg mini-batch loss: 0.013\n",
      "[epoch: 169, i:    29] avg mini-batch loss: 0.013\n",
      "[epoch: 170, i:     9] avg mini-batch loss: 0.017\n",
      "[epoch: 170, i:    19] avg mini-batch loss: 0.013\n",
      "[epoch: 170, i:    29] avg mini-batch loss: 0.012\n",
      "[epoch: 171, i:     9] avg mini-batch loss: 0.017\n",
      "[epoch: 171, i:    19] avg mini-batch loss: 0.014\n",
      "[epoch: 171, i:    29] avg mini-batch loss: 0.011\n",
      "[epoch: 172, i:     9] avg mini-batch loss: 0.017\n",
      "[epoch: 172, i:    19] avg mini-batch loss: 0.016\n",
      "[epoch: 172, i:    29] avg mini-batch loss: 0.011\n",
      "[epoch: 173, i:     9] avg mini-batch loss: 0.017\n",
      "[epoch: 173, i:    19] avg mini-batch loss: 0.017\n",
      "[epoch: 173, i:    29] avg mini-batch loss: 0.011\n",
      "[epoch: 174, i:     9] avg mini-batch loss: 0.016\n",
      "[epoch: 174, i:    19] avg mini-batch loss: 0.019\n",
      "[epoch: 174, i:    29] avg mini-batch loss: 0.012\n",
      "[epoch: 175, i:     9] avg mini-batch loss: 0.014\n",
      "[epoch: 175, i:    19] avg mini-batch loss: 0.018\n",
      "[epoch: 175, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 176, i:     9] avg mini-batch loss: 0.014\n",
      "[epoch: 176, i:    19] avg mini-batch loss: 0.016\n",
      "[epoch: 176, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 177, i:     9] avg mini-batch loss: 0.014\n",
      "[epoch: 177, i:    19] avg mini-batch loss: 0.014\n",
      "[epoch: 177, i:    29] avg mini-batch loss: 0.015\n",
      "[epoch: 178, i:     9] avg mini-batch loss: 0.015\n",
      "[epoch: 178, i:    19] avg mini-batch loss: 0.013\n",
      "[epoch: 178, i:    29] avg mini-batch loss: 0.016\n",
      "[epoch: 179, i:     9] avg mini-batch loss: 0.015\n",
      "[epoch: 179, i:    19] avg mini-batch loss: 0.012\n",
      "[epoch: 179, i:    29] avg mini-batch loss: 0.016\n",
      "[epoch: 180, i:     9] avg mini-batch loss: 0.016\n",
      "[epoch: 180, i:    19] avg mini-batch loss: 0.015\n",
      "[epoch: 180, i:    29] avg mini-batch loss: 0.013\n",
      "[epoch: 181, i:     9] avg mini-batch loss: 0.021\n",
      "[epoch: 181, i:    19] avg mini-batch loss: 0.019\n",
      "[epoch: 181, i:    29] avg mini-batch loss: 0.012\n",
      "[epoch: 182, i:     9] avg mini-batch loss: 0.026\n",
      "[epoch: 182, i:    19] avg mini-batch loss: 0.018\n",
      "[epoch: 182, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 183, i:     9] avg mini-batch loss: 0.017\n",
      "[epoch: 183, i:    19] avg mini-batch loss: 0.020\n",
      "[epoch: 183, i:    29] avg mini-batch loss: 0.013\n",
      "[epoch: 184, i:     9] avg mini-batch loss: 0.024\n",
      "[epoch: 184, i:    19] avg mini-batch loss: 0.014\n",
      "[epoch: 184, i:    29] avg mini-batch loss: 0.007\n",
      "[epoch: 185, i:     9] avg mini-batch loss: 0.018\n",
      "[epoch: 185, i:    19] avg mini-batch loss: 0.016\n",
      "[epoch: 185, i:    29] avg mini-batch loss: 0.007\n",
      "[epoch: 186, i:     9] avg mini-batch loss: 0.015\n",
      "[epoch: 186, i:    19] avg mini-batch loss: 0.019\n",
      "[epoch: 186, i:    29] avg mini-batch loss: 0.009\n",
      "[epoch: 187, i:     9] avg mini-batch loss: 0.015\n",
      "[epoch: 187, i:    19] avg mini-batch loss: 0.022\n",
      "[epoch: 187, i:    29] avg mini-batch loss: 0.010\n",
      "[epoch: 188, i:     9] avg mini-batch loss: 0.011\n",
      "[epoch: 188, i:    19] avg mini-batch loss: 0.022\n",
      "[epoch: 188, i:    29] avg mini-batch loss: 0.021\n",
      "[epoch: 189, i:     9] avg mini-batch loss: 0.018\n",
      "[epoch: 189, i:    19] avg mini-batch loss: 0.027\n",
      "[epoch: 189, i:    29] avg mini-batch loss: 0.013\n",
      "[epoch: 190, i:     9] avg mini-batch loss: 0.020\n",
      "[epoch: 190, i:    19] avg mini-batch loss: 0.021\n",
      "[epoch: 190, i:    29] avg mini-batch loss: 0.016\n",
      "[epoch: 191, i:     9] avg mini-batch loss: 0.024\n",
      "[epoch: 191, i:    19] avg mini-batch loss: 0.018\n",
      "[epoch: 191, i:    29] avg mini-batch loss: 0.020\n",
      "[epoch: 192, i:     9] avg mini-batch loss: 0.022\n",
      "[epoch: 192, i:    19] avg mini-batch loss: 0.023\n",
      "[epoch: 192, i:    29] avg mini-batch loss: 0.015\n",
      "[epoch: 193, i:     9] avg mini-batch loss: 0.012\n",
      "[epoch: 193, i:    19] avg mini-batch loss: 0.020\n",
      "[epoch: 193, i:    29] avg mini-batch loss: 0.017\n",
      "[epoch: 194, i:     9] avg mini-batch loss: 0.012\n",
      "[epoch: 194, i:    19] avg mini-batch loss: 0.019\n",
      "[epoch: 194, i:    29] avg mini-batch loss: 0.021\n",
      "[epoch: 195, i:     9] avg mini-batch loss: 0.018\n",
      "[epoch: 195, i:    19] avg mini-batch loss: 0.016\n",
      "[epoch: 195, i:    29] avg mini-batch loss: 0.027\n",
      "[epoch: 196, i:     9] avg mini-batch loss: 0.027\n",
      "[epoch: 196, i:    19] avg mini-batch loss: 0.017\n",
      "[epoch: 196, i:    29] avg mini-batch loss: 0.030\n",
      "[epoch: 197, i:     9] avg mini-batch loss: 0.042\n",
      "[epoch: 197, i:    19] avg mini-batch loss: 0.024\n",
      "[epoch: 197, i:    29] avg mini-batch loss: 0.029\n",
      "[epoch: 198, i:     9] avg mini-batch loss: 0.027\n",
      "[epoch: 198, i:    19] avg mini-batch loss: 0.015\n",
      "[epoch: 198, i:    29] avg mini-batch loss: 0.034\n",
      "[epoch: 199, i:     9] avg mini-batch loss: 0.040\n",
      "[epoch: 199, i:    19] avg mini-batch loss: 0.014\n",
      "[epoch: 199, i:    29] avg mini-batch loss: 0.022\n",
      "[epoch: 200, i:     9] avg mini-batch loss: 0.047\n",
      "[epoch: 200, i:    19] avg mini-batch loss: 0.032\n",
      "[epoch: 200, i:    29] avg mini-batch loss: 0.020\n",
      "[epoch: 201, i:     9] avg mini-batch loss: 0.041\n",
      "[epoch: 201, i:    19] avg mini-batch loss: 0.046\n",
      "[epoch: 201, i:    29] avg mini-batch loss: 0.021\n",
      "[epoch: 202, i:     9] avg mini-batch loss: 0.043\n",
      "[epoch: 202, i:    19] avg mini-batch loss: 0.040\n",
      "[epoch: 202, i:    29] avg mini-batch loss: 0.020\n",
      "[epoch: 203, i:     9] avg mini-batch loss: 0.014\n",
      "[epoch: 203, i:    19] avg mini-batch loss: 0.030\n",
      "[epoch: 203, i:    29] avg mini-batch loss: 0.019\n",
      "[epoch: 204, i:     9] avg mini-batch loss: 0.010\n",
      "[epoch: 204, i:    19] avg mini-batch loss: 0.026\n",
      "[epoch: 204, i:    29] avg mini-batch loss: 0.026\n",
      "[epoch: 205, i:     9] avg mini-batch loss: 0.009\n",
      "[epoch: 205, i:    19] avg mini-batch loss: 0.019\n",
      "[epoch: 205, i:    29] avg mini-batch loss: 0.012\n",
      "[epoch: 206, i:     9] avg mini-batch loss: 0.014\n",
      "[epoch: 206, i:    19] avg mini-batch loss: 0.030\n",
      "[epoch: 206, i:    29] avg mini-batch loss: 0.021\n",
      "[epoch: 207, i:     9] avg mini-batch loss: 0.017\n",
      "[epoch: 207, i:    19] avg mini-batch loss: 0.025\n",
      "[epoch: 207, i:    29] avg mini-batch loss: 0.022\n",
      "[epoch: 208, i:     9] avg mini-batch loss: 0.011\n",
      "[epoch: 208, i:    19] avg mini-batch loss: 0.023\n",
      "[epoch: 208, i:    29] avg mini-batch loss: 0.011\n",
      "[epoch: 209, i:     9] avg mini-batch loss: 0.022\n",
      "[epoch: 209, i:    19] avg mini-batch loss: 0.025\n",
      "[epoch: 209, i:    29] avg mini-batch loss: 0.018\n",
      "[epoch: 210, i:     9] avg mini-batch loss: 0.017\n",
      "[epoch: 210, i:    19] avg mini-batch loss: 0.042\n",
      "[epoch: 210, i:    29] avg mini-batch loss: 0.021\n",
      "[epoch: 211, i:     9] avg mini-batch loss: 0.023\n",
      "[epoch: 211, i:    19] avg mini-batch loss: 0.027\n",
      "[epoch: 211, i:    29] avg mini-batch loss: 0.023\n",
      "[epoch: 212, i:     9] avg mini-batch loss: 0.013\n",
      "[epoch: 212, i:    19] avg mini-batch loss: 0.026\n",
      "[epoch: 212, i:    29] avg mini-batch loss: 0.015\n",
      "[epoch: 213, i:     9] avg mini-batch loss: 0.023\n",
      "[epoch: 213, i:    19] avg mini-batch loss: 0.031\n",
      "[epoch: 213, i:    29] avg mini-batch loss: 0.020\n",
      "[epoch: 214, i:     9] avg mini-batch loss: 0.016\n",
      "[epoch: 214, i:    19] avg mini-batch loss: 0.023\n",
      "[epoch: 214, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 215, i:     9] avg mini-batch loss: 0.017\n",
      "[epoch: 215, i:    19] avg mini-batch loss: 0.026\n",
      "[epoch: 215, i:    29] avg mini-batch loss: 0.017\n",
      "[epoch: 216, i:     9] avg mini-batch loss: 0.018\n",
      "[epoch: 216, i:    19] avg mini-batch loss: 0.028\n",
      "[epoch: 216, i:    29] avg mini-batch loss: 0.021\n",
      "[epoch: 217, i:     9] avg mini-batch loss: 0.022\n",
      "[epoch: 217, i:    19] avg mini-batch loss: 0.029\n",
      "[epoch: 217, i:    29] avg mini-batch loss: 0.012\n",
      "[epoch: 218, i:     9] avg mini-batch loss: 0.032\n",
      "[epoch: 218, i:    19] avg mini-batch loss: 0.024\n",
      "[epoch: 218, i:    29] avg mini-batch loss: 0.018\n",
      "[epoch: 219, i:     9] avg mini-batch loss: 0.033\n",
      "[epoch: 219, i:    19] avg mini-batch loss: 0.029\n",
      "[epoch: 219, i:    29] avg mini-batch loss: 0.010\n",
      "[epoch: 220, i:     9] avg mini-batch loss: 0.032\n",
      "[epoch: 220, i:    19] avg mini-batch loss: 0.036\n",
      "[epoch: 220, i:    29] avg mini-batch loss: 0.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 221, i:     9] avg mini-batch loss: 0.020\n",
      "[epoch: 221, i:    19] avg mini-batch loss: 0.027\n",
      "[epoch: 221, i:    29] avg mini-batch loss: 0.021\n",
      "[epoch: 222, i:     9] avg mini-batch loss: 0.018\n",
      "[epoch: 222, i:    19] avg mini-batch loss: 0.036\n",
      "[epoch: 222, i:    29] avg mini-batch loss: 0.019\n",
      "[epoch: 223, i:     9] avg mini-batch loss: 0.024\n",
      "[epoch: 223, i:    19] avg mini-batch loss: 0.029\n",
      "[epoch: 223, i:    29] avg mini-batch loss: 0.023\n",
      "[epoch: 224, i:     9] avg mini-batch loss: 0.022\n",
      "[epoch: 224, i:    19] avg mini-batch loss: 0.037\n",
      "[epoch: 224, i:    29] avg mini-batch loss: 0.013\n",
      "[epoch: 225, i:     9] avg mini-batch loss: 0.031\n",
      "[epoch: 225, i:    19] avg mini-batch loss: 0.034\n",
      "[epoch: 225, i:    29] avg mini-batch loss: 0.023\n",
      "[epoch: 226, i:     9] avg mini-batch loss: 0.029\n",
      "[epoch: 226, i:    19] avg mini-batch loss: 0.034\n",
      "[epoch: 226, i:    29] avg mini-batch loss: 0.023\n",
      "[epoch: 227, i:     9] avg mini-batch loss: 0.043\n",
      "[epoch: 227, i:    19] avg mini-batch loss: 0.031\n",
      "[epoch: 227, i:    29] avg mini-batch loss: 0.017\n",
      "[epoch: 228, i:     9] avg mini-batch loss: 0.036\n",
      "[epoch: 228, i:    19] avg mini-batch loss: 0.033\n",
      "[epoch: 228, i:    29] avg mini-batch loss: 0.010\n",
      "[epoch: 229, i:     9] avg mini-batch loss: 0.034\n",
      "[epoch: 229, i:    19] avg mini-batch loss: 0.037\n",
      "[epoch: 229, i:    29] avg mini-batch loss: 0.010\n",
      "[epoch: 230, i:     9] avg mini-batch loss: 0.046\n",
      "[epoch: 230, i:    19] avg mini-batch loss: 0.040\n",
      "[epoch: 230, i:    29] avg mini-batch loss: 0.017\n",
      "[epoch: 231, i:     9] avg mini-batch loss: 0.051\n",
      "[epoch: 231, i:    19] avg mini-batch loss: 0.031\n",
      "[epoch: 231, i:    29] avg mini-batch loss: 0.031\n",
      "[epoch: 232, i:     9] avg mini-batch loss: 0.037\n",
      "[epoch: 232, i:    19] avg mini-batch loss: 0.052\n",
      "[epoch: 232, i:    29] avg mini-batch loss: 0.033\n",
      "[epoch: 233, i:     9] avg mini-batch loss: 0.022\n",
      "[epoch: 233, i:    19] avg mini-batch loss: 0.049\n",
      "[epoch: 233, i:    29] avg mini-batch loss: 0.017\n",
      "[epoch: 234, i:     9] avg mini-batch loss: 0.040\n",
      "[epoch: 234, i:    19] avg mini-batch loss: 0.032\n",
      "[epoch: 234, i:    29] avg mini-batch loss: 0.069\n",
      "[epoch: 235, i:     9] avg mini-batch loss: 0.060\n",
      "[epoch: 235, i:    19] avg mini-batch loss: 0.029\n",
      "[epoch: 235, i:    29] avg mini-batch loss: 0.040\n",
      "[epoch: 236, i:     9] avg mini-batch loss: 0.019\n",
      "[epoch: 236, i:    19] avg mini-batch loss: 0.026\n",
      "[epoch: 236, i:    29] avg mini-batch loss: 0.008\n",
      "[epoch: 237, i:     9] avg mini-batch loss: 0.032\n",
      "[epoch: 237, i:    19] avg mini-batch loss: 0.029\n",
      "[epoch: 237, i:    29] avg mini-batch loss: 0.008\n",
      "[epoch: 238, i:     9] avg mini-batch loss: 0.043\n",
      "[epoch: 238, i:    19] avg mini-batch loss: 0.036\n",
      "[epoch: 238, i:    29] avg mini-batch loss: 0.021\n",
      "[epoch: 239, i:     9] avg mini-batch loss: 0.048\n",
      "[epoch: 239, i:    19] avg mini-batch loss: 0.034\n",
      "[epoch: 239, i:    29] avg mini-batch loss: 0.031\n",
      "[epoch: 240, i:     9] avg mini-batch loss: 0.036\n",
      "[epoch: 240, i:    19] avg mini-batch loss: 0.020\n",
      "[epoch: 240, i:    29] avg mini-batch loss: 0.064\n",
      "[epoch: 241, i:     9] avg mini-batch loss: 0.076\n",
      "[epoch: 241, i:    19] avg mini-batch loss: 0.033\n",
      "[epoch: 241, i:    29] avg mini-batch loss: 0.051\n",
      "[epoch: 242, i:     9] avg mini-batch loss: 0.040\n",
      "[epoch: 242, i:    19] avg mini-batch loss: 0.023\n",
      "[epoch: 242, i:    29] avg mini-batch loss: 0.012\n",
      "[epoch: 243, i:     9] avg mini-batch loss: 0.043\n",
      "[epoch: 243, i:    19] avg mini-batch loss: 0.030\n",
      "[epoch: 243, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 244, i:     9] avg mini-batch loss: 0.038\n",
      "[epoch: 244, i:    19] avg mini-batch loss: 0.052\n",
      "[epoch: 244, i:    29] avg mini-batch loss: 0.014\n",
      "[epoch: 245, i:     9] avg mini-batch loss: 0.044\n",
      "[epoch: 245, i:    19] avg mini-batch loss: 0.022\n",
      "[epoch: 245, i:    29] avg mini-batch loss: 0.039\n",
      "[epoch: 246, i:     9] avg mini-batch loss: 0.072\n",
      "[epoch: 246, i:    19] avg mini-batch loss: 0.050\n",
      "[epoch: 246, i:    29] avg mini-batch loss: 0.038\n",
      "[epoch: 247, i:     9] avg mini-batch loss: 0.060\n",
      "[epoch: 247, i:    19] avg mini-batch loss: 0.064\n",
      "[epoch: 247, i:    29] avg mini-batch loss: 0.036\n",
      "[epoch: 248, i:     9] avg mini-batch loss: 0.031\n",
      "[epoch: 248, i:    19] avg mini-batch loss: 0.011\n",
      "[epoch: 248, i:    29] avg mini-batch loss: 0.064\n",
      "[epoch: 249, i:     9] avg mini-batch loss: 0.059\n",
      "[epoch: 249, i:    19] avg mini-batch loss: 0.026\n",
      "[epoch: 249, i:    29] avg mini-batch loss: 0.052\n",
      "[epoch: 250, i:     9] avg mini-batch loss: 0.077\n",
      "[epoch: 250, i:    19] avg mini-batch loss: 0.034\n",
      "[epoch: 250, i:    29] avg mini-batch loss: 0.041\n",
      "[epoch: 251, i:     9] avg mini-batch loss: 0.082\n",
      "[epoch: 251, i:    19] avg mini-batch loss: 0.031\n",
      "[epoch: 251, i:    29] avg mini-batch loss: 0.049\n",
      "[epoch: 252, i:     9] avg mini-batch loss: 0.075\n",
      "[epoch: 252, i:    19] avg mini-batch loss: 0.039\n",
      "[epoch: 252, i:    29] avg mini-batch loss: 0.041\n",
      "[epoch: 253, i:     9] avg mini-batch loss: 0.051\n",
      "[epoch: 253, i:    19] avg mini-batch loss: 0.028\n",
      "[epoch: 253, i:    29] avg mini-batch loss: 0.035\n",
      "[epoch: 254, i:     9] avg mini-batch loss: 0.048\n",
      "[epoch: 254, i:    19] avg mini-batch loss: 0.024\n",
      "[epoch: 254, i:    29] avg mini-batch loss: 0.062\n",
      "[epoch: 255, i:     9] avg mini-batch loss: 0.058\n",
      "[epoch: 255, i:    19] avg mini-batch loss: 0.036\n",
      "[epoch: 255, i:    29] avg mini-batch loss: 0.062\n",
      "[epoch: 256, i:     9] avg mini-batch loss: 0.057\n",
      "[epoch: 256, i:    19] avg mini-batch loss: 0.034\n",
      "[epoch: 256, i:    29] avg mini-batch loss: 0.072\n",
      "[epoch: 257, i:     9] avg mini-batch loss: 0.089\n",
      "[epoch: 257, i:    19] avg mini-batch loss: 0.029\n",
      "[epoch: 257, i:    29] avg mini-batch loss: 0.050\n",
      "[epoch: 258, i:     9] avg mini-batch loss: 0.054\n",
      "[epoch: 258, i:    19] avg mini-batch loss: 0.031\n",
      "[epoch: 258, i:    29] avg mini-batch loss: 0.077\n",
      "[epoch: 259, i:     9] avg mini-batch loss: 0.042\n",
      "[epoch: 259, i:    19] avg mini-batch loss: 0.056\n",
      "[epoch: 259, i:    29] avg mini-batch loss: 0.067\n",
      "[epoch: 260, i:     9] avg mini-batch loss: 0.028\n",
      "[epoch: 260, i:    19] avg mini-batch loss: 0.073\n",
      "[epoch: 260, i:    29] avg mini-batch loss: 0.077\n",
      "[epoch: 261, i:     9] avg mini-batch loss: 0.037\n",
      "[epoch: 261, i:    19] avg mini-batch loss: 0.072\n",
      "[epoch: 261, i:    29] avg mini-batch loss: 0.070\n",
      "[epoch: 262, i:     9] avg mini-batch loss: 0.075\n",
      "[epoch: 262, i:    19] avg mini-batch loss: 0.042\n",
      "[epoch: 262, i:    29] avg mini-batch loss: 0.034\n",
      "[epoch: 263, i:     9] avg mini-batch loss: 0.047\n",
      "[epoch: 263, i:    19] avg mini-batch loss: 0.057\n",
      "[epoch: 263, i:    29] avg mini-batch loss: 0.015\n",
      "[epoch: 264, i:     9] avg mini-batch loss: 0.042\n",
      "[epoch: 264, i:    19] avg mini-batch loss: 0.041\n",
      "[epoch: 264, i:    29] avg mini-batch loss: 0.008\n",
      "[epoch: 265, i:     9] avg mini-batch loss: 0.040\n",
      "[epoch: 265, i:    19] avg mini-batch loss: 0.016\n",
      "[epoch: 265, i:    29] avg mini-batch loss: 0.019\n",
      "[epoch: 266, i:     9] avg mini-batch loss: 0.018\n",
      "[epoch: 266, i:    19] avg mini-batch loss: 0.005\n",
      "[epoch: 266, i:    29] avg mini-batch loss: 0.004\n",
      "[epoch: 267, i:     9] avg mini-batch loss: 0.005\n",
      "[epoch: 267, i:    19] avg mini-batch loss: 0.002\n",
      "[epoch: 267, i:    29] avg mini-batch loss: 0.002\n",
      "[epoch: 268, i:     9] avg mini-batch loss: 0.004\n",
      "[epoch: 268, i:    19] avg mini-batch loss: 0.002\n",
      "[epoch: 268, i:    29] avg mini-batch loss: 0.002\n",
      "[epoch: 269, i:     9] avg mini-batch loss: 0.004\n",
      "[epoch: 269, i:    19] avg mini-batch loss: 0.002\n",
      "[epoch: 269, i:    29] avg mini-batch loss: 0.002\n",
      "[epoch: 270, i:     9] avg mini-batch loss: 0.004\n",
      "[epoch: 270, i:    19] avg mini-batch loss: 0.002\n",
      "[epoch: 270, i:    29] avg mini-batch loss: 0.002\n",
      "[epoch: 271, i:     9] avg mini-batch loss: 0.004\n",
      "[epoch: 271, i:    19] avg mini-batch loss: 0.002\n",
      "[epoch: 271, i:    29] avg mini-batch loss: 0.002\n",
      "[epoch: 272, i:     9] avg mini-batch loss: 0.004\n",
      "[epoch: 272, i:    19] avg mini-batch loss: 0.002\n",
      "[epoch: 272, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 273, i:     9] avg mini-batch loss: 0.003\n",
      "[epoch: 273, i:    19] avg mini-batch loss: 0.002\n",
      "[epoch: 273, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 274, i:     9] avg mini-batch loss: 0.003\n",
      "[epoch: 274, i:    19] avg mini-batch loss: 0.002\n",
      "[epoch: 274, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 275, i:     9] avg mini-batch loss: 0.003\n",
      "[epoch: 275, i:    19] avg mini-batch loss: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 275, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 276, i:     9] avg mini-batch loss: 0.003\n",
      "[epoch: 276, i:    19] avg mini-batch loss: 0.002\n",
      "[epoch: 276, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 277, i:     9] avg mini-batch loss: 0.003\n",
      "[epoch: 277, i:    19] avg mini-batch loss: 0.002\n",
      "[epoch: 277, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 278, i:     9] avg mini-batch loss: 0.003\n",
      "[epoch: 278, i:    19] avg mini-batch loss: 0.002\n",
      "[epoch: 278, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 279, i:     9] avg mini-batch loss: 0.003\n",
      "[epoch: 279, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 279, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 280, i:     9] avg mini-batch loss: 0.003\n",
      "[epoch: 280, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 280, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 281, i:     9] avg mini-batch loss: 0.003\n",
      "[epoch: 281, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 281, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 282, i:     9] avg mini-batch loss: 0.003\n",
      "[epoch: 282, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 282, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 283, i:     9] avg mini-batch loss: 0.003\n",
      "[epoch: 283, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 283, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 284, i:     9] avg mini-batch loss: 0.003\n",
      "[epoch: 284, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 284, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 285, i:     9] avg mini-batch loss: 0.003\n",
      "[epoch: 285, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 285, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 286, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 286, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 286, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 287, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 287, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 287, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 288, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 288, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 288, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 289, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 289, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 289, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 290, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 290, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 290, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 291, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 291, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 291, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 292, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 292, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 292, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 293, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 293, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 293, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 294, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 294, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 294, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 295, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 295, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 295, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 296, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 296, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 296, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 297, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 297, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 297, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 298, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 298, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 298, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 299, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 299, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 299, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 300, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 300, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 300, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 301, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 301, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 301, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 302, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 302, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 302, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 303, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 303, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 303, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 304, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 304, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 304, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 305, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 305, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 305, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 306, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 306, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 306, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 307, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 307, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 307, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 308, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 308, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 308, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 309, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 309, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 309, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 310, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 310, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 310, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 311, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 311, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 311, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 312, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 312, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 312, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 313, i:     9] avg mini-batch loss: 0.002\n",
      "[epoch: 313, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 313, i:    29] avg mini-batch loss: 0.001\n",
      "[epoch: 314, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 314, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 314, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 315, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 315, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 315, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 316, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 316, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 316, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 317, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 317, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 317, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 318, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 318, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 318, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 319, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 319, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 319, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 320, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 320, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 320, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 321, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 321, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 321, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 322, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 322, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 322, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 323, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 323, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 323, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 324, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 324, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 324, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 325, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 325, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 325, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 326, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 326, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 326, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 327, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 327, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 327, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 328, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 328, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 328, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 329, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 329, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 329, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 330, i:     9] avg mini-batch loss: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 330, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 330, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 331, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 331, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 331, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 332, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 332, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 332, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 333, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 333, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 333, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 334, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 334, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 334, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 335, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 335, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 335, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 336, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 336, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 336, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 337, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 337, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 337, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 338, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 338, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 338, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 339, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 339, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 339, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 340, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 340, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 340, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 341, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 341, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 341, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 342, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 342, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 342, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 343, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 343, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 343, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 344, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 344, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 344, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 345, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 345, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 345, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 346, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 346, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 346, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 347, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 347, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 347, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 348, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 348, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 348, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 349, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 349, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 349, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 350, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 350, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 350, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 351, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 351, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 351, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 352, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 352, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 352, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 353, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 353, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 353, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 354, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 354, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 354, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 355, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 355, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 355, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 356, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 356, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 356, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 357, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 357, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 357, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 358, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 358, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 358, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 359, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 359, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 359, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 360, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 360, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 360, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 361, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 361, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 361, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 362, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 362, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 362, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 363, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 363, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 363, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 364, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 364, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 364, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 365, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 365, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 365, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 366, i:     9] avg mini-batch loss: 0.001\n",
      "[epoch: 366, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 366, i:    29] avg mini-batch loss: 0.000\n",
      "[epoch: 367, i:     9] avg mini-batch loss: 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-799d7a9c44c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-120bbc8d61fd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(net.parameters(), lr=0.0005)\n",
    "avg_losses = [] \n",
    "epochs = 500 \n",
    "print_freq = 20\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    p = 0.4\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.permute(0, 3, 1, 2)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        opt.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1:\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Accuracy of the network on the 40 test images: 70 %\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(total)\n",
    "print('Accuracy of the network on the 40 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240\n",
      "Accuracy of the network on the 1240 training images: 100 %\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(total)\n",
    "print('Accuracy of the network on the 1240 training images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Positive : 64 %\n",
      "Accuracy of Negative : 73 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        one = torch.tensor(1, dtype=torch.float, device=device)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(40):\n",
    "            label = labels[i]\n",
    "            labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkernal size 3*3\\nstep size = 1\\nmaximum pooled layer of 2*2\\nstep size = 2\\nlearning rate = 0.0001\\nbatch size = 63\\ndropout rate = 0.5\\nk-fold: 5-fold cross validation\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "kernal size 3*3\n",
    "step size = 1\n",
    "maximum pooled layer of 2*2\n",
    "step size = 2\n",
    "learning rate = 0.0001\n",
    "batch size = 63\n",
    "dropout rate = 0.5\n",
    "k-fold: 5-fold cross validation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
