{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For AROUSAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/the-4-convolutional-neural-network-models-that-can-classify-your-fashion-images-9fe7f3e5399d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"/Users/apple/Desktop/eeglab14_1_2b/Granger Casuality/img/\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for i in range(len(onlyfiles)):\n",
    "    data = Image.open(mypath + onlyfiles[i])\n",
    "    arr = np.array(data)\n",
    "    arr = arr[:,:,0:3]\n",
    "    #result = np.zeros((32,32))\n",
    "    #toadd = np.zeros((32,32,4))\n",
    "    #for k in range(arr.shape[2]-1):\n",
    "    #    result[:arr[:,:,k].shape[0],:arr[:,:,k].shape[1]] = arr[:,:,k] \n",
    "    #    toadd[:,:,k] = result\n",
    "    X.append(arr)\n",
    "print(len(X))\n",
    "print(X[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/apple/Desktop/eeglab14_1_2b/participant_ratings.csv',\n",
    "                sep=r'\\s*,\\s*',engine = 'python', na_values = '?')\n",
    "df.dropna()\n",
    "Y_chart = pd.get_dummies(df, drop_first=True)\n",
    "Y = Y_chart['Arousal'].tolist()\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Y)):\n",
    "    if Y[i] < 5:\n",
    "        Y[i] = 0\n",
    "    else:\n",
    "        Y[i] = 1\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=(40/len(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1240, 32, 32, 3)\n",
      "(1240,)\n",
      "(40, 32, 32, 3)\n",
      "(40,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 3)\n",
      "Image dataset has min/mean/std/max = 1.00/101.13/49.83/253.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.59/0.49/1.00\n"
     ]
    }
   ],
   "source": [
    "print('Image dataset have shape =', X_train.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train.min(),\n",
    "                        X_train.mean(), X_train.std(), X_train.max()))\n",
    "print('')\n",
    "print('Train label has shape =', y_train.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(y_train.min(),\n",
    "                        y_train.mean(), y_train.std(), y_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 3)\n",
      "Image dataset has min/mean/std/max = 0.00/0.40/0.20/1.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.59/0.49/1.00\n"
     ]
    }
   ],
   "source": [
    "def normalize_data(data): \n",
    "    data = data / data.max()\n",
    "    return data\n",
    "\n",
    "X_train = normalize_data(X_train)\n",
    "X_test = normalize_data(X_test)\n",
    "print('Image dataset have shape =', X_train.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train.min(),\n",
    "                        X_train.mean(), X_train.std(), X_train.max()))\n",
    "print('')\n",
    "print('Train label has shape =', y_train.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(y_train.min(),\n",
    "                        y_train.mean(), y_train.std(), y_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data): \n",
    "    for x in data:\n",
    "        x = x/255\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 3)\n",
      "Image dataset has min/mean/std/max = 1.00/101.13/49.83/253.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.59/0.49/1.00\n"
     ]
    }
   ],
   "source": [
    "X_train = normalize_data(X_train)\n",
    "X_test = normalize_data(X_test)\n",
    "X_train_temp = np.asarray(X_train)\n",
    "Y_train_temp = np.asarray(y_train)\n",
    "print('Image dataset have shape =', X_train_temp.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train_temp.min(),\n",
    "                        X_train_temp.mean(), X_train_temp.std(), X_train_temp.max()))\n",
    "print('')\n",
    "print('Train label has shape =', Y_train_temp.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(Y_train_temp.min(),\n",
    "                        Y_train_temp.mean(), Y_train_temp.std(), Y_train_temp.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    " [transforms.ToTensor(),\n",
    " transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "tensor_x = torch.stack([torch.Tensor(i) for i in X_train])\n",
    "tensor_y = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = utils.TensorDataset(tensor_x,tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = utils.DataLoader(trainset,  batch_size= 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x_test = torch.stack([torch.Tensor(i) for i in X_test])\n",
    "tensor_y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = utils.TensorDataset(tensor_x_test,tensor_y_test)\n",
    "testloader = utils.DataLoader(testset,  batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "classes = ('Positive', 'Negative')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 32, 32, 3])\n",
      "torch.Size([40, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "images = images.permute(0, 3, 1, 2)\n",
    "print(images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "rows = 1\n",
    "columns = 1\n",
    "fig=plt.figure()\n",
    "for i in range(1):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    img = images[i]\n",
    "    img = torchvision.transforms.ToPILImage()(img)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkernal size 3*3\\nstep size = 1\\nmaximum pooled layer of 2*2\\nstep size = 2\\nlearning rate = 0.0001\\nbatch size = 63\\ndropout rate = 0.5\\nk-fold: 5-fold cross validation\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "kernal size 3*3\n",
    "step size = 1\n",
    "maximum pooled layer of 2*2\n",
    "step size = 2\n",
    "learning rate = 0.0001\n",
    "batch size = 63\n",
    "dropout rate = 0.5\n",
    "k-fold: 5-fold cross validation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1280, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(20 * 8 * 8, 100)\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 20 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(net.parameters(), lr=0.0005)\n",
    "avg_losses = [] \n",
    "epochs = 1000 \n",
    "print_freq = 50\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.permute(0, 3, 1, 2)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        opt.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1:\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Accuracy of the network on the 40 test images: 60 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(total)\n",
    "print('Accuracy of the network on the 40 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-f0480319fbd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'other'"
     ]
    }
   ],
   "source": [
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        one = torch.tensor(1, dtype=torch.float, device=device)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(40):\n",
    "            label = labels[i]\n",
    "            labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkernal size 3*3\\nstep size = 1\\nmaximum pooled layer of 2*2\\nstep size = 2\\nlearning rate = 0.0001\\nbatch size = 63\\ndropout rate = 0.5\\nk-fold: 5-fold cross validation\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "kernal size 3*3\n",
    "step size = 1\n",
    "maximum pooled layer of 2*2\n",
    "step size = 2\n",
    "learning rate = 0.0001\n",
    "batch size = 63\n",
    "dropout rate = 0.5\n",
    "k-fold: 5-fold cross validation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
