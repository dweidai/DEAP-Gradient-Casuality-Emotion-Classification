{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For AROUSAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/the-4-convolutional-neural-network-models-that-can-classify-your-fashion-images-9fe7f3e5399d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"/Users/apple/Desktop/eeglab14_1_2b/Granger Casuality/img/\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for i in range(len(onlyfiles)):\n",
    "    data = Image.open(mypath + onlyfiles[i])\n",
    "    arr = np.array(data)\n",
    "    arr = arr[:,:,0:3]\n",
    "    #result = np.zeros((32,32))\n",
    "    #toadd = np.zeros((32,32,4))\n",
    "    #for k in range(arr.shape[2]-1):\n",
    "    #    result[:arr[:,:,k].shape[0],:arr[:,:,k].shape[1]] = arr[:,:,k] \n",
    "    #    toadd[:,:,k] = result\n",
    "    X.append(arr)\n",
    "print(len(X))\n",
    "print(X[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/apple/Desktop/eeglab14_1_2b/participant_ratings.csv',\n",
    "                sep=r'\\s*,\\s*',engine = 'python', na_values = '?')\n",
    "df.dropna()\n",
    "Y_chart = pd.get_dummies(df, drop_first=True)\n",
    "Y = Y_chart['Arousal'].tolist()\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Y)):\n",
    "    if Y[i] < 5:\n",
    "        Y[i] = 0\n",
    "    else:\n",
    "        Y[i] = 1\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=(40/len(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1240, 32, 32, 3)\n",
      "(1240,)\n",
      "(40, 32, 32, 3)\n",
      "(40,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 3)\n",
      "Image dataset has min/mean/std/max = 1.00/101.12/49.81/253.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.59/0.49/1.00\n"
     ]
    }
   ],
   "source": [
    "print('Image dataset have shape =', X_train.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train.min(),\n",
    "                        X_train.mean(), X_train.std(), X_train.max()))\n",
    "print('')\n",
    "print('Train label has shape =', y_train.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(y_train.min(),\n",
    "                        y_train.mean(), y_train.std(), y_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 3)\n",
      "Image dataset has min/mean/std/max = 0.00/0.40/0.20/1.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.59/0.49/1.00\n"
     ]
    }
   ],
   "source": [
    "def normalize_data(data): \n",
    "    data = data / data.max()\n",
    "    return data\n",
    "\n",
    "X_train = normalize_data(X_train)\n",
    "X_test = normalize_data(X_test)\n",
    "print('Image dataset have shape =', X_train.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train.min(),\n",
    "                        X_train.mean(), X_train.std(), X_train.max()))\n",
    "print('')\n",
    "print('Train label has shape =', y_train.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(y_train.min(),\n",
    "                        y_train.mean(), y_train.std(), y_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data): \n",
    "    for x in data:\n",
    "        x = x/255\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 3)\n",
      "Image dataset has min/mean/std/max = 0.00/0.40/0.20/1.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.59/0.49/1.00\n"
     ]
    }
   ],
   "source": [
    "X_train = normalize_data(X_train)\n",
    "X_test = normalize_data(X_test)\n",
    "X_train_temp = np.asarray(X_train)\n",
    "Y_train_temp = np.asarray(y_train)\n",
    "print('Image dataset have shape =', X_train_temp.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train_temp.min(),\n",
    "                        X_train_temp.mean(), X_train_temp.std(), X_train_temp.max()))\n",
    "print('')\n",
    "print('Train label has shape =', Y_train_temp.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(Y_train_temp.min(),\n",
    "                        Y_train_temp.mean(), Y_train_temp.std(), Y_train_temp.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    " [transforms.ToTensor(),\n",
    " transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "tensor_x = torch.stack([torch.Tensor(i) for i in X_train])\n",
    "tensor_y = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = utils.TensorDataset(tensor_x,tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = utils.DataLoader(trainset,  batch_size= 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x_test = torch.stack([torch.Tensor(i) for i in X_test])\n",
    "tensor_y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = utils.TensorDataset(tensor_x_test,tensor_y_test)\n",
    "testloader = utils.DataLoader(testset,  batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "classes = ('Positive', 'Negative')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 32, 32, 3])\n",
      "torch.Size([40, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "images = images.permute(0, 3, 1, 2)\n",
    "print(images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "rows = 1\n",
    "columns = 1\n",
    "fig=plt.figure()\n",
    "for i in range(1):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    img = images[i]\n",
    "    img = torchvision.transforms.ToPILImage()(img)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkernal size 3*3\\nstep size = 1\\nmaximum pooled layer of 2*2\\nstep size = 2\\nlearning rate = 0.0001\\nbatch size = 63\\ndropout rate = 0.5\\nk-fold: 5-fold cross validation\\n'"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "kernal size 3*3\n",
    "step size = 1\n",
    "maximum pooled layer of 2*2\n",
    "step size = 2\n",
    "learning rate = 0.0001\n",
    "batch size = 63\n",
    "dropout rate = 0.5\n",
    "k-fold: 5-fold cross validation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=40, bias=True)\n",
       "  (fc3): Linear(in_features=40, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "drop_out = 0.4;\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # input channel = 3, output channel = 6, kernel_size = 5\n",
    "        # input size = (32, 32), output size = (28, 28)\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        # input channel = 6, output channel = 16, kernel_size = 5\n",
    "        # input size = (14, 14), output size = (10, 10)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # input dim = 16*5*5, output dim = 120\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # input dim = 120, output dim = 40\n",
    "        self.fc2 = nn.Linear(120, 40)\n",
    "        # input dim = 40, output dim = 2\n",
    "        self.fc3 = nn.Linear(40, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pool size = 2\n",
    "        # input size = (28, 28), output size = (14, 14), output channel = 6\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        # pool size = 2\n",
    "        # input size = (10, 10), output size = (5, 5), output channel = 16\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # flatten as one dimension\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # input dim = 16*5*5, output dim = 120\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # input dim = 120, output dim = 40\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # input dim = 40, output dim = 2\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 1, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 2, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 3, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 4, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 5, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 6, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 7, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 8, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 9, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 10, i:    19] avg mini-batch loss: 0.683\n",
      "[epoch: 11, i:    19] avg mini-batch loss: 0.682\n",
      "[epoch: 12, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 13, i:    19] avg mini-batch loss: 0.678\n",
      "[epoch: 14, i:    19] avg mini-batch loss: 0.673\n",
      "[epoch: 15, i:    19] avg mini-batch loss: 0.667\n",
      "[epoch: 16, i:    19] avg mini-batch loss: 0.662\n",
      "[epoch: 17, i:    19] avg mini-batch loss: 0.653\n",
      "[epoch: 18, i:    19] avg mini-batch loss: 0.640\n",
      "[epoch: 19, i:    19] avg mini-batch loss: 0.630\n",
      "[epoch: 20, i:    19] avg mini-batch loss: 0.616\n",
      "[epoch: 21, i:    19] avg mini-batch loss: 0.607\n",
      "[epoch: 22, i:    19] avg mini-batch loss: 0.595\n",
      "[epoch: 23, i:    19] avg mini-batch loss: 0.583\n",
      "[epoch: 24, i:    19] avg mini-batch loss: 0.577\n",
      "[epoch: 25, i:    19] avg mini-batch loss: 0.566\n",
      "[epoch: 26, i:    19] avg mini-batch loss: 0.551\n",
      "[epoch: 27, i:    19] avg mini-batch loss: 0.543\n",
      "[epoch: 28, i:    19] avg mini-batch loss: 0.529\n",
      "[epoch: 29, i:    19] avg mini-batch loss: 0.515\n",
      "[epoch: 30, i:    19] avg mini-batch loss: 0.497\n",
      "[epoch: 31, i:    19] avg mini-batch loss: 0.480\n",
      "[epoch: 32, i:    19] avg mini-batch loss: 0.457\n",
      "[epoch: 33, i:    19] avg mini-batch loss: 0.433\n",
      "[epoch: 34, i:    19] avg mini-batch loss: 0.413\n",
      "[epoch: 35, i:    19] avg mini-batch loss: 0.387\n",
      "[epoch: 36, i:    19] avg mini-batch loss: 0.369\n",
      "[epoch: 37, i:    19] avg mini-batch loss: 0.346\n",
      "[epoch: 38, i:    19] avg mini-batch loss: 0.322\n",
      "[epoch: 39, i:    19] avg mini-batch loss: 0.299\n",
      "[epoch: 40, i:    19] avg mini-batch loss: 0.284\n",
      "[epoch: 41, i:    19] avg mini-batch loss: 0.269\n",
      "[epoch: 42, i:    19] avg mini-batch loss: 0.266\n",
      "[epoch: 43, i:    19] avg mini-batch loss: 0.232\n",
      "[epoch: 44, i:    19] avg mini-batch loss: 0.222\n",
      "[epoch: 45, i:    19] avg mini-batch loss: 0.214\n",
      "[epoch: 46, i:    19] avg mini-batch loss: 0.207\n",
      "[epoch: 47, i:    19] avg mini-batch loss: 0.192\n",
      "[epoch: 48, i:    19] avg mini-batch loss: 0.215\n",
      "[epoch: 49, i:    19] avg mini-batch loss: 0.230\n",
      "[epoch: 50, i:    19] avg mini-batch loss: 0.242\n",
      "[epoch: 51, i:    19] avg mini-batch loss: 0.233\n",
      "[epoch: 52, i:    19] avg mini-batch loss: 0.227\n",
      "[epoch: 53, i:    19] avg mini-batch loss: 0.211\n",
      "[epoch: 54, i:    19] avg mini-batch loss: 0.199\n",
      "[epoch: 55, i:    19] avg mini-batch loss: 0.188\n",
      "[epoch: 56, i:    19] avg mini-batch loss: 0.150\n",
      "[epoch: 57, i:    19] avg mini-batch loss: 0.153\n",
      "[epoch: 58, i:    19] avg mini-batch loss: 0.151\n",
      "[epoch: 59, i:    19] avg mini-batch loss: 0.146\n",
      "[epoch: 60, i:    19] avg mini-batch loss: 0.172\n",
      "[epoch: 61, i:    19] avg mini-batch loss: 0.162\n",
      "[epoch: 62, i:    19] avg mini-batch loss: 0.205\n",
      "[epoch: 63, i:    19] avg mini-batch loss: 0.191\n",
      "[epoch: 64, i:    19] avg mini-batch loss: 0.205\n",
      "[epoch: 65, i:    19] avg mini-batch loss: 0.152\n",
      "[epoch: 66, i:    19] avg mini-batch loss: 0.138\n",
      "[epoch: 67, i:    19] avg mini-batch loss: 0.128\n",
      "[epoch: 68, i:    19] avg mini-batch loss: 0.099\n",
      "[epoch: 69, i:    19] avg mini-batch loss: 0.074\n",
      "[epoch: 70, i:    19] avg mini-batch loss: 0.055\n",
      "[epoch: 71, i:    19] avg mini-batch loss: 0.049\n",
      "[epoch: 72, i:    19] avg mini-batch loss: 0.044\n",
      "[epoch: 73, i:    19] avg mini-batch loss: 0.041\n",
      "[epoch: 74, i:    19] avg mini-batch loss: 0.038\n",
      "[epoch: 75, i:    19] avg mini-batch loss: 0.034\n",
      "[epoch: 76, i:    19] avg mini-batch loss: 0.031\n",
      "[epoch: 77, i:    19] avg mini-batch loss: 0.028\n",
      "[epoch: 78, i:    19] avg mini-batch loss: 0.025\n",
      "[epoch: 79, i:    19] avg mini-batch loss: 0.024\n",
      "[epoch: 80, i:    19] avg mini-batch loss: 0.022\n",
      "[epoch: 81, i:    19] avg mini-batch loss: 0.020\n",
      "[epoch: 82, i:    19] avg mini-batch loss: 0.019\n",
      "[epoch: 83, i:    19] avg mini-batch loss: 0.019\n",
      "[epoch: 84, i:    19] avg mini-batch loss: 0.018\n",
      "[epoch: 85, i:    19] avg mini-batch loss: 0.016\n",
      "[epoch: 86, i:    19] avg mini-batch loss: 0.016\n",
      "[epoch: 87, i:    19] avg mini-batch loss: 0.015\n",
      "[epoch: 88, i:    19] avg mini-batch loss: 0.014\n",
      "[epoch: 89, i:    19] avg mini-batch loss: 0.014\n",
      "[epoch: 90, i:    19] avg mini-batch loss: 0.013\n",
      "[epoch: 91, i:    19] avg mini-batch loss: 0.012\n",
      "[epoch: 92, i:    19] avg mini-batch loss: 0.012\n",
      "[epoch: 93, i:    19] avg mini-batch loss: 0.012\n",
      "[epoch: 94, i:    19] avg mini-batch loss: 0.012\n",
      "[epoch: 95, i:    19] avg mini-batch loss: 0.012\n",
      "[epoch: 96, i:    19] avg mini-batch loss: 0.012\n",
      "[epoch: 97, i:    19] avg mini-batch loss: 0.012\n",
      "[epoch: 98, i:    19] avg mini-batch loss: 0.011\n",
      "[epoch: 99, i:    19] avg mini-batch loss: 0.010\n",
      "[epoch: 100, i:    19] avg mini-batch loss: 0.010\n",
      "[epoch: 101, i:    19] avg mini-batch loss: 0.009\n",
      "[epoch: 102, i:    19] avg mini-batch loss: 0.010\n",
      "[epoch: 103, i:    19] avg mini-batch loss: 0.010\n",
      "[epoch: 104, i:    19] avg mini-batch loss: 0.011\n",
      "[epoch: 105, i:    19] avg mini-batch loss: 0.009\n",
      "[epoch: 106, i:    19] avg mini-batch loss: 0.011\n",
      "[epoch: 107, i:    19] avg mini-batch loss: 0.012\n",
      "[epoch: 108, i:    19] avg mini-batch loss: 0.012\n",
      "[epoch: 109, i:    19] avg mini-batch loss: 0.009\n",
      "[epoch: 110, i:    19] avg mini-batch loss: 0.011\n",
      "[epoch: 111, i:    19] avg mini-batch loss: 0.009\n",
      "[epoch: 112, i:    19] avg mini-batch loss: 0.008\n",
      "[epoch: 113, i:    19] avg mini-batch loss: 0.007\n",
      "[epoch: 114, i:    19] avg mini-batch loss: 0.009\n",
      "[epoch: 115, i:    19] avg mini-batch loss: 0.016\n",
      "[epoch: 116, i:    19] avg mini-batch loss: 0.008\n",
      "[epoch: 117, i:    19] avg mini-batch loss: 0.011\n",
      "[epoch: 118, i:    19] avg mini-batch loss: 0.031\n",
      "[epoch: 119, i:    19] avg mini-batch loss: 0.026\n",
      "[epoch: 120, i:    19] avg mini-batch loss: 0.088\n",
      "[epoch: 121, i:    19] avg mini-batch loss: 0.104\n",
      "[epoch: 122, i:    19] avg mini-batch loss: 0.033\n",
      "[epoch: 123, i:    19] avg mini-batch loss: 0.078\n",
      "[epoch: 124, i:    19] avg mini-batch loss: 0.097\n",
      "[epoch: 125, i:    19] avg mini-batch loss: 0.105\n",
      "[epoch: 126, i:    19] avg mini-batch loss: 0.036\n",
      "[epoch: 127, i:    19] avg mini-batch loss: 0.031\n",
      "[epoch: 128, i:    19] avg mini-batch loss: 0.047\n",
      "[epoch: 129, i:    19] avg mini-batch loss: 0.028\n",
      "[epoch: 130, i:    19] avg mini-batch loss: 0.041\n",
      "[epoch: 131, i:    19] avg mini-batch loss: 0.033\n",
      "[epoch: 132, i:    19] avg mini-batch loss: 0.012\n",
      "[epoch: 133, i:    19] avg mini-batch loss: 0.009\n",
      "[epoch: 134, i:    19] avg mini-batch loss: 0.012\n",
      "[epoch: 135, i:    19] avg mini-batch loss: 0.016\n",
      "[epoch: 136, i:    19] avg mini-batch loss: 0.017\n",
      "[epoch: 137, i:    19] avg mini-batch loss: 0.013\n",
      "[epoch: 138, i:    19] avg mini-batch loss: 0.013\n",
      "[epoch: 139, i:    19] avg mini-batch loss: 0.007\n",
      "[epoch: 140, i:    19] avg mini-batch loss: 0.011\n",
      "[epoch: 141, i:    19] avg mini-batch loss: 0.017\n",
      "[epoch: 142, i:    19] avg mini-batch loss: 0.014\n",
      "[epoch: 143, i:    19] avg mini-batch loss: 0.016\n",
      "[epoch: 144, i:    19] avg mini-batch loss: 0.017\n",
      "[epoch: 145, i:    19] avg mini-batch loss: 0.011\n",
      "[epoch: 146, i:    19] avg mini-batch loss: 0.008\n",
      "[epoch: 147, i:    19] avg mini-batch loss: 0.014\n",
      "[epoch: 148, i:    19] avg mini-batch loss: 0.010\n",
      "[epoch: 149, i:    19] avg mini-batch loss: 0.013\n",
      "[epoch: 150, i:    19] avg mini-batch loss: 0.010\n",
      "[epoch: 151, i:    19] avg mini-batch loss: 0.011\n",
      "[epoch: 152, i:    19] avg mini-batch loss: 0.009\n",
      "[epoch: 153, i:    19] avg mini-batch loss: 0.019\n",
      "[epoch: 154, i:    19] avg mini-batch loss: 0.013\n",
      "[epoch: 155, i:    19] avg mini-batch loss: 0.008\n",
      "[epoch: 156, i:    19] avg mini-batch loss: 0.011\n",
      "[epoch: 157, i:    19] avg mini-batch loss: 0.003\n",
      "[epoch: 158, i:    19] avg mini-batch loss: 0.011\n",
      "[epoch: 159, i:    19] avg mini-batch loss: 0.007\n",
      "[epoch: 160, i:    19] avg mini-batch loss: 0.009\n",
      "[epoch: 161, i:    19] avg mini-batch loss: 0.010\n",
      "[epoch: 162, i:    19] avg mini-batch loss: 0.023\n",
      "[epoch: 163, i:    19] avg mini-batch loss: 0.008\n",
      "[epoch: 164, i:    19] avg mini-batch loss: 0.014\n",
      "[epoch: 165, i:    19] avg mini-batch loss: 0.009\n",
      "[epoch: 166, i:    19] avg mini-batch loss: 0.038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 167, i:    19] avg mini-batch loss: 0.020\n",
      "[epoch: 168, i:    19] avg mini-batch loss: 0.059\n",
      "[epoch: 169, i:    19] avg mini-batch loss: 0.029\n",
      "[epoch: 170, i:    19] avg mini-batch loss: 0.013\n",
      "[epoch: 171, i:    19] avg mini-batch loss: 0.010\n",
      "[epoch: 172, i:    19] avg mini-batch loss: 0.004\n",
      "[epoch: 173, i:    19] avg mini-batch loss: 0.007\n",
      "[epoch: 174, i:    19] avg mini-batch loss: 0.006\n",
      "[epoch: 175, i:    19] avg mini-batch loss: 0.003\n",
      "[epoch: 176, i:    19] avg mini-batch loss: 0.004\n",
      "[epoch: 177, i:    19] avg mini-batch loss: 0.004\n",
      "[epoch: 178, i:    19] avg mini-batch loss: 0.002\n",
      "[epoch: 179, i:    19] avg mini-batch loss: 0.001\n",
      "[epoch: 180, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 181, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 182, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 183, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 184, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 185, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 186, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 187, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 188, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 189, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 190, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 191, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 192, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 193, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 194, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 195, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 196, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 197, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 198, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 199, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 200, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 201, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 202, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 203, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 204, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 205, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 206, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 207, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 208, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 209, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 210, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 211, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 212, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 213, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 214, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 215, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 216, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 217, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 218, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 219, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 220, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 221, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 222, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 223, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 224, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 225, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 226, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 227, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 228, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 229, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 230, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 231, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 232, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 233, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 234, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 235, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 236, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 237, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 238, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 239, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 240, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 241, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 242, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 243, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 244, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 245, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 246, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 247, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 248, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 249, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 250, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 251, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 252, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 253, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 254, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 255, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 256, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 257, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 258, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 259, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 260, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 261, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 262, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 263, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 264, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 265, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 266, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 267, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 268, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 269, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 270, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 271, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 272, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 273, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 274, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 275, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 276, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 277, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 278, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 279, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 280, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 281, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 282, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 283, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 284, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 285, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 286, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 287, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 288, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 289, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 290, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 291, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 292, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 293, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 294, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 295, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 296, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 297, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 298, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 299, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 300, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 301, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 302, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 303, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 304, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 305, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 306, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 307, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 308, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 309, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 310, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 311, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 312, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 313, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 314, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 315, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 316, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 317, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 318, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 319, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 320, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 321, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 322, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 323, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 324, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 325, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 326, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 327, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 328, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 329, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 330, i:    19] avg mini-batch loss: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 331, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 332, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 333, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 334, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 335, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 336, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 337, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 338, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 339, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 340, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 341, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 342, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 343, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 344, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 345, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 346, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 347, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 348, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 349, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 350, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 351, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 352, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 353, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 354, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 355, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 356, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 357, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 358, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 359, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 360, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 361, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 362, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 363, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 364, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 365, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 366, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 367, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 368, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 369, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 370, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 371, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 372, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 373, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 374, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 375, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 376, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 377, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 378, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 379, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 380, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 381, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 382, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 383, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 384, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 385, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 386, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 387, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 388, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 389, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 390, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 391, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 392, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 393, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 394, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 395, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 396, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 397, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 398, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 399, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 400, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 401, i:    19] avg mini-batch loss: 0.000\n",
      "[epoch: 402, i:    19] avg mini-batch loss: 0.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-303-8cca21937df6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(net.parameters(), lr=0.0005)\n",
    "avg_losses = [] \n",
    "epochs = 500 \n",
    "print_freq = 20\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.permute(0, 3, 1, 2)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        opt.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1:\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Accuracy of the network on the 40 test images: 62 %\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(total)\n",
    "print('Accuracy of the network on the 40 test images: %d %%' % (100 * correct / total))\n",
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        one = torch.tensor(1, dtype=torch.float, device=device)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(40):\n",
    "            label = labels[i]\n",
    "            labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240\n",
      "Accuracy of the network on the 1240 training images: 100 %\n",
      "Accuracy of Positive : 100 %\n",
      "Accuracy of Negative : 100 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(total)\n",
    "print('Accuracy of the network on the 1240 training images: %d %%' % (100 * correct / total))\n",
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        one = torch.tensor(1, dtype=torch.float, device=device)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(40):\n",
    "            label = labels[i]\n",
    "            labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkernal size 3*3\\nstep size = 1\\nmaximum pooled layer of 2*2\\nstep size = 2\\nlearning rate = 0.0001\\nbatch size = 63\\ndropout rate = 0.5\\nk-fold: 5-fold cross validation\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "kernal size 3*3\n",
    "step size = 1\n",
    "maximum pooled layer of 2*2\n",
    "step size = 2\n",
    "learning rate = 0.0001\n",
    "batch size = 63\n",
    "dropout rate = 0.5\n",
    "k-fold: 5-fold cross validation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
