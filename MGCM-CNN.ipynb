{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For AROUSAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/the-4-convolutional-neural-network-models-that-can-classify-your-fashion-images-9fe7f3e5399d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"/Users/apple/Desktop/eeglab14_1_2b/Granger Casuality/img/\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "(32, 32, 4)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for i in range(len(onlyfiles)):\n",
    "    data = Image.open(mypath + onlyfiles[i])\n",
    "    arr = np.array(data)\n",
    "    #arr = arr[:,:,0:3]\n",
    "    #result = np.zeros((32,32))\n",
    "    #toadd = np.zeros((32,32,4))\n",
    "    #for k in range(arr.shape[2]-1):\n",
    "    #    result[:arr[:,:,k].shape[0],:arr[:,:,k].shape[1]] = arr[:,:,k] \n",
    "    #    toadd[:,:,k] = result\n",
    "    X.append(arr)\n",
    "print(len(X))\n",
    "print(X[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/apple/Desktop/eeglab14_1_2b/participant_ratings.csv',\n",
    "                sep=r'\\s*,\\s*',engine = 'python', na_values = '?')\n",
    "df.dropna()\n",
    "Y_chart = pd.get_dummies(df, drop_first=True)\n",
    "Y = Y_chart['Arousal'].tolist()\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Y)):\n",
    "    if Y[i] < 5:\n",
    "        Y[i] = 0\n",
    "    else:\n",
    "        Y[i] = 1\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=(40/len(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1240, 32, 32, 4)\n",
      "(1240,)\n",
      "(40, 32, 32, 4)\n",
      "(40,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 4)\n",
      "Image dataset has min/mean/std/max = 1.00/139.60/79.39/255.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.59/0.49/1.00\n"
     ]
    }
   ],
   "source": [
    "print('Image dataset have shape =', X_train.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train.min(),\n",
    "                        X_train.mean(), X_train.std(), X_train.max()))\n",
    "print('')\n",
    "print('Train label has shape =', y_train.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(y_train.min(),\n",
    "                        y_train.mean(), y_train.std(), y_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 4)\n",
      "Image dataset has min/mean/std/max = 0.00/0.55/0.31/1.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.59/0.49/1.00\n"
     ]
    }
   ],
   "source": [
    "def normalize_data(data): \n",
    "    data = data / data.max()\n",
    "    return data\n",
    "\n",
    "X_train = normalize_data(X_train)\n",
    "X_test = normalize_data(X_test)\n",
    "print('Image dataset have shape =', X_train.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train.min(),\n",
    "                        X_train.mean(), X_train.std(), X_train.max()))\n",
    "print('')\n",
    "print('Train label has shape =', y_train.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(y_train.min(),\n",
    "                        y_train.mean(), y_train.std(), y_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    " [transforms.ToTensor(),\n",
    " transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "tensor_x = torch.stack([torch.Tensor(i) for i in X_train])\n",
    "tensor_y = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = utils.TensorDataset(tensor_x,tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = utils.DataLoader(trainset,  batch_size= 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x_test = torch.stack([torch.Tensor(i) for i in X_test])\n",
    "tensor_y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = utils.TensorDataset(tensor_x_test,tensor_y_test)\n",
    "testloader = utils.DataLoader(testset,  batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "classes = ('Positive', 'Negative')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 32, 32, 4])\n",
      "torch.Size([40, 4, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "images = images.permute(0, 3, 1, 2)\n",
    "print(images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "rows = 1\n",
    "columns = 1\n",
    "fig=plt.figure()\n",
    "for i in range(1):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    img = images[i]\n",
    "    img = torchvision.transforms.ToPILImage()(img)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkernal size 3*3\\nstep size = 1\\nmaximum pooled layer of 2*2\\nstep size = 2\\nlearning rate = 0.0001\\nbatch size = 63\\ndropout rate = 0.5\\nk-fold: 5-fold cross validation\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "kernal size 3*3\n",
    "step size = 1\n",
    "maximum pooled layer of 2*2\n",
    "step size = 2\n",
    "learning rate = 0.0001\n",
    "batch size = 63\n",
    "dropout rate = 0.5\n",
    "k-fold: 5-fold cross validation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(4, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1280, out_features=100, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 10, 3, padding=1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(20)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(10)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(20*8*8, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(100, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 20 * 8 * 8)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_classes = 2\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 6, 3)\n",
    "        self.conv1_bn = nn.BatchNorm2d(20)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.conv2_bn = nn.BatchNorm2d(10)\n",
    "        \n",
    "        #spatial transformer localization\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(4, 10, 3, padding = 1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(10, 20, 3, padding=1),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.ReLU(True)\n",
    "            \n",
    "        ) '''\n",
    "        #add an regressor\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(16*6*6, 96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(96, 6),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(6, num_classes),\n",
    "        )\n",
    "   \n",
    "    def forward(self, x):\n",
    "        #x = self.stn(x)\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        #x = F.dropout2d(x, p=0.5)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.flat(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    #spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        #xs = self.flat(xs)\n",
    "        theta = self.classifier(xs)\n",
    "        theta = theta.view(-1,2,3)\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x,grid)\n",
    "        return x\n",
    "        '''\n",
    "        \n",
    "    def flat(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num = 1\n",
    "        for s in size:\n",
    "            num *= s\n",
    "        return num\n",
    "    \n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.hub.load('pytorch/vision:v0.4.2', 'squeezenet1_0', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 1, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 2, i:    19] avg mini-batch loss: 0.683\n",
      "[epoch: 3, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 4, i:    19] avg mini-batch loss: 0.681\n",
      "[epoch: 5, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 6, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 7, i:    19] avg mini-batch loss: 0.681\n",
      "[epoch: 8, i:    19] avg mini-batch loss: 0.681\n",
      "[epoch: 9, i:    19] avg mini-batch loss: 0.681\n",
      "[epoch: 10, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 11, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 12, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 13, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 14, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 15, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 16, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 17, i:    19] avg mini-batch loss: 0.681\n",
      "[epoch: 18, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 19, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 20, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 21, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 22, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 23, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 24, i:    19] avg mini-batch loss: 0.681\n",
      "[epoch: 25, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 26, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 27, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 28, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 29, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 30, i:    19] avg mini-batch loss: 0.681\n",
      "[epoch: 31, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 32, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 33, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 34, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 35, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 36, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 37, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 38, i:    19] avg mini-batch loss: 0.681\n",
      "[epoch: 39, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 40, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 41, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 42, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 43, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 44, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 45, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 46, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 47, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 48, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 49, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 50, i:    19] avg mini-batch loss: 0.681\n",
      "[epoch: 51, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 52, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 53, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 54, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 55, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 56, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 57, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 58, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 59, i:    19] avg mini-batch loss: 0.681\n",
      "[epoch: 60, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 61, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 62, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 63, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 64, i:    19] avg mini-batch loss: 0.681\n",
      "[epoch: 65, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 66, i:    19] avg mini-batch loss: 0.681\n",
      "[epoch: 67, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 68, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 69, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 70, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 71, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 72, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 73, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 74, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 75, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 76, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 77, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 78, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 79, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 80, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 81, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 82, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 83, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 84, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 85, i:    19] avg mini-batch loss: 0.681\n",
      "[epoch: 86, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 87, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 88, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 89, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 90, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 91, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 92, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 93, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 94, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 95, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 96, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 97, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 98, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 99, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 100, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 101, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 102, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 103, i:    19] avg mini-batch loss: 0.681\n",
      "[epoch: 104, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 105, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 106, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 107, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 108, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 109, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 110, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 111, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 112, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 113, i:    19] avg mini-batch loss: 0.678\n",
      "[epoch: 114, i:    19] avg mini-batch loss: 0.677\n",
      "[epoch: 115, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 116, i:    19] avg mini-batch loss: 0.677\n",
      "[epoch: 117, i:    19] avg mini-batch loss: 0.680\n",
      "[epoch: 118, i:    19] avg mini-batch loss: 0.678\n",
      "[epoch: 119, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 120, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 121, i:    19] avg mini-batch loss: 0.679\n",
      "[epoch: 122, i:    19] avg mini-batch loss: 0.675\n",
      "[epoch: 123, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 124, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 125, i:    19] avg mini-batch loss: 0.678\n",
      "[epoch: 126, i:    19] avg mini-batch loss: 0.677\n",
      "[epoch: 127, i:    19] avg mini-batch loss: 0.675\n",
      "[epoch: 128, i:    19] avg mini-batch loss: 0.674\n",
      "[epoch: 129, i:    19] avg mini-batch loss: 0.678\n",
      "[epoch: 130, i:    19] avg mini-batch loss: 0.677\n",
      "[epoch: 131, i:    19] avg mini-batch loss: 0.674\n",
      "[epoch: 132, i:    19] avg mini-batch loss: 0.678\n",
      "[epoch: 133, i:    19] avg mini-batch loss: 0.674\n",
      "[epoch: 134, i:    19] avg mini-batch loss: 0.668\n",
      "[epoch: 135, i:    19] avg mini-batch loss: 0.675\n",
      "[epoch: 136, i:    19] avg mini-batch loss: 0.676\n",
      "[epoch: 137, i:    19] avg mini-batch loss: 0.671\n",
      "[epoch: 138, i:    19] avg mini-batch loss: 0.670\n",
      "[epoch: 139, i:    19] avg mini-batch loss: 0.670\n",
      "[epoch: 140, i:    19] avg mini-batch loss: 0.671\n",
      "[epoch: 141, i:    19] avg mini-batch loss: 0.674\n",
      "[epoch: 142, i:    19] avg mini-batch loss: 0.664\n",
      "[epoch: 143, i:    19] avg mini-batch loss: 0.670\n",
      "[epoch: 144, i:    19] avg mini-batch loss: 0.668\n",
      "[epoch: 145, i:    19] avg mini-batch loss: 0.664\n",
      "[epoch: 146, i:    19] avg mini-batch loss: 0.661\n",
      "[epoch: 147, i:    19] avg mini-batch loss: 0.659\n",
      "[epoch: 148, i:    19] avg mini-batch loss: 0.658\n",
      "[epoch: 149, i:    19] avg mini-batch loss: 0.653\n",
      "[epoch: 150, i:    19] avg mini-batch loss: 0.656\n",
      "[epoch: 151, i:    19] avg mini-batch loss: 0.659\n",
      "[epoch: 152, i:    19] avg mini-batch loss: 0.646\n",
      "[epoch: 153, i:    19] avg mini-batch loss: 0.656\n",
      "[epoch: 154, i:    19] avg mini-batch loss: 0.657\n",
      "[epoch: 155, i:    19] avg mini-batch loss: 0.662\n",
      "[epoch: 156, i:    19] avg mini-batch loss: 0.647\n",
      "[epoch: 157, i:    19] avg mini-batch loss: 0.639\n",
      "[epoch: 158, i:    19] avg mini-batch loss: 0.647\n",
      "[epoch: 159, i:    19] avg mini-batch loss: 0.653\n",
      "[epoch: 160, i:    19] avg mini-batch loss: 0.639\n",
      "[epoch: 161, i:    19] avg mini-batch loss: 0.639\n",
      "[epoch: 162, i:    19] avg mini-batch loss: 0.639\n",
      "[epoch: 163, i:    19] avg mini-batch loss: 0.647\n",
      "[epoch: 164, i:    19] avg mini-batch loss: 0.640\n",
      "[epoch: 165, i:    19] avg mini-batch loss: 0.631\n",
      "[epoch: 166, i:    19] avg mini-batch loss: 0.634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 167, i:    19] avg mini-batch loss: 0.662\n",
      "[epoch: 168, i:    19] avg mini-batch loss: 0.643\n",
      "[epoch: 169, i:    19] avg mini-batch loss: 0.647\n",
      "[epoch: 170, i:    19] avg mini-batch loss: 0.641\n",
      "[epoch: 171, i:    19] avg mini-batch loss: 0.647\n",
      "[epoch: 172, i:    19] avg mini-batch loss: 0.630\n",
      "[epoch: 173, i:    19] avg mini-batch loss: 0.620\n",
      "[epoch: 174, i:    19] avg mini-batch loss: 0.626\n",
      "[epoch: 175, i:    19] avg mini-batch loss: 0.628\n",
      "[epoch: 176, i:    19] avg mini-batch loss: 0.624\n",
      "[epoch: 177, i:    19] avg mini-batch loss: 0.609\n",
      "[epoch: 178, i:    19] avg mini-batch loss: 0.616\n",
      "[epoch: 179, i:    19] avg mini-batch loss: 0.611\n",
      "[epoch: 180, i:    19] avg mini-batch loss: 0.611\n",
      "[epoch: 181, i:    19] avg mini-batch loss: 0.594\n",
      "[epoch: 182, i:    19] avg mini-batch loss: 0.601\n",
      "[epoch: 183, i:    19] avg mini-batch loss: 0.611\n",
      "[epoch: 184, i:    19] avg mini-batch loss: 0.613\n",
      "[epoch: 185, i:    19] avg mini-batch loss: 0.596\n",
      "[epoch: 186, i:    19] avg mini-batch loss: 0.582\n",
      "[epoch: 187, i:    19] avg mini-batch loss: 0.595\n",
      "[epoch: 188, i:    19] avg mini-batch loss: 0.600\n",
      "[epoch: 189, i:    19] avg mini-batch loss: 0.595\n",
      "[epoch: 190, i:    19] avg mini-batch loss: 0.588\n",
      "[epoch: 191, i:    19] avg mini-batch loss: 0.573\n",
      "[epoch: 192, i:    19] avg mini-batch loss: 0.584\n",
      "[epoch: 193, i:    19] avg mini-batch loss: 0.590\n",
      "[epoch: 194, i:    19] avg mini-batch loss: 0.588\n",
      "[epoch: 195, i:    19] avg mini-batch loss: 0.591\n",
      "[epoch: 196, i:    19] avg mini-batch loss: 0.579\n",
      "[epoch: 197, i:    19] avg mini-batch loss: 0.592\n",
      "[epoch: 198, i:    19] avg mini-batch loss: 0.564\n",
      "[epoch: 199, i:    19] avg mini-batch loss: 0.586\n",
      "[epoch: 200, i:    19] avg mini-batch loss: 0.570\n",
      "[epoch: 201, i:    19] avg mini-batch loss: 0.561\n",
      "[epoch: 202, i:    19] avg mini-batch loss: 0.563\n",
      "[epoch: 203, i:    19] avg mini-batch loss: 0.556\n",
      "[epoch: 204, i:    19] avg mini-batch loss: 0.575\n",
      "[epoch: 205, i:    19] avg mini-batch loss: 0.555\n",
      "[epoch: 206, i:    19] avg mini-batch loss: 0.566\n",
      "[epoch: 207, i:    19] avg mini-batch loss: 0.575\n",
      "[epoch: 208, i:    19] avg mini-batch loss: 0.561\n",
      "[epoch: 209, i:    19] avg mini-batch loss: 0.565\n",
      "[epoch: 210, i:    19] avg mini-batch loss: 0.541\n",
      "[epoch: 211, i:    19] avg mini-batch loss: 0.539\n",
      "[epoch: 212, i:    19] avg mini-batch loss: 0.526\n",
      "[epoch: 213, i:    19] avg mini-batch loss: 0.538\n",
      "[epoch: 214, i:    19] avg mini-batch loss: 0.535\n",
      "[epoch: 215, i:    19] avg mini-batch loss: 0.547\n",
      "[epoch: 216, i:    19] avg mini-batch loss: 0.538\n",
      "[epoch: 217, i:    19] avg mini-batch loss: 0.518\n",
      "[epoch: 218, i:    19] avg mini-batch loss: 0.504\n",
      "[epoch: 219, i:    19] avg mini-batch loss: 0.514\n",
      "[epoch: 220, i:    19] avg mini-batch loss: 0.517\n",
      "[epoch: 221, i:    19] avg mini-batch loss: 0.528\n",
      "[epoch: 222, i:    19] avg mini-batch loss: 0.505\n",
      "[epoch: 223, i:    19] avg mini-batch loss: 0.519\n",
      "[epoch: 224, i:    19] avg mini-batch loss: 0.524\n",
      "[epoch: 225, i:    19] avg mini-batch loss: 0.501\n",
      "[epoch: 226, i:    19] avg mini-batch loss: 0.488\n",
      "[epoch: 227, i:    19] avg mini-batch loss: 0.471\n",
      "[epoch: 228, i:    19] avg mini-batch loss: 0.498\n",
      "[epoch: 229, i:    19] avg mini-batch loss: 0.497\n",
      "[epoch: 230, i:    19] avg mini-batch loss: 0.526\n",
      "[epoch: 231, i:    19] avg mini-batch loss: 0.482\n",
      "[epoch: 232, i:    19] avg mini-batch loss: 0.507\n",
      "[epoch: 233, i:    19] avg mini-batch loss: 0.452\n",
      "[epoch: 234, i:    19] avg mini-batch loss: 0.483\n",
      "[epoch: 235, i:    19] avg mini-batch loss: 0.482\n",
      "[epoch: 236, i:    19] avg mini-batch loss: 0.466\n",
      "[epoch: 237, i:    19] avg mini-batch loss: 0.458\n",
      "[epoch: 238, i:    19] avg mini-batch loss: 0.437\n",
      "[epoch: 239, i:    19] avg mini-batch loss: 0.467\n",
      "[epoch: 240, i:    19] avg mini-batch loss: 0.431\n",
      "[epoch: 241, i:    19] avg mini-batch loss: 0.459\n",
      "[epoch: 242, i:    19] avg mini-batch loss: 0.446\n",
      "[epoch: 243, i:    19] avg mini-batch loss: 0.408\n",
      "[epoch: 244, i:    19] avg mini-batch loss: 0.455\n",
      "[epoch: 245, i:    19] avg mini-batch loss: 0.445\n",
      "[epoch: 246, i:    19] avg mini-batch loss: 0.421\n",
      "[epoch: 247, i:    19] avg mini-batch loss: 0.406\n",
      "[epoch: 248, i:    19] avg mini-batch loss: 0.379\n",
      "[epoch: 249, i:    19] avg mini-batch loss: 0.383\n",
      "[epoch: 250, i:    19] avg mini-batch loss: 0.375\n",
      "[epoch: 251, i:    19] avg mini-batch loss: 0.387\n",
      "[epoch: 252, i:    19] avg mini-batch loss: 0.393\n",
      "[epoch: 253, i:    19] avg mini-batch loss: 0.389\n",
      "[epoch: 254, i:    19] avg mini-batch loss: 0.363\n",
      "[epoch: 255, i:    19] avg mini-batch loss: 0.384\n",
      "[epoch: 256, i:    19] avg mini-batch loss: 0.405\n",
      "[epoch: 257, i:    19] avg mini-batch loss: 0.348\n",
      "[epoch: 258, i:    19] avg mini-batch loss: 0.355\n",
      "[epoch: 259, i:    19] avg mini-batch loss: 0.332\n",
      "[epoch: 260, i:    19] avg mini-batch loss: 0.356\n",
      "[epoch: 261, i:    19] avg mini-batch loss: 0.355\n",
      "[epoch: 262, i:    19] avg mini-batch loss: 0.334\n",
      "[epoch: 263, i:    19] avg mini-batch loss: 0.322\n",
      "[epoch: 264, i:    19] avg mini-batch loss: 0.335\n",
      "[epoch: 265, i:    19] avg mini-batch loss: 0.342\n",
      "[epoch: 266, i:    19] avg mini-batch loss: 0.342\n",
      "[epoch: 267, i:    19] avg mini-batch loss: 0.314\n",
      "[epoch: 268, i:    19] avg mini-batch loss: 0.339\n",
      "[epoch: 269, i:    19] avg mini-batch loss: 0.326\n",
      "[epoch: 270, i:    19] avg mini-batch loss: 0.302\n",
      "[epoch: 271, i:    19] avg mini-batch loss: 0.325\n",
      "[epoch: 272, i:    19] avg mini-batch loss: 0.317\n",
      "[epoch: 273, i:    19] avg mini-batch loss: 0.358\n",
      "[epoch: 274, i:    19] avg mini-batch loss: 0.365\n",
      "[epoch: 275, i:    19] avg mini-batch loss: 0.318\n",
      "[epoch: 276, i:    19] avg mini-batch loss: 0.292\n",
      "[epoch: 277, i:    19] avg mini-batch loss: 0.294\n",
      "[epoch: 278, i:    19] avg mini-batch loss: 0.350\n",
      "[epoch: 279, i:    19] avg mini-batch loss: 0.368\n",
      "[epoch: 280, i:    19] avg mini-batch loss: 0.364\n",
      "[epoch: 281, i:    19] avg mini-batch loss: 0.333\n",
      "[epoch: 282, i:    19] avg mini-batch loss: 0.354\n",
      "[epoch: 283, i:    19] avg mini-batch loss: 0.373\n",
      "[epoch: 284, i:    19] avg mini-batch loss: 0.372\n",
      "[epoch: 285, i:    19] avg mini-batch loss: 0.328\n",
      "[epoch: 286, i:    19] avg mini-batch loss: 0.382\n",
      "[epoch: 287, i:    19] avg mini-batch loss: 0.296\n",
      "[epoch: 288, i:    19] avg mini-batch loss: 0.294\n",
      "[epoch: 289, i:    19] avg mini-batch loss: 0.281\n",
      "[epoch: 290, i:    19] avg mini-batch loss: 0.293\n",
      "[epoch: 291, i:    19] avg mini-batch loss: 0.341\n",
      "[epoch: 292, i:    19] avg mini-batch loss: 0.290\n",
      "[epoch: 293, i:    19] avg mini-batch loss: 0.263\n",
      "[epoch: 294, i:    19] avg mini-batch loss: 0.272\n",
      "[epoch: 295, i:    19] avg mini-batch loss: 0.276\n",
      "[epoch: 296, i:    19] avg mini-batch loss: 0.303\n",
      "[epoch: 297, i:    19] avg mini-batch loss: 0.251\n",
      "[epoch: 298, i:    19] avg mini-batch loss: 0.226\n",
      "[epoch: 299, i:    19] avg mini-batch loss: 0.273\n",
      "[epoch: 300, i:    19] avg mini-batch loss: 0.256\n",
      "[epoch: 301, i:    19] avg mini-batch loss: 0.244\n",
      "[epoch: 302, i:    19] avg mini-batch loss: 0.267\n",
      "[epoch: 303, i:    19] avg mini-batch loss: 0.239\n",
      "[epoch: 304, i:    19] avg mini-batch loss: 0.243\n",
      "[epoch: 305, i:    19] avg mini-batch loss: 0.215\n",
      "[epoch: 306, i:    19] avg mini-batch loss: 0.242\n",
      "[epoch: 307, i:    19] avg mini-batch loss: 0.240\n",
      "[epoch: 308, i:    19] avg mini-batch loss: 0.232\n",
      "[epoch: 309, i:    19] avg mini-batch loss: 0.181\n",
      "[epoch: 310, i:    19] avg mini-batch loss: 0.222\n",
      "[epoch: 311, i:    19] avg mini-batch loss: 0.249\n",
      "[epoch: 312, i:    19] avg mini-batch loss: 0.232\n",
      "[epoch: 313, i:    19] avg mini-batch loss: 0.221\n",
      "[epoch: 314, i:    19] avg mini-batch loss: 0.157\n",
      "[epoch: 315, i:    19] avg mini-batch loss: 0.215\n",
      "[epoch: 316, i:    19] avg mini-batch loss: 0.193\n",
      "[epoch: 317, i:    19] avg mini-batch loss: 0.204\n",
      "[epoch: 318, i:    19] avg mini-batch loss: 0.220\n",
      "[epoch: 319, i:    19] avg mini-batch loss: 0.190\n",
      "[epoch: 320, i:    19] avg mini-batch loss: 0.233\n",
      "[epoch: 321, i:    19] avg mini-batch loss: 0.209\n",
      "[epoch: 322, i:    19] avg mini-batch loss: 0.189\n",
      "[epoch: 323, i:    19] avg mini-batch loss: 0.168\n",
      "[epoch: 324, i:    19] avg mini-batch loss: 0.203\n",
      "[epoch: 325, i:    19] avg mini-batch loss: 0.185\n",
      "[epoch: 326, i:    19] avg mini-batch loss: 0.197\n",
      "[epoch: 327, i:    19] avg mini-batch loss: 0.197\n",
      "[epoch: 328, i:    19] avg mini-batch loss: 0.187\n",
      "[epoch: 329, i:    19] avg mini-batch loss: 0.196\n",
      "[epoch: 330, i:    19] avg mini-batch loss: 0.165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 331, i:    19] avg mini-batch loss: 0.177\n",
      "[epoch: 332, i:    19] avg mini-batch loss: 0.189\n",
      "[epoch: 333, i:    19] avg mini-batch loss: 0.157\n",
      "[epoch: 334, i:    19] avg mini-batch loss: 0.156\n",
      "[epoch: 335, i:    19] avg mini-batch loss: 0.182\n",
      "[epoch: 336, i:    19] avg mini-batch loss: 0.176\n",
      "[epoch: 337, i:    19] avg mini-batch loss: 0.172\n",
      "[epoch: 338, i:    19] avg mini-batch loss: 0.176\n",
      "[epoch: 339, i:    19] avg mini-batch loss: 0.180\n",
      "[epoch: 340, i:    19] avg mini-batch loss: 0.232\n",
      "[epoch: 341, i:    19] avg mini-batch loss: 0.189\n",
      "[epoch: 342, i:    19] avg mini-batch loss: 0.195\n",
      "[epoch: 343, i:    19] avg mini-batch loss: 0.172\n",
      "[epoch: 344, i:    19] avg mini-batch loss: 0.158\n",
      "[epoch: 345, i:    19] avg mini-batch loss: 0.182\n",
      "[epoch: 346, i:    19] avg mini-batch loss: 0.177\n",
      "[epoch: 347, i:    19] avg mini-batch loss: 0.139\n",
      "[epoch: 348, i:    19] avg mini-batch loss: 0.174\n",
      "[epoch: 349, i:    19] avg mini-batch loss: 0.141\n",
      "[epoch: 350, i:    19] avg mini-batch loss: 0.158\n",
      "[epoch: 351, i:    19] avg mini-batch loss: 0.149\n",
      "[epoch: 352, i:    19] avg mini-batch loss: 0.185\n",
      "[epoch: 353, i:    19] avg mini-batch loss: 0.144\n",
      "[epoch: 354, i:    19] avg mini-batch loss: 0.144\n",
      "[epoch: 355, i:    19] avg mini-batch loss: 0.169\n",
      "[epoch: 356, i:    19] avg mini-batch loss: 0.138\n",
      "[epoch: 357, i:    19] avg mini-batch loss: 0.163\n",
      "[epoch: 358, i:    19] avg mini-batch loss: 0.169\n",
      "[epoch: 359, i:    19] avg mini-batch loss: 0.146\n",
      "[epoch: 360, i:    19] avg mini-batch loss: 0.149\n",
      "[epoch: 361, i:    19] avg mini-batch loss: 0.159\n",
      "[epoch: 362, i:    19] avg mini-batch loss: 0.161\n",
      "[epoch: 363, i:    19] avg mini-batch loss: 0.154\n",
      "[epoch: 364, i:    19] avg mini-batch loss: 0.159\n",
      "[epoch: 365, i:    19] avg mini-batch loss: 0.142\n",
      "[epoch: 366, i:    19] avg mini-batch loss: 0.155\n",
      "[epoch: 367, i:    19] avg mini-batch loss: 0.162\n",
      "[epoch: 368, i:    19] avg mini-batch loss: 0.120\n",
      "[epoch: 369, i:    19] avg mini-batch loss: 0.132\n",
      "[epoch: 370, i:    19] avg mini-batch loss: 0.143\n",
      "[epoch: 371, i:    19] avg mini-batch loss: 0.125\n",
      "[epoch: 372, i:    19] avg mini-batch loss: 0.168\n",
      "[epoch: 373, i:    19] avg mini-batch loss: 0.170\n",
      "[epoch: 374, i:    19] avg mini-batch loss: 0.169\n",
      "[epoch: 375, i:    19] avg mini-batch loss: 0.128\n",
      "[epoch: 376, i:    19] avg mini-batch loss: 0.161\n",
      "[epoch: 377, i:    19] avg mini-batch loss: 0.140\n",
      "[epoch: 378, i:    19] avg mini-batch loss: 0.122\n",
      "[epoch: 379, i:    19] avg mini-batch loss: 0.144\n",
      "[epoch: 380, i:    19] avg mini-batch loss: 0.146\n",
      "[epoch: 381, i:    19] avg mini-batch loss: 0.145\n",
      "[epoch: 382, i:    19] avg mini-batch loss: 0.112\n",
      "[epoch: 383, i:    19] avg mini-batch loss: 0.133\n",
      "[epoch: 384, i:    19] avg mini-batch loss: 0.151\n",
      "[epoch: 385, i:    19] avg mini-batch loss: 0.147\n",
      "[epoch: 386, i:    19] avg mini-batch loss: 0.142\n",
      "[epoch: 387, i:    19] avg mini-batch loss: 0.151\n",
      "[epoch: 388, i:    19] avg mini-batch loss: 0.140\n",
      "[epoch: 389, i:    19] avg mini-batch loss: 0.106\n",
      "[epoch: 390, i:    19] avg mini-batch loss: 0.142\n",
      "[epoch: 391, i:    19] avg mini-batch loss: 0.129\n",
      "[epoch: 392, i:    19] avg mini-batch loss: 0.131\n",
      "[epoch: 393, i:    19] avg mini-batch loss: 0.118\n",
      "[epoch: 394, i:    19] avg mini-batch loss: 0.163\n",
      "[epoch: 395, i:    19] avg mini-batch loss: 0.126\n",
      "[epoch: 396, i:    19] avg mini-batch loss: 0.136\n",
      "[epoch: 397, i:    19] avg mini-batch loss: 0.119\n",
      "[epoch: 398, i:    19] avg mini-batch loss: 0.138\n",
      "[epoch: 399, i:    19] avg mini-batch loss: 0.138\n",
      "[epoch: 400, i:    19] avg mini-batch loss: 0.158\n",
      "[epoch: 401, i:    19] avg mini-batch loss: 0.134\n",
      "[epoch: 402, i:    19] avg mini-batch loss: 0.125\n",
      "[epoch: 403, i:    19] avg mini-batch loss: 0.128\n",
      "[epoch: 404, i:    19] avg mini-batch loss: 0.149\n",
      "[epoch: 405, i:    19] avg mini-batch loss: 0.147\n",
      "[epoch: 406, i:    19] avg mini-batch loss: 0.132\n",
      "[epoch: 407, i:    19] avg mini-batch loss: 0.088\n",
      "[epoch: 408, i:    19] avg mini-batch loss: 0.101\n",
      "[epoch: 409, i:    19] avg mini-batch loss: 0.133\n",
      "[epoch: 410, i:    19] avg mini-batch loss: 0.106\n",
      "[epoch: 411, i:    19] avg mini-batch loss: 0.161\n",
      "[epoch: 412, i:    19] avg mini-batch loss: 0.122\n",
      "[epoch: 413, i:    19] avg mini-batch loss: 0.128\n",
      "[epoch: 414, i:    19] avg mini-batch loss: 0.129\n",
      "[epoch: 415, i:    19] avg mini-batch loss: 0.140\n",
      "[epoch: 416, i:    19] avg mini-batch loss: 0.160\n",
      "[epoch: 417, i:    19] avg mini-batch loss: 0.143\n",
      "[epoch: 418, i:    19] avg mini-batch loss: 0.178\n",
      "[epoch: 419, i:    19] avg mini-batch loss: 0.118\n",
      "[epoch: 420, i:    19] avg mini-batch loss: 0.113\n",
      "[epoch: 421, i:    19] avg mini-batch loss: 0.136\n",
      "[epoch: 422, i:    19] avg mini-batch loss: 0.115\n",
      "[epoch: 423, i:    19] avg mini-batch loss: 0.115\n",
      "[epoch: 424, i:    19] avg mini-batch loss: 0.147\n",
      "[epoch: 425, i:    19] avg mini-batch loss: 0.126\n",
      "[epoch: 426, i:    19] avg mini-batch loss: 0.109\n",
      "[epoch: 427, i:    19] avg mini-batch loss: 0.119\n",
      "[epoch: 428, i:    19] avg mini-batch loss: 0.098\n",
      "[epoch: 429, i:    19] avg mini-batch loss: 0.113\n",
      "[epoch: 430, i:    19] avg mini-batch loss: 0.125\n",
      "[epoch: 431, i:    19] avg mini-batch loss: 0.118\n",
      "[epoch: 432, i:    19] avg mini-batch loss: 0.109\n",
      "[epoch: 433, i:    19] avg mini-batch loss: 0.089\n",
      "[epoch: 434, i:    19] avg mini-batch loss: 0.144\n",
      "[epoch: 435, i:    19] avg mini-batch loss: 0.104\n",
      "[epoch: 436, i:    19] avg mini-batch loss: 0.133\n",
      "[epoch: 437, i:    19] avg mini-batch loss: 0.104\n",
      "[epoch: 438, i:    19] avg mini-batch loss: 0.148\n",
      "[epoch: 439, i:    19] avg mini-batch loss: 0.130\n",
      "[epoch: 440, i:    19] avg mini-batch loss: 0.094\n",
      "[epoch: 441, i:    19] avg mini-batch loss: 0.105\n",
      "[epoch: 442, i:    19] avg mini-batch loss: 0.096\n",
      "[epoch: 443, i:    19] avg mini-batch loss: 0.080\n",
      "[epoch: 444, i:    19] avg mini-batch loss: 0.120\n",
      "[epoch: 445, i:    19] avg mini-batch loss: 0.108\n",
      "[epoch: 446, i:    19] avg mini-batch loss: 0.146\n",
      "[epoch: 447, i:    19] avg mini-batch loss: 0.094\n",
      "[epoch: 448, i:    19] avg mini-batch loss: 0.103\n",
      "[epoch: 449, i:    19] avg mini-batch loss: 0.113\n",
      "[epoch: 450, i:    19] avg mini-batch loss: 0.100\n",
      "[epoch: 451, i:    19] avg mini-batch loss: 0.101\n",
      "[epoch: 452, i:    19] avg mini-batch loss: 0.103\n",
      "[epoch: 453, i:    19] avg mini-batch loss: 0.091\n",
      "[epoch: 454, i:    19] avg mini-batch loss: 0.108\n",
      "[epoch: 455, i:    19] avg mini-batch loss: 0.149\n",
      "[epoch: 456, i:    19] avg mini-batch loss: 0.134\n",
      "[epoch: 457, i:    19] avg mini-batch loss: 0.096\n",
      "[epoch: 458, i:    19] avg mini-batch loss: 0.099\n",
      "[epoch: 459, i:    19] avg mini-batch loss: 0.113\n",
      "[epoch: 460, i:    19] avg mini-batch loss: 0.156\n",
      "[epoch: 461, i:    19] avg mini-batch loss: 0.110\n",
      "[epoch: 462, i:    19] avg mini-batch loss: 0.139\n",
      "[epoch: 463, i:    19] avg mini-batch loss: 0.118\n",
      "[epoch: 464, i:    19] avg mini-batch loss: 0.101\n",
      "[epoch: 465, i:    19] avg mini-batch loss: 0.098\n",
      "[epoch: 466, i:    19] avg mini-batch loss: 0.113\n",
      "[epoch: 467, i:    19] avg mini-batch loss: 0.097\n",
      "[epoch: 468, i:    19] avg mini-batch loss: 0.128\n",
      "[epoch: 469, i:    19] avg mini-batch loss: 0.105\n",
      "[epoch: 470, i:    19] avg mini-batch loss: 0.137\n",
      "[epoch: 471, i:    19] avg mini-batch loss: 0.099\n",
      "[epoch: 472, i:    19] avg mini-batch loss: 0.097\n",
      "[epoch: 473, i:    19] avg mini-batch loss: 0.088\n",
      "[epoch: 474, i:    19] avg mini-batch loss: 0.095\n",
      "[epoch: 475, i:    19] avg mini-batch loss: 0.089\n",
      "[epoch: 476, i:    19] avg mini-batch loss: 0.112\n",
      "[epoch: 477, i:    19] avg mini-batch loss: 0.089\n",
      "[epoch: 478, i:    19] avg mini-batch loss: 0.095\n",
      "[epoch: 479, i:    19] avg mini-batch loss: 0.104\n",
      "[epoch: 480, i:    19] avg mini-batch loss: 0.107\n",
      "[epoch: 481, i:    19] avg mini-batch loss: 0.138\n",
      "[epoch: 482, i:    19] avg mini-batch loss: 0.104\n",
      "[epoch: 483, i:    19] avg mini-batch loss: 0.116\n",
      "[epoch: 484, i:    19] avg mini-batch loss: 0.112\n",
      "[epoch: 485, i:    19] avg mini-batch loss: 0.101\n",
      "[epoch: 486, i:    19] avg mini-batch loss: 0.080\n",
      "[epoch: 487, i:    19] avg mini-batch loss: 0.102\n",
      "[epoch: 488, i:    19] avg mini-batch loss: 0.097\n",
      "[epoch: 489, i:    19] avg mini-batch loss: 0.136\n",
      "[epoch: 490, i:    19] avg mini-batch loss: 0.106\n",
      "[epoch: 491, i:    19] avg mini-batch loss: 0.092\n",
      "[epoch: 492, i:    19] avg mini-batch loss: 0.112\n",
      "[epoch: 493, i:    19] avg mini-batch loss: 0.097\n",
      "[epoch: 494, i:    19] avg mini-batch loss: 0.102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 495, i:    19] avg mini-batch loss: 0.130\n",
      "[epoch: 496, i:    19] avg mini-batch loss: 0.115\n",
      "[epoch: 497, i:    19] avg mini-batch loss: 0.103\n",
      "[epoch: 498, i:    19] avg mini-batch loss: 0.080\n",
      "[epoch: 499, i:    19] avg mini-batch loss: 0.097\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "#opt = torch.optim.Adam(net.parameters(), lr= 0.001)\n",
    "#opt = torch.optim.Adamax(net.parameters(), lr=0.01)\n",
    "opt = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "#opt = torch.optim.Adagrad(net.parameters(), lr=0.0)\n",
    "avg_losses = [] \n",
    "epochs = 500\n",
    "print_freq = 20\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.permute(0, 3, 1, 2)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        opt.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1:\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Accuracy of the network on the 40 test images: 50 %\n",
      "Accuracy of Positive : 44 %\n",
      "Accuracy of Negative : 54 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(total)\n",
    "print('Accuracy of the network on the 40 test images: %d %%' % (100 * correct / total))\n",
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        one = torch.tensor(1, dtype=torch.float, device=device)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(40):\n",
    "            label = labels[i]\n",
    "            labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240\n",
      "Accuracy of the network on the 1240 training images: 100 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Positive : 100 %\n",
      "Accuracy of Negative : 100 %\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(total)\n",
    "print('Accuracy of the network on the 1240 training images: %d %%' % (100 * correct / total))\n",
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        one = torch.tensor(1, dtype=torch.float, device=device)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(40):\n",
    "            label = labels[i]\n",
    "            labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkernal size 3*3\\nstep size = 1\\nmaximum pooled layer of 2*2\\nstep size = 2\\nlearning rate = 0.0001\\nbatch size = 63\\ndropout rate = 0.5\\nk-fold: 5-fold cross validation\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "kernal size 3*3\n",
    "step size = 1\n",
    "maximum pooled layer of 2*2\n",
    "step size = 2\n",
    "learning rate = 0.0001\n",
    "batch size = 63\n",
    "dropout rate = 0.5\n",
    "k-fold: 5-fold cross validation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
