{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suppress Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "old = sys.stdout\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "def enablePrint():\n",
    "    sys.stdout = old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Back Projected ICA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trials is: 40\n",
      "Total number of channels in each trial is: 32\n",
      "Total number of time points in per channel per trial is: 8064\n"
     ]
    }
   ],
   "source": [
    "enablePrint()\n",
    "filepath = '/Users/apple/Desktop/eeglab14_1_2b/ICA_Data/EEGData1.mat'\n",
    "mat_contents = sio.loadmat(filepath)\n",
    "ica = mat_contents['data']\n",
    "temp_trial = ica[:,:,1]\n",
    "trial = ica.shape[2]\n",
    "print(\"{}: {}\".format(\"Total number of trials is\", trial))\n",
    "channel = temp_trial.shape[0]\n",
    "print(\"{}: {}\".format(\"Total number of channels in each trial is\", channel))\n",
    "timepoint = temp_trial.shape[1]\n",
    "print(\"{}: {}\".format(\"Total number of time points in per channel per trial is\", timepoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing between 1 trial 2 channels with GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.tsa.stattools as stm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8064)\n",
      "(32, 807)\n"
     ]
    }
   ],
   "source": [
    "#we just gonna pick temp_trial\n",
    "print(temp_trial.shape)\n",
    "temp_trial = temp_trial[:,1::10]\n",
    "print(temp_trial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8064, 2)\n"
     ]
    }
   ],
   "source": [
    "a = np.asarray(temp_trial[0,:])\n",
    "b = np.asarray(temp_trial[1,:])\n",
    "x = np.vstack((a, b)).T\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lag: 36\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.ar_model import AR\n",
    "model = AR(a)\n",
    "model_fit = model.fit()\n",
    "print('Lag: %s' % model_fit.k_ar)\n",
    "maxlag = model_fit.k_ar\n",
    "if maxlag > 5:\n",
    "    maxlag =5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "addconst = True\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=137.4970, p=0.0000  , df_denom=8060, df_num=1\n",
      "ssr based chi2 test:   chi2=137.5481, p=0.0000  , df=1\n",
      "likelihood ratio test: chi2=136.3881, p=0.0000  , df=1\n",
      "parameter F test:         F=137.4970, p=0.0000  , df_denom=8060, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=311.0022, p=0.0000  , df_denom=8057, df_num=2\n",
      "ssr based chi2 test:   chi2=622.3905, p=0.0000  , df=2\n",
      "likelihood ratio test: chi2=599.5351, p=0.0000  , df=2\n",
      "parameter F test:         F=311.0022, p=0.0000  , df_denom=8057, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=283.9087, p=0.0000  , df_denom=8054, df_num=3\n",
      "ssr based chi2 test:   chi2=852.4664, p=0.0000  , df=3\n",
      "likelihood ratio test: chi2=810.3369, p=0.0000  , df=3\n",
      "parameter F test:         F=283.9087, p=0.0000  , df_denom=8054, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=215.8010, p=0.0000  , df_denom=8051, df_num=4\n",
      "ssr based chi2 test:   chi2=864.1688, p=0.0000  , df=4\n",
      "likelihood ratio test: chi2=820.9081, p=0.0000  , df=4\n",
      "parameter F test:         F=215.8010, p=0.0000  , df_denom=8051, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=131.9068, p=0.0000  , df_denom=8048, df_num=5\n",
      "ssr based chi2 test:   chi2=660.4354, p=0.0000  , df=5\n",
      "likelihood ratio test: chi2=634.7672, p=0.0000  , df=5\n",
      "parameter F test:         F=131.9068, p=0.0000  , df_denom=8048, df_num=5\n"
     ]
    }
   ],
   "source": [
    "result = stm.grangercausalitytests(x, maxlag, addconst, verbose)\n",
    "optimal_lag = -1\n",
    "F_test = -1.0\n",
    "for key in result.keys():\n",
    "    _F_test_ = result[key][0]['params_ftest'][0]\n",
    "    if _F_test_ > F_test:\n",
    "        F_test = _F_test_\n",
    "        optimal_lag = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are going to look into the GC with Optimal Lag of 2\n"
     ]
    }
   ],
   "source": [
    "print(\"{} {}\".format(\"We are going to look into the GC with Optimal Lag of\", optimal_lag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the p-value of the test as a measure for Granger causality: rejection of ℋ0 (p < 0.03) signifies Granger causality, acceptance means non-causality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The causality relations drawn from systems with very small values of |det(ΛˆI)| are not meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (result[optimal_lag][0]['params_ftest'][1] < 0.03):\n",
    "    print(result[optimal_lag][0]['params_ftest'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute one Multivariant Granger Causality Matrix MGCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Used: 189.257473\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "MGCM = np.zeros((channel,channel))\n",
    "for i in range(channel):\n",
    "    for j in range(channel):\n",
    "        if i == j:\n",
    "            blockPrint()\n",
    "            print(\"{}:{}\".format(i,j))\n",
    "            MGCM[i,j] = 0\n",
    "        blockPrint()\n",
    "        a = np.asarray(temp_trial[i,:])\n",
    "        b = np.asarray(temp_trial[j,:])\n",
    "        x = np.vstack((a, b)).T\n",
    "        model = AR(a)\n",
    "        model_fit = model.fit()\n",
    "        maxlag = model_fit.k_ar\n",
    "        if maxlag > 5:\n",
    "            maxlag = 5\n",
    "        result = stm.grangercausalitytests(x, maxlag, addconst = True, verbose = True)\n",
    "        optimal_lag = -1\n",
    "        F_test = -1.0\n",
    "        for key in result.keys():\n",
    "            _F_test_ = result[key][0]['params_ftest'][0]\n",
    "            if _F_test_ > F_test:\n",
    "                F_test = _F_test_\n",
    "                optimal_lag = key\n",
    "        if (result[optimal_lag][0]['params_ftest'][1] < 0.03):\n",
    "            MGCM[i,j] = math.log(result[optimal_lag][0]['params_ftest'][0])\n",
    "        else:\n",
    "            MGCM[i,j] = 0\n",
    "blockPrint()\n",
    "diag = np.max(MGCM)\n",
    "for i in range(channel):\n",
    "    for j in range(channel):\n",
    "        if i == j:\n",
    "            MGCM[i,j] = 1\n",
    "        else:\n",
    "            MGCM[i,j] = MGCM[i,j]/diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "enablePrint()\n",
    "pyplot.matshow(MGCM)\n",
    "pyplot.show()\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print(\"{}: {}\".format(\"Time Used\", time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35693551284594077\n",
      "0.3423807029848485\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(MGCM))\n",
    "print(np.median(MGCM))\n",
    "print(np.max(MGCM))\n",
    "print(np.min(MGCM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hours needed:67.29154595555556\n"
     ]
    }
   ],
   "source": [
    "print(\"{}:{}\".format(\"Hours needed\", time_elapsed*40*32/60/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GoogleColab takes 34 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data computing MGCM for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_trial = ica[:,:,1]\n",
    "trial = ica.shape[2]\n",
    "print(\"{}: {}\".format(\"Total number of trials is\", trial))\n",
    "channel = temp_trial.shape[0]\n",
    "print(\"{}: {}\".format(\"Total number of channels in each trial is\", channel))\n",
    "timepoint = temp_trial.shape[1]\n",
    "print(\"{}: {}\".format(\"Total number of time points in per channel per trial is\", timepoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "hz = 128\n",
    "#a 3 second pre-trial baseline removed\n",
    "lstm_trial = temp_trial[:,128*3:]\n",
    "print(temp_trial.shape)\n",
    "print(lstm_trial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_trial = lstm_trial[:,0*hz:(0+1)*hz]\n",
    "print(current_trial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AR\n",
    "a = np.asarray(current_trial[0,:])\n",
    "b = np.asarray(current_trial[17,:])\n",
    "x = np.vstack((a, b)).T\n",
    "print(x.shape)\n",
    "\n",
    "model = AR(a)\n",
    "model_fit = model.fit()\n",
    "print('Lag: %s' % model_fit.k_ar)\n",
    "maxlag = model_fit.k_ar\n",
    "if maxlag > 8:\n",
    "    maxlag =8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are going to look into the GC with Optimal Lag of 7\n"
     ]
    }
   ],
   "source": [
    "blockPrint()\n",
    "result = stm.grangercausalitytests(x, maxlag, addconst, verbose)\n",
    "optimal_lag = -1\n",
    "F_test = -1.0\n",
    "for key in result.keys():\n",
    "    _F_test_ = result[key][0]['params_ftest'][0]\n",
    "    if _F_test_ > F_test:\n",
    "        F_test = _F_test_\n",
    "        optimal_lag = key\n",
    "enablePrint()\n",
    "print(\"{} {}\".format(\"We are going to look into the GC with Optimal Lag of\", optimal_lag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here split the dataset second by second and compute the MGCM for each 128 datapoints. Since 7680/128 = 60 seconds, the sanity check is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "for k in range(60):\n",
    "    print(k)\n",
    "    blockPrint()\n",
    "    current_trial = lstm_trial[k*hz:(k+1)*hz]\n",
    "    for i in range(channel):\n",
    "        for j in range(channel):\n",
    "            if i == j:\n",
    "                print(\"{} -> {}:{}\".format(k,i,j))\n",
    "                MGCM[i,j] = 0\n",
    "            blockPrint()\n",
    "            a = np.asarray(current_trial[i,:])\n",
    "            b = np.asarray(current_trial[j,:])\n",
    "            x = np.vstack((a, b)).T\n",
    "            model = AR(a)\n",
    "            model_fit = model.fit()\n",
    "            maxlag = model_fit.k_ar\n",
    "            if maxlag > 8:\n",
    "                maxlag = 8\n",
    "            result = stm.grangercausalitytests(x, maxlag, addconst = True, verbose = True)\n",
    "            optimal_lag = -1\n",
    "            F_test = -1.0\n",
    "            for key in result.keys():\n",
    "                _F_test_ = result[key][0]['params_ftest'][0]\n",
    "                if _F_test_ > F_test:\n",
    "                    F_test = _F_test_\n",
    "                    optimal_lag = key\n",
    "            if (result[optimal_lag][0]['params_ftest'][1] < 0.03):\n",
    "                MGCM[i,j] = math.log(result[optimal_lag][0]['params_ftest'][0])\n",
    "            else:\n",
    "                MGCM[i,j] = 0\n",
    "    enablePrint()\n",
    "    diag = np.max(MGCM)\n",
    "    print(diag)\n",
    "    for i in range(channel):\n",
    "        for j in range(channel):\n",
    "            if i == j:\n",
    "                MGCM[i,j] = 1\n",
    "            else:\n",
    "                MGCM[i,j] = MGCM[i,j]/diag\n",
    "    enablePrint()\n",
    "    pyplot.matshow(MGCM)\n",
    "    pyplot.show()\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print(\"{}: {}\".format(\"Time Used\", time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
