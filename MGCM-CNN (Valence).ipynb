{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"/Users/apple/Desktop/eeglab14_1_2b/Granger Casuality/img/\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "onlyfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "(32, 32, 4)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for i in range(len(onlyfiles)):\n",
    "    data = Image.open(mypath + onlyfiles[i])\n",
    "    arr = np.array(data)\n",
    "    X.append(arr)\n",
    "print(len(X))\n",
    "print(X[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('/Users/apple/Desktop/eeglab14_1_2b/participant_ratings.csv',\n",
    "                sep=r'\\s*,\\s*',engine = 'python', na_values = '?')\n",
    "df.dropna()\n",
    "Y_chart = pd.get_dummies(df, drop_first=True)\n",
    "Y = Y_chart['Valence'].tolist()\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Y)):\n",
    "    if Y[i] < 5:\n",
    "        Y[i] = 0\n",
    "    else:\n",
    "        Y[i] = 1\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1240, 32, 32, 4)\n",
      "(1240,)\n",
      "(40, 32, 32, 4)\n",
      "(40,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=(40/len(Y)))\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 4)\n",
      "Image dataset has min/mean/std/max = 1.00/139.56/79.39/255.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.57/0.50/1.00\n"
     ]
    }
   ],
   "source": [
    "print('Image dataset have shape =', X_train.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train.min(),\n",
    "                        X_train.mean(), X_train.std(), X_train.max()))\n",
    "print('')\n",
    "print('Train label has shape =', y_train.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(y_train.min(),\n",
    "                        y_train.mean(), y_train.std(), y_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset have shape = (1240, 32, 32, 4)\n",
      "Image dataset has min/mean/std/max = 0.00/0.55/0.31/1.00\n",
      "\n",
      "Train label has shape = (1240,)\n",
      "Training label has min/mean/std/max = 0.00/0.57/0.50/1.00\n"
     ]
    }
   ],
   "source": [
    "def normalize_data(data): \n",
    "    data = data / data.max()\n",
    "    return data\n",
    "\n",
    "X_train = normalize_data(X_train)\n",
    "X_test = normalize_data(X_test)\n",
    "print('Image dataset have shape =', X_train.shape)\n",
    "print('Image dataset has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(X_train.min(),\n",
    "                        X_train.mean(), X_train.std(), X_train.max()))\n",
    "print('')\n",
    "print('Train label has shape =', y_train.shape)\n",
    "print('Training label has min/mean/std/max = %.2f/%.2f/%.2f/%.2f'%(y_train.min(),\n",
    "                        y_train.mean(), y_train.std(), y_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    " [transforms.ToTensor(),\n",
    " transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "tensor_x = torch.stack([torch.Tensor(i) for i in X_train])\n",
    "tensor_y = torch.from_numpy(y_train)\n",
    "tensor_x_test = torch.stack([torch.Tensor(i) for i in X_test])\n",
    "tensor_y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = utils.TensorDataset(tensor_x,tensor_y)\n",
    "trainloader = utils.DataLoader(trainset,  batch_size= 40)\n",
    "testset = utils.TensorDataset(tensor_x_test,tensor_y_test)\n",
    "testloader = utils.DataLoader(testset,  batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "classes = ('Positive', 'Negative')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 32, 32, 4])\n",
      "torch.Size([40, 4, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "images = images.permute(0, 3, 1, 2)\n",
    "print(images.size())\n",
    "%matplotlib inline\n",
    "rows = 1\n",
    "columns = 1\n",
    "fig=plt.figure()\n",
    "for i in range(1):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    img = images[i]\n",
    "    img = torchvision.transforms.ToPILImage()(img)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(4, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (localization): Sequential(\n",
       "    (0): Conv2d(4, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU(inplace)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=576, out_features=96, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=96, out_features=6, bias=True)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Linear(in_features=6, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 6, 3)\n",
    "        self.conv1_bn = nn.BatchNorm2d(20)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.conv2_bn = nn.BatchNorm2d(10)\n",
    "        \n",
    "        #spatial transformer localization\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(4, 10, 3, padding = 1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(10, 20, 3, padding=1),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.ReLU(True)\n",
    "            \n",
    "        ) \n",
    "        #add an regressor\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(16*6*6, 96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(96, 6),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(6, num_classes),\n",
    "        )\n",
    "   \n",
    "    def forward(self, x):\n",
    "        #x = self.stn(x)\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        #x = F.dropout2d(x, p=0.5)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.flat(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def flat(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num = 1\n",
    "        for s in size:\n",
    "            num *= s\n",
    "        return num\n",
    "    \n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_classes = 2\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 10, 3, padding=1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(20)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(10)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(20*8*8, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(100, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 20 * 8 * 8)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:    19] avg mini-batch loss: 0.697\n",
      "[epoch: 1, i:    19] avg mini-batch loss: 0.691\n",
      "[epoch: 2, i:    19] avg mini-batch loss: 0.691\n",
      "[epoch: 3, i:    19] avg mini-batch loss: 0.692\n",
      "[epoch: 4, i:    19] avg mini-batch loss: 0.688\n",
      "[epoch: 5, i:    19] avg mini-batch loss: 0.683\n",
      "[epoch: 6, i:    19] avg mini-batch loss: 0.687\n",
      "[epoch: 7, i:    19] avg mini-batch loss: 0.687\n",
      "[epoch: 8, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 9, i:    19] avg mini-batch loss: 0.689\n",
      "[epoch: 10, i:    19] avg mini-batch loss: 0.686\n",
      "[epoch: 11, i:    19] avg mini-batch loss: 0.686\n",
      "[epoch: 12, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 13, i:    19] avg mini-batch loss: 0.687\n",
      "[epoch: 14, i:    19] avg mini-batch loss: 0.686\n",
      "[epoch: 15, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 16, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 17, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 18, i:    19] avg mini-batch loss: 0.686\n",
      "[epoch: 19, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 20, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 21, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 22, i:    19] avg mini-batch loss: 0.682\n",
      "[epoch: 23, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 24, i:    19] avg mini-batch loss: 0.686\n",
      "[epoch: 25, i:    19] avg mini-batch loss: 0.683\n",
      "[epoch: 26, i:    19] avg mini-batch loss: 0.686\n",
      "[epoch: 27, i:    19] avg mini-batch loss: 0.686\n",
      "[epoch: 28, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 29, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 30, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 31, i:    19] avg mini-batch loss: 0.686\n",
      "[epoch: 32, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 33, i:    19] avg mini-batch loss: 0.686\n",
      "[epoch: 34, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 35, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 36, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 37, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 38, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 39, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 40, i:    19] avg mini-batch loss: 0.686\n",
      "[epoch: 41, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 42, i:    19] avg mini-batch loss: 0.686\n",
      "[epoch: 43, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 44, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 45, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 46, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 47, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 48, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 49, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 50, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 51, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 52, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 53, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 54, i:    19] avg mini-batch loss: 0.686\n",
      "[epoch: 55, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 56, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 57, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 58, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 59, i:    19] avg mini-batch loss: 0.683\n",
      "[epoch: 60, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 61, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 62, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 63, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 64, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 65, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 66, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 67, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 68, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 69, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 70, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 71, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 72, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 73, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 74, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 75, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 76, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 77, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 78, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 79, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 80, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 81, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 82, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 83, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 84, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 85, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 86, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 87, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 88, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 89, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 90, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 91, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 92, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 93, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 94, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 95, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 96, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 97, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 98, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 99, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 100, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 101, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 102, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 103, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 104, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 105, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 106, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 107, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 108, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 109, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 110, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 111, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 112, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 113, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 114, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 115, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 116, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 117, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 118, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 119, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 120, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 121, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 122, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 123, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 124, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 125, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 126, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 127, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 128, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 129, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 130, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 131, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 132, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 133, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 134, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 135, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 136, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 137, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 138, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 139, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 140, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 141, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 142, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 143, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 144, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 145, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 146, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 147, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 148, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 149, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 150, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 151, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 152, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 153, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 154, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 155, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 156, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 157, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 158, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 159, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 160, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 161, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 162, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 163, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 164, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 165, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 166, i:    19] avg mini-batch loss: 0.684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 167, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 168, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 169, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 170, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 171, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 172, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 173, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 174, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 175, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 176, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 177, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 178, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 179, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 180, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 181, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 182, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 183, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 184, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 185, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 186, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 187, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 188, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 189, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 190, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 191, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 192, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 193, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 194, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 195, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 196, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 197, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 198, i:    19] avg mini-batch loss: 0.685\n",
      "[epoch: 199, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 200, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 201, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 202, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 203, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 204, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 205, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 206, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 207, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 208, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 209, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 210, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 211, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 212, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 213, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 214, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 215, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 216, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 217, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 218, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 219, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 220, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 221, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 222, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 223, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 224, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 225, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 226, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 227, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 228, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 229, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 230, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 231, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 232, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 233, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 234, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 235, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 236, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 237, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 238, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 239, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 240, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 241, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 242, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 243, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 244, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 245, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 246, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 247, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 248, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 249, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 250, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 251, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 252, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 253, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 254, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 255, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 256, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 257, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 258, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 259, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 260, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 261, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 262, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 263, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 264, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 265, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 266, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 267, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 268, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 269, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 270, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 271, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 272, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 273, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 274, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 275, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 276, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 277, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 278, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 279, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 280, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 281, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 282, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 283, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 284, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 285, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 286, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 287, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 288, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 289, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 290, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 291, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 292, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 293, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 294, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 295, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 296, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 297, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 298, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 299, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 300, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 301, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 302, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 303, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 304, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 305, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 306, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 307, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 308, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 309, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 310, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 311, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 312, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 313, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 314, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 315, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 316, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 317, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 318, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 319, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 320, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 321, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 322, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 323, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 324, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 325, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 326, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 327, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 328, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 329, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 330, i:    19] avg mini-batch loss: 0.684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 331, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 332, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 333, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 334, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 335, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 336, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 337, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 338, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 339, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 340, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 341, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 342, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 343, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 344, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 345, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 346, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 347, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 348, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 349, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 350, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 351, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 352, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 353, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 354, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 355, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 356, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 357, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 358, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 359, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 360, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 361, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 362, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 363, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 364, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 365, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 366, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 367, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 368, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 369, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 370, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 371, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 372, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 373, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 374, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 375, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 376, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 377, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 378, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 379, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 380, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 381, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 382, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 383, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 384, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 385, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 386, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 387, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 388, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 389, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 390, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 391, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 392, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 393, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 394, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 395, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 396, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 397, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 398, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 399, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 400, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 401, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 402, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 403, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 404, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 405, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 406, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 407, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 408, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 409, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 410, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 411, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 412, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 413, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 414, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 415, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 416, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 417, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 418, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 419, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 420, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 421, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 422, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 423, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 424, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 425, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 426, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 427, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 428, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 429, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 430, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 431, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 432, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 433, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 434, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 435, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 436, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 437, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 438, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 439, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 440, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 441, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 442, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 443, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 444, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 445, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 446, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 447, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 448, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 449, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 450, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 451, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 452, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 453, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 454, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 455, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 456, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 457, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 458, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 459, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 460, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 461, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 462, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 463, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 464, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 465, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 466, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 467, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 468, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 469, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 470, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 471, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 472, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 473, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 474, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 475, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 476, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 477, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 478, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 479, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 480, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 481, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 482, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 483, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 484, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 485, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 486, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 487, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 488, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 489, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 490, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 491, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 492, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 493, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 494, i:    19] avg mini-batch loss: 0.684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 495, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 496, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 497, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 498, i:    19] avg mini-batch loss: 0.684\n",
      "[epoch: 499, i:    19] avg mini-batch loss: 0.684\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(net.parameters(), lr= 0.001)\n",
    "#opt = torch.optim.Adamax(net.parameters(), lr=0.01)\n",
    "#opt = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "#opt = torch.optim.Adagrad(net.parameters(), lr=0.0)\n",
    "avg_losses = [] \n",
    "epochs = 500\n",
    "print_freq = 20\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.permute(0, 3, 1, 2)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        opt.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1:\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Accuracy of the network on the 40 test images: 52 %\n",
      "Accuracy of Positive :  0 %\n",
      "Accuracy of Negative : 100 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(total)\n",
    "print('Accuracy of the network on the 40 test images: %d %%' % (100 * correct / total))\n",
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        one = torch.tensor(1, dtype=torch.float, device=device)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(40):\n",
    "            label = labels[i]\n",
    "            labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240\n",
      "Accuracy of the network on the 1240 training images: 56 %\n",
      "Accuracy of Positive :  0 %\n",
      "Accuracy of Negative : 100 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(total)\n",
    "print('Accuracy of the network on the 1240 training images: %d %%' % (100 * correct / total))\n",
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        images = images.permute(0, 3, 1, 2)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        one = torch.tensor(1, dtype=torch.float, device=device)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(40):\n",
    "            label = labels[i]\n",
    "            labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
